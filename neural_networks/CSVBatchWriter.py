import os
import pandas as pd

class CSVBatchWriter:
    def __init__(self, filename, q_ranges_names_with_dofs, nb_muscles, nb_q, batch_size=100):
        """ Initialize the CSVBatchWriter with a file name, a list of degrees of freedom names,
        and an optional batch size.
        
        Args:
        - filename (str): The name - path of the CSV file to write data.
        - q_ranges_names_with_dofs (list of string): A list of names for the degrees of freedom.
        - nb_muscle (int) : number of muscle in the biorbd model
        - nb_q (int):  number of q in the biorbd model.
        - batch_size (int): The size of the batch for buffering data before writing to CSV.
        """
        self.filename = filename
        self.q_ranges_names_with_dofs = q_ranges_names_with_dofs
        self.nb_muscles = nb_muscles
        self.nb_q = nb_q
        self.batch_size = batch_size
        self.buffer = [] # Initialize an empty list to act as a buffer for batch writing
        
        # Check if file exists, if not create it with initial structure
        if not os.path.exists(filename):
            # Create a dictionary with keys for each column in the CSV
            data = {
                "muscle_selected": [],
                # Add columns for each degree of freedom (DOF) and its derivative (qdot)
                **{f"q_{self.q_ranges_names_with_dofs[k]}": [] for k in range(len(self.q_ranges_names_with_dofs))},
                **{f"qdot_{self.q_ranges_names_with_dofs[k]}": [] for k in range(len(self.q_ranges_names_with_dofs))},
                "alpha": [],
                "origin_muscle_x": [],
                "origin_muscle_y": [],
                "origin_muscle_z": [],
                "insertion_muscle_x": [],
                "insertion_muscle_y": [],
                "insertion_muscle_z": [],
                "segment_length": [],
                **{f"dlmt_dq_{j}_{self.q_ranges_names_with_dofs[k]}": [] for j in range(self.nb_muscles) for k in range(len(self.q_ranges_names_with_dofs)) },
                **{f"muscle_force_{k}": [] for k in range(self.nb_q)},
                **{f"torque_{k}": [] for k in range(self.nb_q)},
                 }
            # Create a DataFrame from the dictionary and write it to a CSV file
            pd.DataFrame(data).to_csv(filename, index=False)


    def add_line(self, muscle_selected_index, q, qdot, alpha, origin_muscle, insertion_muscle, segment_length, dlmt_dq, 
                 muscle_force, torque):
        """ Add a new line of data to the buffer. If the buffer reaches the batch size, write it to the CSV file.

        Args:
        - muscle_selected_index (int): Index of the selected muscle.
        - q (list): List of joint angles for each degree of freedom.
        - qdot (list): List of joint angular velocities for each degree of freedom.
        - alpha (float): Parameter related to muscle configuration.
        - origin_muscle (list): List of x, y, z coordinates for the muscle's origin.
        - insertion_muscle (list): List of x, y, z coordinates for the muscle's insertion.
        - segment_length (float): Length of the muscle segment.
        - dlmt_dq (list): Partial derivatives of muscle length with respect to each DOF.
        - muscle_force (float): Force exerted by the muscle.
        - torque (float): Torque generated by the muscle force.
        """
        # Create a new line with the provided data
        new_line = {
            "muscle_selected": muscle_selected_index,
            # Populate q and qdot values for each degree of freedom
            **{f"q_{self.q_ranges_names_with_dofs[k]}":  q[k] for k in range(len(q))},
            **{f"qdot_{self.q_ranges_names_with_dofs[k]}":  qdot[k] for k in range(len(qdot))},
            "alpha": alpha,
            "origin_muscle_x": origin_muscle[0],
            "origin_muscle_y": origin_muscle[1],
            "origin_muscle_z": origin_muscle[2],
            "insertion_muscle_x": insertion_muscle[0],
            "insertion_muscle_y": insertion_muscle[1],
            "insertion_muscle_z": insertion_muscle[2],
            "segment_length": segment_length,            
            **{f"dlmt_dq_{j}_{self.q_ranges_names_with_dofs[k]}": dlmt_dq[j][k] for j in range(self.nb_muscles) for k in range(len(self.q_ranges_names_with_dofs)) },
            **{f"muscle_force_{k}": muscle_force[k] for k in range(self.nb_q)},
            **{f"torque_{k}": torque[k] for k in range(self.nb_q)},
        }
        
        # Add the new line to the buffer
        self.buffer.append(new_line)
        
        # If the buffer reaches the batch size, write the buffered data to the CSV file
        if len(self.buffer) >= self.batch_size:
            self._flush()

    def _flush(self):
        """  Write the buffered data to the CSV file. If the file already exists, append the buffered data
        to the existing data; otherwise, create a new file with the buffered data.
        """
        if not self.buffer:
            return

        # Convert the buffer into a DataFrame
        buffer_df = pd.DataFrame(self.buffer)

        # Check if the CSV file already exists
        if os.path.exists(self.filename):
            # Read existing data
            df = pd.read_csv(self.filename)
            # Concatenate existing data with buffer
            df = pd.concat([df, buffer_df], ignore_index=True)
        else:
            # If file doesn't exist, use the buffer data
            df = buffer_df

        # Write the updated DataFrame to the CSV file
        df.to_csv(self.filename, index=False)

        # Clear the buffer
        self.buffer = []

    def del_lines(self, n):
        """ Delete excess lines from the CSV file, keeping only the first 'n' lines.

        Args:
        - n (int): The number of lines to retain in the CSV file.
        """
        # Read the data from the CSV file
        df = pd.read_csv(self.filename)
        current_lines = df.shape[0]

        # If the current number of lines is greater than 'n', delete the excess lines
        if current_lines > n:
            df = df.head(n) # Retain only the first 'n' lines

            # Write the updated DataFrame back to the CSV file
            df.to_csv(self.filename, index=False)
                
    def get_num_line(self) : 
        """ Get the number of lines currently in the CSV file.

        Returns:
        int: The number of lines in the CSV file. Returns 0 if the file does not exist.
        """
        # Check if the CSV file exists
        if os.path.exists(self.filename):
            df = pd.read_csv(self.filename)
            return len(df)
        else:
            # If the file does not exist, return 0
            return 0
        
    def close(self):
        """
        Flush any remaining lines in the buffer to the CSV file when closing.
        """
        # Write any remaining buffered data to the CSV file
        self._flush()


6.173668661117554

num_try : 864 | val_loss = 6.173668661117554 | val acc = 4.2106523513793945
Time execution (tranning): 62.040000 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.2125444507598875

num_try : 900 | val_loss = 6.2125444507598875 | val acc = 4.215485095977783
Time execution (tranning): 111.400859 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.327681827545166

num_try : 972 | val_loss = 6.327681827545166 | val acc = 4.317105770111084
Time execution (tranning): 77.727047 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.469809055328369

num_try : 936 | val_loss = 6.469809055328369 | val acc = 4.3245158195495605
Time execution (tranning): 72.649565 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.501618671417236

num_try : 792 | val_loss = 6.501618671417236 | val acc = 4.405607223510742
Time execution (tranning): 89.850265 seconds 
Time execution (load saved model): 0.002106 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.548812322616577

num_try : 756 | val_loss = 6.548812322616577 | val acc = 4.4067158699035645
Time execution (tranning): 63.131726 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.574565420150757

num_try : 981 | val_loss = 6.574565420150757 | val acc = 4.385801792144775
Time execution (tranning): 81.310695 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.6142508411407475

num_try : 720 | val_loss = 6.6142508411407475 | val acc = 4.502202987670898
Time execution (tranning): 76.432104 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.669619345664978

num_try : 909 | val_loss = 6.669619345664978 | val acc = 4.367664337158203
Time execution (tranning): 90.260329 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.687929801940918

num_try : 837 | val_loss = 6.687929801940918 | val acc = 4.366357326507568
Time execution (tranning): 83.909745 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.688350067138672

num_try : 927 | val_loss = 6.688350067138672 | val acc = 4.422195911407471
Time execution (tranning): 154.684272 seconds 
Time execution (load saved model): 0.002160 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.73297887802124

num_try : 828 | val_loss = 6.73297887802124 | val acc = 4.509064197540283
Time execution (tranning): 73.577313 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.765057888031006

num_try : 801 | val_loss = 6.765057888031006 | val acc = 4.455206871032715
Time execution (tranning): 71.682168 seconds 
Time execution (load saved model): 0.002104 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.783205928802491

num_try : 612 | val_loss = 6.783205928802491 | val acc = 4.468993663787842
Time execution (tranning): 103.251496 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.877685508728027

num_try : 729 | val_loss = 6.877685508728027 | val acc = 4.497071266174316
Time execution (tranning): 107.965719 seconds 
Time execution (load saved model): 0.002101 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.925739917755127

num_try : 882 | val_loss = 6.925739917755127 | val acc = 4.594031810760498
Time execution (tranning): 130.603784 seconds 
Time execution (load saved model): 0.002141 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 390
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.92643364906311

num_try : 891 | val_loss = 6.92643364906311 | val acc = 4.469921112060547
Time execution (tranning): 149.194070 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 423
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.958698663711548

num_try : 954 | val_loss = 6.958698663711548 | val acc = 4.579336166381836
Time execution (tranning): 142.670068 seconds 
Time execution (load saved model): 0.002170 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 422
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

6.960760478973389

num_try : 873 | val_loss = 6.960760478973389 | val acc = 4.493900775909424
Time execution (tranning): 103.651979 seconds 
Time execution (load saved model): 0.002171 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.049757242202759

num_try : 945 | val_loss = 7.049757242202759 | val acc = 4.5384440422058105
Time execution (tranning): 136.357063 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.094313869476318

num_try : 765 | val_loss = 7.094313869476318 | val acc = 4.598949432373047
Time execution (tranning): 78.697485 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.125169372558593

num_try : 585 | val_loss = 7.125169372558593 | val acc = 4.671949863433838
Time execution (tranning): 84.143948 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.208144540786743

num_try : 819 | val_loss = 7.208144540786743 | val acc = 4.6345133781433105
Time execution (tranning): 144.776323 seconds 
Time execution (load saved model): 0.002106 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.223835153579712

num_try : 855 | val_loss = 7.223835153579712 | val acc = 4.603572845458984
Time execution (tranning): 151.796760 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 469
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.247151603698731

num_try : 684 | val_loss = 7.247151603698731 | val acc = 4.843343734741211
Time execution (tranning): 102.265146 seconds 
Time execution (load saved model): 0.002064 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 333
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.249156103134156

num_try : 576 | val_loss = 7.249156103134156 | val acc = 4.798739433288574
Time execution (tranning): 85.535534 seconds 
Time execution (load saved model): 0.002076 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.284658460617066

num_try : 963 | val_loss = 7.284658460617066 | val acc = 4.676516056060791
Time execution (tranning): 125.156010 seconds 
Time execution (load saved model): 0.002140 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.312426767349243

num_try : 648 | val_loss = 7.312426767349243 | val acc = 4.903160572052002
Time execution (tranning): 108.171729 seconds 
Time execution (load saved model): 0.002095 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 346
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.330577392578125

num_try : 990 | val_loss = 7.330577392578125 | val acc = 4.789619445800781
Time execution (tranning): 112.681235 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.346163496971131

num_try : 783 | val_loss = 7.346163496971131 | val acc = 4.694999694824219
Time execution (tranning): 147.802604 seconds 
Time execution (load saved model): 0.002121 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 451
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.347647638320923

num_try : 747 | val_loss = 7.347647638320923 | val acc = 4.652890682220459
Time execution (tranning): 158.345074 seconds 
Time execution (load saved model): 0.002105 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 487
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.352740392684937

num_try : 468 | val_loss = 7.352740392684937 | val acc = 4.891381740570068
Time execution (tranning): 107.510825 seconds 
Time execution (load saved model): 0.002103 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 359
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.36968957901001

num_try : 657 | val_loss = 7.36968957901001 | val acc = 4.7712860107421875
Time execution (tranning): 102.541188 seconds 
Time execution (load saved model): 0.002097 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.3831232643127445

num_try : 999 | val_loss = 7.3831232643127445 | val acc = 4.713925361633301
Time execution (tranning): 127.976454 seconds 
Time execution (load saved model): 0.002160 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 368
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.4142493057250975

num_try : 693 | val_loss = 7.4142493057250975 | val acc = 4.754179000854492
Time execution (tranning): 80.065949 seconds 
Time execution (load saved model): 0.002081 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.503560628890991

num_try : 774 | val_loss = 7.503560628890991 | val acc = 4.851587295532227
Time execution (tranning): 94.835748 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.520861263275147

num_try : 738 | val_loss = 7.520861263275147 | val acc = 4.912292003631592
Time execution (tranning): 112.159679 seconds 
Time execution (load saved model): 0.002103 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.533506374359131

num_try : 621 | val_loss = 7.533506374359131 | val acc = 4.890866756439209
Time execution (tranning): 75.288756 seconds 
Time execution (load saved model): 0.002095 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.652841186523437

num_try : 810 | val_loss = 7.652841186523437 | val acc = 4.9812703132629395
Time execution (tranning): 110.523278 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.7032163619995115

num_try : 918 | val_loss = 7.7032163619995115 | val acc = 4.977084159851074
Time execution (tranning): 98.365726 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.788555612564087

num_try : 630 | val_loss = 7.788555612564087 | val acc = 4.975606918334961
Time execution (tranning): 132.766493 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 426
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

7.791295728683472

num_try : 846 | val_loss = 7.791295728683472 | val acc = 4.977654933929443
Time execution (tranning): 86.564229 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.249766654968262

num_try : 504 | val_loss = 8.249766654968262 | val acc = 5.337151527404785
Time execution (tranning): 60.235802 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.257413539886475

num_try : 540 | val_loss = 8.257413539886475 | val acc = 5.338892936706543
Time execution (tranning): 102.474595 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.28931360244751

num_try : 666 | val_loss = 8.28931360244751 | val acc = 5.276994228363037
Time execution (tranning): 132.236656 seconds 
Time execution (load saved model): 0.002139 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 431
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.298576793670655

num_try : 432 | val_loss = 8.298576793670655 | val acc = 5.383131504058838
Time execution (tranning): 95.253688 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.391078023910522

num_try : 711 | val_loss = 8.391078023910522 | val acc = 5.266106605529785
Time execution (tranning): 158.001559 seconds 
Time execution (load saved model): 0.002095 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 498
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.480672769546509

num_try : 450 | val_loss = 8.480672769546509 | val acc = 5.322354793548584
Time execution (tranning): 119.793426 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 391
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.482223901748657

num_try : 396 | val_loss = 8.482223901748657 | val acc = 5.467929840087891
Time execution (tranning): 101.105469 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.52890287399292

num_try : 675 | val_loss = 8.52890287399292 | val acc = 5.2417097091674805
Time execution (tranning): 102.518351 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.589021577835084

num_try : 603 | val_loss = 8.589021577835084 | val acc = 5.337914943695068
Time execution (tranning): 139.800885 seconds 
Time execution (load saved model): 0.002081 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 444
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.821618843078614

num_try : 702 | val_loss = 8.821618843078614 | val acc = 5.490805625915527
Time execution (tranning): 110.110372 seconds 
Time execution (load saved model): 0.002078 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

8.933741340637207

num_try : 594 | val_loss = 8.933741340637207 | val acc = 5.523428916931152
Time execution (tranning): 86.955047 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.003016529083252

num_try : 549 | val_loss = 9.003016529083252 | val acc = 5.467428684234619
Time execution (tranning): 63.894375 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.141211605072021

num_try : 486 | val_loss = 9.141211605072021 | val acc = 5.724982738494873
Time execution (tranning): 143.851482 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 482
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.363939428329468

num_try : 639 | val_loss = 9.363939428329468 | val acc = 5.596154689788818
Time execution (tranning): 107.484024 seconds 
Time execution (load saved model): 0.002099 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 338
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.506457042694091

num_try : 522 | val_loss = 9.506457042694091 | val acc = 5.816453456878662
Time execution (tranning): 96.323160 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.509081630706786

num_try : 306 | val_loss = 9.509081630706786 | val acc = 5.840733051300049
Time execution (tranning): 168.267050 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 563
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.56021411895752

num_try : 288 | val_loss = 9.56021411895752 | val acc = 5.805352687835693
Time execution (tranning): 75.871438 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.690332584381103

num_try : 477 | val_loss = 9.690332584381103 | val acc = 5.813310146331787
Time execution (tranning): 110.479877 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.881002616882324

num_try : 108 | val_loss = 9.881002616882324 | val acc = 6.0644850730896
Time execution (tranning): 93.419909 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.971728687286378

num_try : 558 | val_loss = 9.971728687286378 | val acc = 6.018569469451904
Time execution (tranning): 104.506700 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 347
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.971952667236328

num_try : 342 | val_loss = 9.971952667236328 | val acc = 6.15786075592041
Time execution (tranning): 128.850821 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 430
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

9.976408653259277

num_try : 252 | val_loss = 9.976408653259277 | val acc = 5.8961615562438965
Time execution (tranning): 76.683493 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

10.421562366485595

num_try : 144 | val_loss = 10.421562366485595 | val acc = 6.131884574890137
Time execution (tranning): 62.197028 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

10.483331241607665

num_try : 441 | val_loss = 10.483331241607665 | val acc = 6.337695121765137
Time execution (tranning): 97.905431 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

10.507080440521241

num_try : 360 | val_loss = 10.507080440521241 | val acc = 6.156587600708008
Time execution (tranning): 93.347455 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

10.571091918945312

num_try : 324 | val_loss = 10.571091918945312 | val acc = 6.208435535430908
Time execution (tranning): 66.459554 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

10.958756923675537

num_try : 126 | val_loss = 10.958756923675537 | val acc = 6.649076461791992
Time execution (tranning): 121.563517 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 409
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

11.047714214324952

num_try : 36 | val_loss = 11.047714214324952 | val acc = 6.459291934967041
Time execution (tranning): 64.578608 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

11.276138801574707

num_try : 901 | val_loss = 11.276138801574707 | val acc = 4.194641590118408
Time execution (tranning): 79.390591 seconds 
Time execution (load saved model): 0.002188 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

11.501658630371093

num_try : 216 | val_loss = 11.501658630371093 | val acc = 6.476810932159424
Time execution (tranning): 102.996454 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

11.686365604400635

num_try : 973 | val_loss = 11.686365604400635 | val acc = 4.317821502685547
Time execution (tranning): 80.348153 seconds 
Time execution (load saved model): 0.002161 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

11.83648193359375

num_try : 378 | val_loss = 11.83648193359375 | val acc = 6.800151824951172
Time execution (tranning): 86.931281 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

11.95555871963501

num_try : 757 | val_loss = 11.95555871963501 | val acc = 4.358672618865967
Time execution (tranning): 78.641723 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

11.973453617095947

num_try : 0 | val_loss = 11.973453617095947 | val acc = 6.683276176452637
Time execution (tranning): 114.889634 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 367
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

11.997383365631103

num_try : 937 | val_loss = 11.997383365631103 | val acc = 4.320546627044678
Time execution (tranning): 66.028395 seconds 
Time execution (load saved model): 0.002186 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.083688411712647

num_try : 865 | val_loss = 12.083688411712647 | val acc = 4.349388122558594
Time execution (tranning): 63.846832 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.09908535003662

num_try : 351 | val_loss = 12.09908535003662 | val acc = 6.952220439910889
Time execution (tranning): 143.831001 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 475
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.11517951965332

num_try : 18 | val_loss = 12.11517951965332 | val acc = 7.031327724456787
Time execution (tranning): 92.304171 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.245590114593506

num_try : 459 | val_loss = 12.245590114593506 | val acc = 6.973227500915527
Time execution (tranning): 117.492947 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.316399879455567

num_try : 793 | val_loss = 12.316399879455567 | val acc = 4.467573165893555
Time execution (tranning): 96.814604 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.35593053817749

num_try : 991 | val_loss = 12.35593053817749 | val acc = 4.532745838165283
Time execution (tranning): 210.783949 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 618
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.395755786895752

num_try : 649 | val_loss = 12.395755786895752 | val acc = 4.555391311645508
Time execution (tranning): 128.491253 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 409
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.396339550018311

num_try : 72 | val_loss = 12.396339550018311 | val acc = 6.867091655731201
Time execution (tranning): 97.205345 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.457432413101197

num_try : 874 | val_loss = 12.457432413101197 | val acc = 4.32900857925415
Time execution (tranning): 133.601268 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 380
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.468265285491944

num_try : 90 | val_loss = 12.468265285491944 | val acc = 7.2004289627075195
Time execution (tranning): 78.149304 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.475138721466065

num_try : 982 | val_loss = 12.475138721466065 | val acc = 4.409055709838867
Time execution (tranning): 92.528435 seconds 
Time execution (load saved model): 0.002182 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.518132677078247

num_try : 892 | val_loss = 12.518132677078247 | val acc = 4.372493743896484
Time execution (tranning): 166.992135 seconds 
Time execution (load saved model): 0.002184 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 474
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.543871974945068

num_try : 946 | val_loss = 12.543871974945068 | val acc = 4.377569675445557
Time execution (tranning): 114.366698 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.647524499893189

num_try : 721 | val_loss = 12.647524499893189 | val acc = 4.51672887802124
Time execution (tranning): 74.707061 seconds 
Time execution (load saved model): 0.002122 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.660176620483398

num_try : 766 | val_loss = 12.660176620483398 | val acc = 4.402429103851318
Time execution (tranning): 104.813133 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.668700523376465

num_try : 513 | val_loss = 12.668700523376465 | val acc = 7.102951526641846
Time execution (tranning): 87.654236 seconds 
Time execution (load saved model): 0.002152 seconds 
Time execution (use saved model): 0.000358 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.669044551849366

num_try : 81 | val_loss = 12.669044551849366 | val acc = 7.3621697425842285
Time execution (tranning): 56.103330 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.709773731231689

num_try : 685 | val_loss = 12.709773731231689 | val acc = 4.638426780700684
Time execution (tranning): 75.703625 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.721607494354249

num_try : 730 | val_loss = 12.721607494354249 | val acc = 4.448049545288086
Time execution (tranning): 120.454156 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.786627426147462

num_try : 198 | val_loss = 12.786627426147462 | val acc = 7.2558393478393555
Time execution (tranning): 99.622564 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 332
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.80221118927002

num_try : 387 | val_loss = 12.80221118927002 | val acc = 7.136358261108398
Time execution (tranning): 132.418629 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.82518274307251

num_try : 117 | val_loss = 12.82518274307251 | val acc = 7.376672267913818
Time execution (tranning): 62.068168 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.843964767456054

num_try : 531 | val_loss = 12.843964767456054 | val acc = 7.202826023101807
Time execution (tranning): 94.628103 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.855660934448242

num_try : 910 | val_loss = 12.855660934448242 | val acc = 4.5849738121032715
Time execution (tranning): 98.219146 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.880706615447998

num_try : 838 | val_loss = 12.880706615447998 | val acc = 4.431028842926025
Time execution (tranning): 94.414680 seconds 
Time execution (load saved model): 0.002121 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

12.881299839019775

num_try : 405 | val_loss = 12.881299839019775 | val acc = 7.156468391418457
Time execution (tranning): 64.151519 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.888362922668456

num_try : 189 | val_loss = 12.888362922668456 | val acc = 7.219402313232422
Time execution (tranning): 95.334823 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.926198616027833

num_try : 234 | val_loss = 12.926198616027833 | val acc = 7.25462532043457
Time execution (tranning): 86.775605 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000214 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

12.939643344879151

num_try : 811 | val_loss = 12.939643344879151 | val acc = 4.694638252258301
Time execution (tranning): 169.834296 seconds 
Time execution (load saved model): 0.002182 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 543
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.042905330657959

num_try : 613 | val_loss = 13.042905330657959 | val acc = 4.735403537750244
Time execution (tranning): 102.351508 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.072706394195556

num_try : 802 | val_loss = 13.072706394195556 | val acc = 4.548989772796631
Time execution (tranning): 84.579969 seconds 
Time execution (load saved model): 0.002105 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.080360260009765

num_try : 180 | val_loss = 13.080360260009765 | val acc = 7.193149566650391
Time execution (tranning): 53.749397 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 180
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.10071559906006

num_try : 1000 | val_loss = 13.10071559906006 | val acc = 4.5411176681518555
Time execution (tranning): 127.035093 seconds 
Time execution (load saved model): 0.002167 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 365
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.122661952972413

num_try : 883 | val_loss = 13.122661952972413 | val acc = 4.6694722175598145
Time execution (tranning): 142.430929 seconds 
Time execution (load saved model): 0.002137 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 428
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.140217990875245

num_try : 315 | val_loss = 13.140217990875245 | val acc = 7.2883195877075195
Time execution (tranning): 92.685311 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.172065525054931

num_try : 748 | val_loss = 13.172065525054931 | val acc = 4.548854827880859
Time execution (tranning): 168.971685 seconds 
Time execution (load saved model): 0.002102 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 520
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.219713039398194

num_try : 964 | val_loss = 13.219713039398194 | val acc = 4.528670787811279
Time execution (tranning): 169.525888 seconds 
Time execution (load saved model): 0.002139 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 491
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.225588264465332

num_try : 54 | val_loss = 13.225588264465332 | val acc = 7.414630889892578
Time execution (tranning): 97.450170 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.23217472076416

num_try : 847 | val_loss = 13.23217472076416 | val acc = 4.666689872741699
Time execution (tranning): 140.540943 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 444
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.24091329574585

num_try : 829 | val_loss = 13.24091329574585 | val acc = 4.739099502563477
Time execution (tranning): 120.171058 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 378
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.299127807617188

num_try : 153 | val_loss = 13.299127807617188 | val acc = 7.3698296546936035
Time execution (tranning): 61.886258 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.317871837615966

num_try : 270 | val_loss = 13.317871837615966 | val acc = 7.464020252227783
Time execution (tranning): 80.735468 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.333358917236328

num_try : 928 | val_loss = 13.333358917236328 | val acc = 4.758219242095947
Time execution (tranning): 178.423989 seconds 
Time execution (load saved model): 0.002163 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 514
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.380867710113526

num_try : 297 | val_loss = 13.380867710113526 | val acc = 7.375188827514648
Time execution (tranning): 119.550400 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 395
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.389032745361328

num_try : 955 | val_loss = 13.389032745361328 | val acc = 4.699580669403076
Time execution (tranning): 124.684017 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 368
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.399752349853516

num_try : 495 | val_loss = 13.399752349853516 | val acc = 7.389846324920654
Time execution (tranning): 97.068829 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.458154487609864

num_try : 577 | val_loss = 13.458154487609864 | val acc = 4.778131008148193
Time execution (tranning): 74.561341 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.516139183044434

num_try : 171 | val_loss = 13.516139183044434 | val acc = 7.456420421600342
Time execution (tranning): 73.314851 seconds 
Time execution (load saved model): 0.002019 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.605568351745605

num_try : 279 | val_loss = 13.605568351745605 | val acc = 7.431787490844727
Time execution (tranning): 64.608296 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.626757144927979

num_try : 784 | val_loss = 13.626757144927979 | val acc = 4.691092014312744
Time execution (tranning): 159.428150 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 490
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.660709781646728

num_try : 694 | val_loss = 13.660709781646728 | val acc = 4.7135701179504395
Time execution (tranning): 85.598755 seconds 
Time execution (load saved model): 0.002079 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.673481216430664

num_try : 469 | val_loss = 13.673481216430664 | val acc = 4.8785200119018555
Time execution (tranning): 87.635090 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.68367467880249

num_try : 919 | val_loss = 13.68367467880249 | val acc = 4.803074359893799
Time execution (tranning): 104.028346 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.700763702392578

num_try : 658 | val_loss = 13.700763702392578 | val acc = 4.750627517700195
Time execution (tranning): 91.143484 seconds 
Time execution (load saved model): 0.002065 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.739556121826173

num_try : 162 | val_loss = 13.739556121826173 | val acc = 7.5924391746521
Time execution (tranning): 74.219888 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.783370761871337

num_try : 856 | val_loss = 13.783370761871337 | val acc = 4.730384349822998
Time execution (tranning): 129.162323 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

13.889487533569335

num_try : 333 | val_loss = 13.889487533569335 | val acc = 7.491439342498779
Time execution (tranning): 66.167051 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.91101095199585

num_try : 414 | val_loss = 13.91101095199585 | val acc = 7.564881801605225
Time execution (tranning): 70.750841 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.969590072631837

num_try : 622 | val_loss = 13.969590072631837 | val acc = 4.734854221343994
Time execution (tranning): 90.086797 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.06968074798584

num_try : 45 | val_loss = 14.06968074798584 | val acc = 7.749107837677002
Time execution (tranning): 80.476934 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

14.124563999176026

num_try : 586 | val_loss = 14.124563999176026 | val acc = 4.788498401641846
Time execution (tranning): 66.261416 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.171482048034669

num_try : 433 | val_loss = 14.171482048034669 | val acc = 5.020162105560303
Time execution (tranning): 75.434106 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.358194198608398

num_try : 9 | val_loss = 14.358194198608398 | val acc = 7.800094127655029
Time execution (tranning): 55.693428 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 184
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

14.36348892211914

num_try : 775 | val_loss = 14.36348892211914 | val acc = 5.041255474090576
Time execution (tranning): 104.629120 seconds 
Time execution (load saved model): 0.002100 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.430633506774903

num_try : 99 | val_loss = 14.430633506774903 | val acc = 7.807222843170166
Time execution (tranning): 131.256988 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

14.473542346954346

num_try : 567 | val_loss = 14.473542346954346 | val acc = 7.721914291381836
Time execution (tranning): 135.533388 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 441
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

14.709193782806397

num_try : 739 | val_loss = 14.709193782806397 | val acc = 4.9936137199401855
Time execution (tranning): 92.261868 seconds 
Time execution (load saved model): 0.002105 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.824248161315918

num_try : 820 | val_loss = 14.824248161315918 | val acc = 4.970331192016602
Time execution (tranning): 108.767916 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

14.882454853057862

num_try : 369 | val_loss = 14.882454853057862 | val acc = 7.825949192047119
Time execution (tranning): 56.609308 seconds 
Time execution (load saved model): 0.002027 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 186
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

14.943984718322755

num_try : 604 | val_loss = 14.943984718322755 | val acc = 5.009431838989258
Time execution (tranning): 169.089972 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 537
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.034107360839844

num_try : 63 | val_loss = 15.034107360839844 | val acc = 7.947782039642334
Time execution (tranning): 76.443876 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.073005065917968

num_try : 595 | val_loss = 15.073005065917968 | val acc = 5.153570652008057
Time execution (tranning): 106.544904 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 349
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.096309585571289

num_try : 703 | val_loss = 15.096309585571289 | val acc = 5.216385364532471
Time execution (tranning): 139.925136 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000361 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 447
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.214079971313476

num_try : 243 | val_loss = 15.214079971313476 | val acc = 7.978654384613037
Time execution (tranning): 83.845967 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.224072246551513

num_try : 867 | val_loss = 15.224072246551513 | val acc = 4.2359514236450195
Time execution (tranning): 85.363958 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

15.241188106536866

num_try : 640 | val_loss = 15.241188106536866 | val acc = 5.0825934410095215
Time execution (tranning): 163.698890 seconds 
Time execution (load saved model): 0.002099 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 517
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.245552768707276

num_try : 712 | val_loss = 15.245552768707276 | val acc = 5.059763431549072
Time execution (tranning): 146.516530 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 463
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.262595119476318

num_try : 903 | val_loss = 15.262595119476318 | val acc = 4.267213344573975
Time execution (tranning): 79.435508 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

15.317360725402832

num_try : 27 | val_loss = 15.317360725402832 | val acc = 7.975033760070801
Time execution (tranning): 60.930243 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.34509708404541

num_try : 423 | val_loss = 15.34509708404541 | val acc = 8.038751602172852
Time execution (tranning): 110.515204 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 361
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.364464378356933

num_try : 541 | val_loss = 15.364464378356933 | val acc = 5.3409953117370605
Time execution (tranning): 56.722304 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.4127001953125

num_try : 631 | val_loss = 15.4127001953125 | val acc = 5.209091663360596
Time execution (tranning): 134.341806 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.479148578643798

num_try : 523 | val_loss = 15.479148578643798 | val acc = 5.336298942565918
Time execution (tranning): 164.885819 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 542
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.570061016082764

num_try : 397 | val_loss = 15.570061016082764 | val acc = 5.231181621551514
Time execution (tranning): 110.137485 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 366
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.578035564422608

num_try : 207 | val_loss = 15.578035564422608 | val acc = 8.072778701782227
Time execution (tranning): 78.384250 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.587556400299071

num_try : 676 | val_loss = 15.587556400299071 | val acc = 5.140861988067627
Time execution (tranning): 117.559385 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 371
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

15.771941375732421

num_try : 135 | val_loss = 15.771941375732421 | val acc = 8.130948066711426
Time execution (tranning): 62.726280 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.796835498809815

num_try : 795 | val_loss = 15.796835498809815 | val acc = 4.341717720031738
Time execution (tranning): 93.106958 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

15.931863384246826

num_try : 975 | val_loss = 15.931863384246826 | val acc = 4.3234171867370605
Time execution (tranning): 85.414622 seconds 
Time execution (load saved model): 0.002182 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

15.9969291305542

num_try : 759 | val_loss = 15.9969291305542 | val acc = 4.459791660308838
Time execution (tranning): 82.012808 seconds 
Time execution (load saved model): 0.002186 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.146513175964355

num_try : 948 | val_loss = 16.146513175964355 | val acc = 4.2855706214904785
Time execution (tranning): 88.147108 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.17229597091675

num_try : 505 | val_loss = 16.17229597091675 | val acc = 5.459661483764648
Time execution (tranning): 92.164690 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

16.18778242111206

num_try : 831 | val_loss = 16.18778242111206 | val acc = 4.398713111877441
Time execution (tranning): 58.447237 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.202915134429933

num_try : 615 | val_loss = 16.202915134429933 | val acc = 4.516061782836914
Time execution (tranning): 85.331662 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.321382656097413

num_try : 912 | val_loss = 16.321382656097413 | val acc = 4.409379959106445
Time execution (tranning): 97.726485 seconds 
Time execution (load saved model): 0.002181 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.347742614746092

num_try : 876 | val_loss = 16.347742614746092 | val acc = 4.3124308586120605
Time execution (tranning): 128.440551 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 370
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.37752878189087

num_try : 768 | val_loss = 16.37752878189087 | val acc = 4.380307674407959
Time execution (tranning): 101.701973 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.497471466064454

num_try : 957 | val_loss = 16.497471466064454 | val acc = 4.4959516525268555
Time execution (tranning): 134.044489 seconds 
Time execution (load saved model): 0.002240 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.621969985961915

num_try : 993 | val_loss = 16.621969985961915 | val acc = 4.492375373840332
Time execution (tranning): 139.750099 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.663780841827393

num_try : 984 | val_loss = 16.663780841827393 | val acc = 4.471548557281494
Time execution (tranning): 100.670304 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.66860736846924

num_try : 723 | val_loss = 16.66860736846924 | val acc = 4.515015125274658
Time execution (tranning): 87.948615 seconds 
Time execution (load saved model): 0.002116 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.7825888633728

num_try : 579 | val_loss = 16.7825888633728 | val acc = 4.562613487243652
Time execution (tranning): 92.002930 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

16.962479877471925

num_try : 786 | val_loss = 16.962479877471925 | val acc = 4.480318546295166
Time execution (tranning): 198.531728 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 610
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.09577375411987

num_try : 487 | val_loss = 17.09577375411987 | val acc = 5.654465198516846
Time execution (tranning): 157.626052 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 530
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.101743469238283

num_try : 921 | val_loss = 17.101743469238283 | val acc = 4.617469310760498
Time execution (tranning): 204.912166 seconds 
Time execution (load saved model): 0.002164 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 610
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.29345283508301

num_try : 325 | val_loss = 17.29345283508301 | val acc = 5.672374725341797
Time execution (tranning): 97.075667 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 320
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.296017990112304

num_try : 667 | val_loss = 17.296017990112304 | val acc = 5.679707050323486
Time execution (tranning): 79.276902 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.34971128463745

num_try : 451 | val_loss = 17.34971128463745 | val acc = 5.698884963989258
Time execution (tranning): 124.433185 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 407
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.356178150177

num_try : 624 | val_loss = 17.356178150177 | val acc = 4.613002300262451
Time execution (tranning): 108.212395 seconds 
Time execution (load saved model): 0.002129 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.400510787963867

num_try : 866 | val_loss = 17.400510787963867 | val acc = 4.314169406890869
Time execution (tranning): 83.618219 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

17.49881669998169

num_try : 902 | val_loss = 17.49881669998169 | val acc = 4.328580856323242
Time execution (tranning): 97.942710 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

17.5112308883667

num_try : 145 | val_loss = 17.5112308883667 | val acc = 5.802038669586182
Time execution (tranning): 57.437866 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.56079267501831

num_try : 732 | val_loss = 17.56079267501831 | val acc = 4.553127288818359
Time execution (tranning): 117.796190 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.577104873657227

num_try : 1 | val_loss = 17.577104873657227 | val acc = 5.930826187133789
Time execution (tranning): 80.999624 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.629009666442872

num_try : 966 | val_loss = 17.629009666442872 | val acc = 4.605830192565918
Time execution (tranning): 122.641446 seconds 
Time execution (load saved model): 0.002141 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 359
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.63931812286377

num_try : 804 | val_loss = 17.63931812286377 | val acc = 4.628699779510498
Time execution (tranning): 78.763964 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.64389207839966

num_try : 974 | val_loss = 17.64389207839966 | val acc = 4.302037715911865
Time execution (tranning): 76.244937 seconds 
Time execution (load saved model): 0.002168 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

17.651294326782228

num_try : 696 | val_loss = 17.651294326782228 | val acc = 4.626360893249512
Time execution (tranning): 86.095261 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.668416919708253

num_try : 930 | val_loss = 17.668416919708253 | val acc = 4.606052398681641
Time execution (tranning): 143.473186 seconds 
Time execution (load saved model): 0.002168 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 402
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.686126136779784

num_try : 217 | val_loss = 17.686126136779784 | val acc = 5.82862663269043
Time execution (tranning): 107.764323 seconds 
Time execution (load saved model): 0.002030 seconds 
Time execution (use saved model): 0.000213 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 347
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

17.883292293548585

num_try : 1002 | val_loss = 17.883292293548585 | val acc = 4.679102897644043
Time execution (tranning): 151.903264 seconds 
Time execution (load saved model): 0.002161 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 429
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

17.934333591461183

num_try : 794 | val_loss = 17.934333591461183 | val acc = 4.401132583618164
Time execution (tranning): 99.303344 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

17.944169902801512

num_try : 660 | val_loss = 17.944169902801512 | val acc = 4.683671951293945
Time execution (tranning): 79.265236 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.000604972839355

num_try : 938 | val_loss = 18.000604972839355 | val acc = 4.3781514167785645
Time execution (tranning): 92.164724 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000244 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.085540885925294

num_try : 840 | val_loss = 18.085540885925294 | val acc = 4.667500972747803
Time execution (tranning): 86.687267 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.096686038970947

num_try : 983 | val_loss = 18.096686038970947 | val acc = 4.334502696990967
Time execution (tranning): 85.653457 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.10024103164673

num_try : 289 | val_loss = 18.10024103164673 | val acc = 5.887631893157959
Time execution (tranning): 81.065997 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

18.100604782104494

num_try : 651 | val_loss = 18.100604782104494 | val acc = 4.8261284828186035
Time execution (tranning): 87.186883 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.103840465545655

num_try : 894 | val_loss = 18.103840465545655 | val acc = 4.694686412811279
Time execution (tranning): 119.508623 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.13117832183838

num_try : 875 | val_loss = 18.13117832183838 | val acc = 4.393011569976807
Time execution (tranning): 113.842909 seconds 
Time execution (load saved model): 0.002240 seconds 
Time execution (use saved model): 0.000244 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.176864585876466

num_try : 777 | val_loss = 18.176864585876466 | val acc = 4.8478193283081055
Time execution (tranning): 122.925952 seconds 
Time execution (load saved model): 0.002097 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 393
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.192678565979005

num_try : 687 | val_loss = 18.192678565979005 | val acc = 4.913524627685547
Time execution (tranning): 80.027468 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.31171745300293

num_try : 920 | val_loss = 18.31171745300293 | val acc = 4.4646782875061035
Time execution (tranning): 152.138703 seconds 
Time execution (load saved model): 0.002165 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 451
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.315696048736573

num_try : 830 | val_loss = 18.315696048736573 | val acc = 4.49912691116333
Time execution (tranning): 93.977841 seconds 
Time execution (load saved model): 0.002130 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 296
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.316804313659667

num_try : 939 | val_loss = 18.316804313659667 | val acc = 5.042132377624512
Time execution (tranning): 84.760713 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000244 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.37839867591858

num_try : 750 | val_loss = 18.37839867591858 | val acc = 4.688638210296631
Time execution (tranning): 129.152517 seconds 
Time execution (load saved model): 0.002129 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 399
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.409161338806154

num_try : 947 | val_loss = 18.409161338806154 | val acc = 4.409688472747803
Time execution (tranning): 100.969226 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.455441551208494

num_try : 885 | val_loss = 18.455441551208494 | val acc = 4.948614597320557
Time execution (tranning): 108.343276 seconds 
Time execution (load saved model): 0.002207 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.54401170730591

num_try : 559 | val_loss = 18.54401170730591 | val acc = 5.965054988861084
Time execution (tranning): 88.419879 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

18.56043773651123

num_try : 911 | val_loss = 18.56043773651123 | val acc = 4.411536693572998
Time execution (tranning): 90.217636 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.567838134765626

num_try : 588 | val_loss = 18.567838134765626 | val acc = 4.793825149536133
Time execution (tranning): 90.710835 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.671919918060304

num_try : 415 | val_loss = 18.671919918060304 | val acc = 6.140923023223877
Time execution (tranning): 118.954288 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 399
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

18.68885185241699

num_try : 578 | val_loss = 18.68885185241699 | val acc = 4.574301242828369
Time execution (tranning): 101.547885 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.6916934967041

num_try : 992 | val_loss = 18.6916934967041 | val acc = 4.528021335601807
Time execution (tranning): 130.412504 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 381
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.706095371246338

num_try : 858 | val_loss = 18.706095371246338 | val acc = 4.81456995010376
Time execution (tranning): 103.583370 seconds 
Time execution (load saved model): 0.002139 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.728419494628906

num_try : 261 | val_loss = 18.728419494628906 | val acc = 9.068641662597656
Time execution (tranning): 76.103484 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

18.760233783721922

num_try : 741 | val_loss = 18.760233783721922 | val acc = 4.926340579986572
Time execution (tranning): 131.606180 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 416
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.779737548828123

num_try : 822 | val_loss = 18.779737548828123 | val acc = 4.807338714599609
Time execution (tranning): 134.484954 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 414
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.818170490264894

num_try : 633 | val_loss = 18.818170490264894 | val acc = 4.919955730438232
Time execution (tranning): 150.717119 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 488
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

18.837221527099608

num_try : 478 | val_loss = 18.837221527099608 | val acc = 5.9734721183776855
Time execution (tranning): 93.512946 seconds 
Time execution (load saved model): 0.002116 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

18.88136442184448

num_try : 235 | val_loss = 18.88136442184448 | val acc = 6.2535810470581055
Time execution (tranning): 132.086064 seconds 
Time execution (load saved model): 0.002020 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 452
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

18.90565441131592

num_try : 722 | val_loss = 18.90565441131592 | val acc = 4.60790491104126
Time execution (tranning): 54.802270 seconds 
Time execution (load saved model): 0.002114 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 170
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.91638391494751

num_try : 956 | val_loss = 18.91638391494751 | val acc = 4.624532699584961
Time execution (tranning): 133.176795 seconds 
Time execution (load saved model): 0.002171 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 394
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

18.941250839233398

num_try : 225 | val_loss = 18.941250839233398 | val acc = 9.195520401000977
Time execution (tranning): 56.666350 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 186
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

18.97017059326172

num_try : 803 | val_loss = 18.97017059326172 | val acc = 4.485273838043213
Time execution (tranning): 75.981122 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.022902412414552

num_try : 813 | val_loss = 19.022902412414552 | val acc = 5.018220901489258
Time execution (tranning): 139.227243 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

19.063829193115236

num_try : 163 | val_loss = 19.063829193115236 | val acc = 6.169038772583008
Time execution (tranning): 106.216325 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

19.08076789855957

num_try : 442 | val_loss = 19.08076789855957 | val acc = 5.9522294998168945
Time execution (tranning): 74.113035 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

19.085414028167726

num_try : 740 | val_loss = 19.085414028167726 | val acc = 4.720032691955566
Time execution (tranning): 146.054124 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 468
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.101782608032227

num_try : 514 | val_loss = 19.101782608032227 | val acc = 6.1328206062316895
Time execution (tranning): 110.824302 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

19.205534553527833

num_try : 543 | val_loss = 19.205534553527833 | val acc = 5.077319622039795
Time execution (tranning): 96.714727 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

19.290516014099122

num_try : 929 | val_loss = 19.290516014099122 | val acc = 4.576675891876221
Time execution (tranning): 157.373396 seconds 
Time execution (load saved model): 0.002162 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 443
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.336267776489258

num_try : 19 | val_loss = 19.336267776489258 | val acc = 6.376338958740234
Time execution (tranning): 116.141761 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 390
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

19.449951915740968

num_try : 1001 | val_loss = 19.449951915740968 | val acc = 4.566234588623047
Time execution (tranning): 118.539339 seconds 
Time execution (load saved model): 0.002168 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.491059722900392

num_try : 435 | val_loss = 19.491059722900392 | val acc = 5.136051177978516
Time execution (tranning): 86.511215 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

19.545604152679445

num_try : 758 | val_loss = 19.545604152679445 | val acc = 4.667373180389404
Time execution (tranning): 64.775660 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.598055381774902

num_try : 849 | val_loss = 19.598055381774902 | val acc = 5.084714889526367
Time execution (tranning): 92.866203 seconds 
Time execution (load saved model): 0.002112 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

19.633999519348144

num_try : 821 | val_loss = 19.633999519348144 | val acc = 4.596918106079102
Time execution (tranning): 147.178798 seconds 
Time execution (load saved model): 0.002113 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 453
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.64205856323242

num_try : 749 | val_loss = 19.64205856323242 | val acc = 4.5917229652404785
Time execution (tranning): 147.632192 seconds 
Time execution (load saved model): 0.002189 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 453
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.677358932495117

num_try : 965 | val_loss = 19.677358932495117 | val acc = 4.69730806350708
Time execution (tranning): 127.186728 seconds 
Time execution (load saved model): 0.002139 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 373
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.787155780792236

num_try : 587 | val_loss = 19.787155780792236 | val acc = 4.658573150634766
Time execution (tranning): 88.704722 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.8555286026001

num_try : 884 | val_loss = 19.8555286026001 | val acc = 4.696967124938965
Time execution (tranning): 126.355474 seconds 
Time execution (load saved model): 0.002141 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 379
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

19.867882385253907

num_try : 614 | val_loss = 19.867882385253907 | val acc = 4.889082431793213
Time execution (tranning): 93.713865 seconds 
Time execution (load saved model): 0.002158 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.027553329467775

num_try : 767 | val_loss = 20.027553329467775 | val acc = 4.579239368438721
Time execution (tranning): 87.506332 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.042483673095703

num_try : 597 | val_loss = 20.042483673095703 | val acc = 5.235383987426758
Time execution (tranning): 133.167456 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

20.064444770812987

num_try : 650 | val_loss = 20.064444770812987 | val acc = 4.889665126800537
Time execution (tranning): 66.287980 seconds 
Time execution (load saved model): 0.002093 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.15232837677002

num_try : 785 | val_loss = 20.15232837677002 | val acc = 4.627572536468506
Time execution (tranning): 139.152233 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 432
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.15739227294922

num_try : 776 | val_loss = 20.15739227294922 | val acc = 4.8499860763549805
Time execution (tranning): 130.658564 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.215859794616698

num_try : 839 | val_loss = 20.215859794616698 | val acc = 4.69592809677124
Time execution (tranning): 72.005899 seconds 
Time execution (load saved model): 0.002118 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.22239261627197

num_try : 507 | val_loss = 20.22239261627197 | val acc = 5.371666431427002
Time execution (tranning): 108.302065 seconds 
Time execution (load saved model): 0.002068 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 356
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

20.24672103881836

num_try : 686 | val_loss = 20.24672103881836 | val acc = 4.796588897705078
Time execution (tranning): 51.021690 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 165
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.279869079589844

num_try : 848 | val_loss = 20.279869079589844 | val acc = 4.8418474197387695
Time execution (tranning): 121.587665 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 386
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.28906925201416

num_try : 154 | val_loss = 20.28906925201416 | val acc = 6.573409557342529
Time execution (tranning): 85.209320 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

20.39209857940674

num_try : 659 | val_loss = 20.39209857940674 | val acc = 4.776568412780762
Time execution (tranning): 89.731914 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.52845516204834

num_try : 361 | val_loss = 20.52845516204834 | val acc = 6.441704273223877
Time execution (tranning): 96.248597 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

20.563148269653322

num_try : 606 | val_loss = 20.563148269653322 | val acc = 5.178322792053223
Time execution (tranning): 154.438062 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 490
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

20.597376861572265

num_try : 623 | val_loss = 20.597376861572265 | val acc = 4.730976581573486
Time execution (tranning): 88.915295 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.665833568573

num_try : 893 | val_loss = 20.665833568573 | val acc = 4.796076774597168
Time execution (tranning): 118.892942 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

20.707982330322267

num_try : 705 | val_loss = 20.707982330322267 | val acc = 5.332396030426025
Time execution (tranning): 116.624198 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 376
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

20.75338981628418

num_try : 399 | val_loss = 20.75338981628418 | val acc = 5.434945583343506
Time execution (tranning): 76.449328 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

20.84031894683838

num_try : 37 | val_loss = 20.84031894683838 | val acc = 6.473268985748291
Time execution (tranning): 76.930140 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 257
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

20.94307189941406

num_try : 460 | val_loss = 20.94307189941406 | val acc = 6.408487319946289
Time execution (tranning): 107.859904 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

20.98224784851074

num_try : 695 | val_loss = 20.98224784851074 | val acc = 4.8651604652404785
Time execution (tranning): 91.159278 seconds 
Time execution (load saved model): 0.002080 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

21.086239852905273

num_try : 525 | val_loss = 21.086239852905273 | val acc = 5.3560791015625
Time execution (tranning): 160.868829 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 531
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.139076805114748

num_try : 471 | val_loss = 21.139076805114748 | val acc = 5.385317325592041
Time execution (tranning): 82.295689 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.301547317504884

num_try : 379 | val_loss = 21.301547317504884 | val acc = 6.6018900871276855
Time execution (tranning): 107.705168 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

21.312422943115234

num_try : 552 | val_loss = 21.312422943115234 | val acc = 5.344257354736328
Time execution (tranning): 131.578305 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 430
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.425541763305663

num_try : 181 | val_loss = 21.425541763305663 | val acc = 6.44882345199585
Time execution (tranning): 91.123626 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

21.49769691467285

num_try : 453 | val_loss = 21.49769691467285 | val acc = 5.520191669464111
Time execution (tranning): 132.416348 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.51694013595581

num_try : 470 | val_loss = 21.51694013595581 | val acc = 5.2208170890808105
Time execution (tranning): 115.608706 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 384
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

21.520423774719237

num_try : 812 | val_loss = 21.520423774719237 | val acc = 5.060126781463623
Time execution (tranning): 131.515810 seconds 
Time execution (load saved model): 0.002104 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 424
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

21.535817527770995

num_try : 678 | val_loss = 21.535817527770995 | val acc = 5.38018798828125
Time execution (tranning): 153.899058 seconds 
Time execution (load saved model): 0.002075 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 487
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.548713607788088

num_try : 91 | val_loss = 21.548713607788088 | val acc = 6.9520463943481445
Time execution (tranning): 127.279241 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 430
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

21.65767322540283

num_try : 298 | val_loss = 21.65767322540283 | val acc = 6.757319927215576
Time execution (tranning): 74.601967 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

21.66643009185791

num_try : 669 | val_loss = 21.66643009185791 | val acc = 5.5211873054504395
Time execution (tranning): 109.209629 seconds 
Time execution (load saved model): 0.002078 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

21.794331970214845

num_try : 731 | val_loss = 21.794331970214845 | val acc = 5.010797500610352
Time execution (tranning): 96.324706 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

21.854152641296388

num_try : 199 | val_loss = 21.854152641296388 | val acc = 6.773644924163818
Time execution (tranning): 129.301043 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 434
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

22.186896362304687

num_try : 334 | val_loss = 22.186896362304687 | val acc = 6.872342109680176
Time execution (tranning): 99.423200 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

22.344858589172365

num_try : 127 | val_loss = 22.344858589172365 | val acc = 7.027429103851318
Time execution (tranning): 126.245412 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 427
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

22.44066509246826

num_try : 255 | val_loss = 22.44066509246826 | val acc = 5.753416538238525
Time execution (tranning): 79.757859 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

22.449175758361818

num_try : 568 | val_loss = 22.449175758361818 | val acc = 6.898988723754883
Time execution (tranning): 119.141537 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 386
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

22.455963706970216

num_try : 713 | val_loss = 22.455963706970216 | val acc = 5.135284423828125
Time execution (tranning): 157.066696 seconds 
Time execution (load saved model): 0.002104 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 498
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

22.58231391906738

num_try : 542 | val_loss = 22.58231391906738 | val acc = 5.269915580749512
Time execution (tranning): 80.674783 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

22.87347743988037

num_try : 857 | val_loss = 22.87347743988037 | val acc = 5.123411178588867
Time execution (tranning): 99.985326 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

22.91160041809082

num_try : 596 | val_loss = 22.91160041809082 | val acc = 5.392757415771484
Time execution (tranning): 165.902267 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 541
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

22.92092487335205

num_try : 271 | val_loss = 22.92092487335205 | val acc = 7.137932777404785
Time execution (tranning): 110.687528 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 372
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.090865859985353

num_try : 642 | val_loss = 23.090865859985353 | val acc = 5.633586406707764
Time execution (tranning): 105.746505 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

23.105451393127442

num_try : 632 | val_loss = 23.105451393127442 | val acc = 5.288622856140137
Time execution (tranning): 138.630953 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 448
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.120444564819337

num_try : 506 | val_loss = 23.120444564819337 | val acc = 5.34162712097168
Time execution (tranning): 77.636116 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.1536092376709

num_try : 550 | val_loss = 23.1536092376709 | val acc = 6.959695816040039
Time execution (tranning): 94.212499 seconds 
Time execution (load saved model): 0.002078 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.173211059570313

num_try : 73 | val_loss = 23.173211059570313 | val acc = 6.829766273498535
Time execution (tranning): 72.428911 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.177024726867675

num_try : 561 | val_loss = 23.177024726867675 | val acc = 5.709386825561523
Time execution (tranning): 147.167923 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 495
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

23.2705908203125

num_try : 343 | val_loss = 23.2705908203125 | val acc = 7.132293701171875
Time execution (tranning): 98.061121 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.34859992980957

num_try : 291 | val_loss = 23.34859992980957 | val acc = 5.788900852203369
Time execution (tranning): 127.493998 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 423
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

23.596202850341797

num_try : 370 | val_loss = 23.596202850341797 | val acc = 7.104179859161377
Time execution (tranning): 110.965774 seconds 
Time execution (load saved model): 0.002023 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 368
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.62354175567627

num_try : 668 | val_loss = 23.62354175567627 | val acc = 5.452603816986084
Time execution (tranning): 122.233917 seconds 
Time execution (load saved model): 0.002076 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 394
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.640981636047364

num_try : 714 | val_loss = 23.640981636047364 | val acc = 5.729274272918701
Time execution (tranning): 101.089824 seconds 
Time execution (load saved model): 0.002088 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 320
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

23.687123680114745

num_try : 109 | val_loss = 23.687123680114745 | val acc = 6.988994121551514
Time execution (tranning): 71.746838 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

23.81886344909668

num_try : 677 | val_loss = 23.81886344909668 | val acc = 5.311861515045166
Time execution (tranning): 144.570333 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 458
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.91916820526123

num_try : 488 | val_loss = 23.91916820526123 | val acc = 5.451227188110352
Time execution (tranning): 120.208557 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 404
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.940906524658203

num_try : 605 | val_loss = 23.940906524658203 | val acc = 5.371793746948242
Time execution (tranning): 151.946563 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 481
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

23.971520881652832

num_try : 489 | val_loss = 23.971520881652832 | val acc = 5.877387523651123
Time execution (tranning): 120.796427 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 404
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

24.08382221221924

num_try : 551 | val_loss = 24.08382221221924 | val acc = 5.501748561859131
Time execution (tranning): 83.614087 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.139629096984862

num_try : 434 | val_loss = 24.139629096984862 | val acc = 5.541218280792236
Time execution (tranning): 75.391642 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.159819259643555

num_try : 363 | val_loss = 24.159819259643555 | val acc = 5.865504264831543
Time execution (tranning): 110.349587 seconds 
Time execution (load saved model): 0.002085 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 374
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

24.2301815032959

num_try : 444 | val_loss = 24.2301815032959 | val acc = 6.017800331115723
Time execution (tranning): 93.931831 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

24.315195579528808

num_try : 479 | val_loss = 24.315195579528808 | val acc = 5.520176410675049
Time execution (tranning): 84.037553 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.362371520996092

num_try : 452 | val_loss = 24.362371520996092 | val acc = 5.632680892944336
Time execution (tranning): 170.356359 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 557
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.470700721740723

num_try : 352 | val_loss = 24.470700721740723 | val acc = 7.260507583618164
Time execution (tranning): 86.769186 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.476273002624513

num_try : 398 | val_loss = 24.476273002624513 | val acc = 5.588500499725342
Time execution (tranning): 85.343913 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.495535202026367

num_try : 190 | val_loss = 24.495535202026367 | val acc = 7.211118698120117
Time execution (tranning): 61.004177 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.553597869873048

num_try : 39 | val_loss = 24.553597869873048 | val acc = 5.996043682098389
Time execution (tranning): 90.186134 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

24.68148536682129

num_try : 183 | val_loss = 24.68148536682129 | val acc = 5.996217727661133
Time execution (tranning): 85.331891 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

24.691990127563475

num_try : 253 | val_loss = 24.691990127563475 | val acc = 7.173486709594727
Time execution (tranning): 71.661048 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.742714233398438

num_try : 704 | val_loss = 24.742714233398438 | val acc = 5.570883750915527
Time execution (tranning): 86.590613 seconds 
Time execution (load saved model): 0.002088 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

24.758109664916994

num_try : 262 | val_loss = 24.758109664916994 | val acc = 7.310402870178223
Time execution (tranning): 61.612920 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 203
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.888745956420898

num_try : 307 | val_loss = 24.888745956420898 | val acc = 7.360540390014648
Time execution (tranning): 62.648367 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.93075366973877

num_try : 118 | val_loss = 24.93075366973877 | val acc = 7.456223964691162
Time execution (tranning): 120.091398 seconds 
Time execution (load saved model): 0.002119 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

24.944135360717773

num_try : 560 | val_loss = 24.944135360717773 | val acc = 5.742738246917725
Time execution (tranning): 95.353848 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

25.07377201080322

num_try : 254 | val_loss = 25.07377201080322 | val acc = 5.719121932983398
Time execution (tranning): 80.056540 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

25.111672897338867

num_try : 172 | val_loss = 25.111672897338867 | val acc = 7.378299713134766
Time execution (tranning): 105.099384 seconds 
Time execution (load saved model): 0.002023 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 350
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

25.18627326965332

num_try : 388 | val_loss = 25.18627326965332 | val acc = 7.375611782073975
Time execution (tranning): 113.144095 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 372
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

25.25326030731201

num_try : 641 | val_loss = 25.25326030731201 | val acc = 5.683794975280762
Time execution (tranning): 160.643188 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 508
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

25.341854438781738

num_try : 147 | val_loss = 25.341854438781738 | val acc = 6.069253444671631
Time execution (tranning): 81.091113 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.454387702941894

num_try : 46 | val_loss = 25.454387702941894 | val acc = 7.524305820465088
Time execution (tranning): 69.787444 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

25.473640480041503

num_try : 280 | val_loss = 25.473640480041503 | val acc = 7.382951736450195
Time execution (tranning): 75.237382 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

25.507452278137208

num_try : 182 | val_loss = 25.507452278137208 | val acc = 5.787092208862305
Time execution (tranning): 75.672609 seconds 
Time execution (load saved model): 0.002020 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

25.51188259124756

num_try : 516 | val_loss = 25.51188259124756 | val acc = 6.1493916511535645
Time execution (tranning): 86.354066 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.599701652526857

num_try : 290 | val_loss = 25.599701652526857 | val acc = 5.786956787109375
Time execution (tranning): 94.886127 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

25.604566192626955

num_try : 237 | val_loss = 25.604566192626955 | val acc = 6.330479621887207
Time execution (tranning): 129.526749 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 442
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.607666511535644

num_try : 165 | val_loss = 25.607666511535644 | val acc = 6.321598052978516
Time execution (tranning): 81.972692 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.609823799133302

num_try : 327 | val_loss = 25.609823799133302 | val acc = 6.1869659423828125
Time execution (tranning): 109.065740 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 361
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.62880973815918

num_try : 534 | val_loss = 25.62880973815918 | val acc = 6.089257717132568
Time execution (tranning): 95.605909 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

25.92624408721924

num_try : 55 | val_loss = 25.92624408721924 | val acc = 7.558205604553223
Time execution (tranning): 69.352701 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

25.95298179626465

num_try : 309 | val_loss = 25.95298179626465 | val acc = 6.3789777755737305
Time execution (tranning): 99.877502 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 333
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

26.161897392272948

num_try : 524 | val_loss = 26.161897392272948 | val acc = 5.792038440704346
Time execution (tranning): 168.702004 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 556
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

26.340302124023438

num_try : 443 | val_loss = 26.340302124023438 | val acc = 5.908202648162842
Time execution (tranning): 101.186320 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

26.431502227783202

num_try : 515 | val_loss = 26.431502227783202 | val acc = 5.883328437805176
Time execution (tranning): 123.928458 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 405
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

26.450729179382325

num_try : 218 | val_loss = 26.450729179382325 | val acc = 5.85385274887085
Time execution (tranning): 91.106994 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000212 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

26.65971431732178

num_try : 244 | val_loss = 26.65971431732178 | val acc = 7.652180194854736
Time execution (tranning): 73.421419 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

26.800608711242674

num_try : 10 | val_loss = 26.800608711242674 | val acc = 7.7672834396362305
Time execution (tranning): 61.384170 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

26.811686363220215

num_try : 480 | val_loss = 26.811686363220215 | val acc = 6.265125751495361
Time execution (tranning): 89.810859 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

26.87098533630371

num_try : 74 | val_loss = 26.87098533630371 | val acc = 5.974559783935547
Time execution (tranning): 93.659726 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

27.142734298706056

num_try : 316 | val_loss = 27.142734298706056 | val acc = 7.709414005279541
Time execution (tranning): 102.664398 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.152403564453124

num_try : 496 | val_loss = 27.152403564453124 | val acc = 7.711074352264404
Time execution (tranning): 70.737776 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.25722728729248

num_try : 56 | val_loss = 27.25722728729248 | val acc = 6.207127094268799
Time execution (tranning): 157.403370 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 530
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

27.419202880859373

num_try : 38 | val_loss = 27.419202880859373 | val acc = 6.119304656982422
Time execution (tranning): 73.313590 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

27.457830200195314

num_try : 532 | val_loss = 27.457830200195314 | val acc = 7.747368335723877
Time execution (tranning): 88.333684 seconds 
Time execution (load saved model): 0.002068 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.54695121765137

num_try : 136 | val_loss = 27.54695121765137 | val acc = 7.775179862976074
Time execution (tranning): 75.682659 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.55320602416992

num_try : 28 | val_loss = 27.55320602416992 | val acc = 7.860558032989502
Time execution (tranning): 95.478952 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.6175244140625

num_try : 100 | val_loss = 27.6175244140625 | val acc = 7.791593074798584
Time execution (tranning): 73.058919 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

27.7362850189209

num_try : 362 | val_loss = 27.7362850189209 | val acc = 5.969638824462891
Time execution (tranning): 73.467443 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

28.134034843444823

num_try : 424 | val_loss = 28.134034843444823 | val acc = 7.8929123878479
Time execution (tranning): 63.895926 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

28.326742515563964

num_try : 308 | val_loss = 28.326742515563964 | val acc = 6.242427825927734
Time execution (tranning): 98.301837 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

28.339859085083006

num_try : 406 | val_loss = 28.339859085083006 | val acc = 7.853612899780273
Time execution (tranning): 57.592182 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 186
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

28.38086093902588

num_try : 326 | val_loss = 28.38086093902588 | val acc = 6.07978630065918
Time execution (tranning): 67.835832 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

28.473076362609863

num_try : 498 | val_loss = 28.473076362609863 | val acc = 6.566880702972412
Time execution (tranning): 101.773062 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

28.501123352050783

num_try : 156 | val_loss = 28.501123352050783 | val acc = 6.8161163330078125
Time execution (tranning): 95.880898 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

28.547171859741212

num_try : 226 | val_loss = 28.547171859741212 | val acc = 7.911854267120361
Time execution (tranning): 65.995245 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

28.68807918548584

num_try : 146 | val_loss = 28.68807918548584 | val acc = 6.0807204246521
Time execution (tranning): 72.040278 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

28.721868171691895

num_try : 208 | val_loss = 28.721868171691895 | val acc = 7.9113569259643555
Time execution (tranning): 75.789907 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

28.97320960998535

num_try : 904 | val_loss = 28.97320960998535 | val acc = 4.317245960235596
Time execution (tranning): 102.814825 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

29.050751914978026

num_try : 371 | val_loss = 29.050751914978026 | val acc = 6.256083965301514
Time execution (tranning): 75.421726 seconds 
Time execution (load saved model): 0.002029 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

29.24313076019287

num_try : 64 | val_loss = 29.24313076019287 | val acc = 8.060975074768066
Time execution (tranning): 66.666363 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

29.35778350830078

num_try : 868 | val_loss = 29.35778350830078 | val acc = 4.269869327545166
Time execution (tranning): 106.942116 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

29.516826820373534

num_try : 832 | val_loss = 29.516826820373534 | val acc = 4.334255695343018
Time execution (tranning): 68.010040 seconds 
Time execution (load saved model): 0.002116 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

29.559873962402342

num_try : 272 | val_loss = 29.559873962402342 | val acc = 6.537659168243408
Time execution (tranning): 92.666740 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

29.697800064086913

num_try : 128 | val_loss = 29.697800064086913 | val acc = 6.638331890106201
Time execution (tranning): 100.365632 seconds 
Time execution (load saved model): 0.002104 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

29.739971694946288

num_try : 417 | val_loss = 29.739971694946288 | val acc = 6.8819708824157715
Time execution (tranning): 99.861685 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

29.807971115112306

num_try : 164 | val_loss = 29.807971115112306 | val acc = 6.46187686920166
Time execution (tranning): 119.178442 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 399
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

29.81153579711914

num_try : 760 | val_loss = 29.81153579711914 | val acc = 4.439480781555176
Time execution (tranning): 90.380526 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

29.952112464904786

num_try : 940 | val_loss = 29.952112464904786 | val acc = 4.343191146850586
Time execution (tranning): 102.651221 seconds 
Time execution (load saved model): 0.002182 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

29.9783642578125

num_try : 93 | val_loss = 29.9783642578125 | val acc = 7.080136299133301
Time execution (tranning): 95.778758 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.03929447174072

num_try : 264 | val_loss = 30.03929447174072 | val acc = 6.9855637550354
Time execution (tranning): 76.653464 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.144765129089354

num_try : 870 | val_loss = 30.144765129089354 | val acc = 4.222606182098389
Time execution (tranning): 79.968449 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

30.36768383026123

num_try : 976 | val_loss = 30.36768383026123 | val acc = 4.422286510467529
Time execution (tranning): 70.279230 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

30.40758129119873

num_try : 300 | val_loss = 30.40758129119873 | val acc = 7.0047831535339355
Time execution (tranning): 83.401556 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.466216621398925

num_try : 344 | val_loss = 30.466216621398925 | val acc = 6.612890243530273
Time execution (tranning): 113.249538 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

30.53697624206543

num_try : 949 | val_loss = 30.53697624206543 | val acc = 4.373316764831543
Time execution (tranning): 118.393637 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

30.588248672485353

num_try : 381 | val_loss = 30.588248672485353 | val acc = 7.0315165519714355
Time execution (tranning): 83.116929 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.636610870361327

num_try : 408 | val_loss = 30.636610870361327 | val acc = 7.05152702331543
Time execution (tranning): 94.073429 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.64352693557739

num_try : 942 | val_loss = 30.64352693557739 | val acc = 4.237473011016846
Time execution (tranning): 65.433603 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

30.64726909637451

num_try : 877 | val_loss = 30.64726909637451 | val acc = 4.341183662414551
Time execution (tranning): 82.630068 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

30.67045364379883

num_try : 407 | val_loss = 30.67045364379883 | val acc = 6.5442962646484375
Time execution (tranning): 83.336922 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

30.76607192993164

num_try : 345 | val_loss = 30.76607192993164 | val acc = 7.092433452606201
Time execution (tranning): 141.380260 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 468
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.772438049316406

num_try : 201 | val_loss = 30.772438049316406 | val acc = 7.167798042297363
Time execution (tranning): 150.830189 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 507
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.772604026794433

num_try : 354 | val_loss = 30.772604026794433 | val acc = 7.061070442199707
Time execution (tranning): 103.723222 seconds 
Time execution (load saved model): 0.002027 seconds 
Time execution (use saved model): 0.000281 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

30.92837291717529

num_try : 913 | val_loss = 30.92837291717529 | val acc = 4.451756477355957
Time execution (tranning): 126.842623 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 356
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

31.14992000579834

num_try : 724 | val_loss = 31.14992000579834 | val acc = 4.544534683227539
Time execution (tranning): 97.874687 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

31.15644645690918

num_try : 906 | val_loss = 31.15644645690918 | val acc = 4.326578140258789
Time execution (tranning): 64.088355 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.195244941711426

num_try : 978 | val_loss = 31.195244941711426 | val acc = 4.416473865509033
Time execution (tranning): 94.982482 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.241354064941405

num_try : 3 | val_loss = 31.241354064941405 | val acc = 7.045299053192139
Time execution (tranning): 70.727022 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.24402297973633

num_try : 318 | val_loss = 31.24402297973633 | val acc = 7.117495536804199
Time execution (tranning): 142.522956 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 471
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.247375144958497

num_try : 805 | val_loss = 31.247375144958497 | val acc = 4.491954803466797
Time execution (tranning): 96.347428 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

31.314178352355956

num_try : 336 | val_loss = 31.314178352355956 | val acc = 7.123809337615967
Time execution (tranning): 79.517634 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.36827205657959

num_try : 570 | val_loss = 31.36827205657959 | val acc = 7.102679252624512
Time execution (tranning): 98.408139 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.461152229309082

num_try : 931 | val_loss = 31.461152229309082 | val acc = 4.458786487579346
Time execution (tranning): 155.735188 seconds 
Time execution (load saved model): 0.002168 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 442
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

31.661484680175782

num_try : 174 | val_loss = 31.661484680175782 | val acc = 7.1497578620910645
Time execution (tranning): 118.260122 seconds 
Time execution (load saved model): 0.002022 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 393
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.73903491973877

num_try : 933 | val_loss = 31.73903491973877 | val acc = 4.319302558898926
Time execution (tranning): 166.198768 seconds 
Time execution (load saved model): 0.002157 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 471
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.782864532470704

num_try : 57 | val_loss = 31.782864532470704 | val acc = 7.264845371246338
Time execution (tranning): 78.878589 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.851790771484374

num_try : 879 | val_loss = 31.851790771484374 | val acc = 4.374608516693115
Time execution (tranning): 111.047590 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.862384643554687

num_try : 219 | val_loss = 31.862384643554687 | val acc = 7.059470176696777
Time execution (tranning): 66.639454 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

31.885002670288085

num_try : 798 | val_loss = 31.885002670288085 | val acc = 4.469098091125488
Time execution (tranning): 87.310841 seconds 
Time execution (load saved model): 0.002105 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.897764015197755

num_try : 834 | val_loss = 31.897764015197755 | val acc = 4.478274345397949
Time execution (tranning): 101.514205 seconds 
Time execution (load saved model): 0.002112 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

31.92985591888428

num_try : 985 | val_loss = 31.92985591888428 | val acc = 4.508705139160156
Time execution (tranning): 114.504298 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

31.994618377685548

num_try : 859 | val_loss = 31.994618377685548 | val acc = 4.466728210449219
Time execution (tranning): 187.285855 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 576
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.08986179351807

num_try : 951 | val_loss = 32.08986179351807 | val acc = 4.386199951171875
Time execution (tranning): 113.357548 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.22808624267578

num_try : 616 | val_loss = 32.22808624267578 | val acc = 4.620115756988525
Time execution (tranning): 88.983792 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000278 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.25650779724121

num_try : 841 | val_loss = 32.25650779724121 | val acc = 4.529646873474121
Time execution (tranning): 112.565182 seconds 
Time execution (load saved model): 0.002117 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.27655601501465

num_try : 390 | val_loss = 32.27655601501465 | val acc = 7.240846157073975
Time execution (tranning): 91.462788 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.284508895874026

num_try : 582 | val_loss = 32.284508895874026 | val acc = 4.540040969848633
Time execution (tranning): 116.006992 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 379
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.29775722503662

num_try : 814 | val_loss = 32.29775722503662 | val acc = 4.6964335441589355
Time execution (tranning): 155.349821 seconds 
Time execution (load saved model): 0.002105 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 491
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.30382675170898

num_try : 888 | val_loss = 32.30382675170898 | val acc = 4.4959516525268555
Time execution (tranning): 138.048053 seconds 
Time execution (load saved model): 0.002143 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 410
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.33550510406494

num_try : 733 | val_loss = 32.33550510406494 | val acc = 4.560122489929199
Time execution (tranning): 87.976402 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.36790939331055

num_try : 796 | val_loss = 32.36790939331055 | val acc = 4.730702877044678
Time execution (tranning): 67.730090 seconds 
Time execution (load saved model): 0.002112 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 217
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.43810691833496

num_try : 1003 | val_loss = 32.43810691833496 | val acc = 4.502465724945068
Time execution (tranning): 146.589996 seconds 
Time execution (load saved model): 0.002161 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 418
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.45776927947998

num_try : 726 | val_loss = 32.45776927947998 | val acc = 4.542769908905029
Time execution (tranning): 89.966928 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.542871704101564

num_try : 688 | val_loss = 32.542871704101564 | val acc = 4.742147445678711
Time execution (tranning): 76.867436 seconds 
Time execution (load saved model): 0.002096 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.55075973510742

num_try : 625 | val_loss = 32.55075973510742 | val acc = 4.599365234375
Time execution (tranning): 128.976262 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 410
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.596498031616214

num_try : 75 | val_loss = 32.596498031616214 | val acc = 7.2239789962768555
Time execution (tranning): 54.600333 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.61887950897217

num_try : 843 | val_loss = 32.61887950897217 | val acc = 4.494409561157227
Time execution (tranning): 90.352734 seconds 
Time execution (load saved model): 0.002169 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.6218664932251

num_try : 769 | val_loss = 32.6218664932251 | val acc = 4.571444034576416
Time execution (tranning): 71.893685 seconds 
Time execution (load saved model): 0.002127 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.644183769226075

num_try : 228 | val_loss = 32.644183769226075 | val acc = 7.362575054168701
Time execution (tranning): 75.727774 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.64478370666504

num_try : 652 | val_loss = 32.64478370666504 | val acc = 4.637468338012695
Time execution (tranning): 76.035064 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

32.68243728637695

num_try : 372 | val_loss = 32.68243728637695 | val acc = 7.291558265686035
Time execution (tranning): 60.133794 seconds 
Time execution (load saved model): 0.002030 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.69973434448242

num_try : 263 | val_loss = 32.69973434448242 | val acc = 6.88230037689209
Time execution (tranning): 77.328595 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

32.71887321472168

num_try : 462 | val_loss = 32.71887321472168 | val acc = 7.26485538482666
Time execution (tranning): 123.296705 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 402
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.78096397399902

num_try : 915 | val_loss = 32.78096397399902 | val acc = 4.426528453826904
Time execution (tranning): 96.363054 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.78405288696289

num_try : 924 | val_loss = 32.78405288696289 | val acc = 4.566124439239502
Time execution (tranning): 148.365134 seconds 
Time execution (load saved model): 0.002158 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 443
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.84187889099121

num_try : 771 | val_loss = 32.84187889099121 | val acc = 4.454845905303955
Time execution (tranning): 92.124947 seconds 
Time execution (load saved model): 0.002099 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

32.95033779144287

num_try : 580 | val_loss = 32.95033779144287 | val acc = 4.8038811683654785
Time execution (tranning): 81.742680 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.01617069244385

num_try : 987 | val_loss = 33.01617069244385 | val acc = 4.481645584106445
Time execution (tranning): 111.321504 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.069857864379884

num_try : 850 | val_loss = 33.069857864379884 | val acc = 4.749479293823242
Time execution (tranning): 132.247492 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.12404308319092

num_try : 886 | val_loss = 33.12404308319092 | val acc = 4.73948335647583
Time execution (tranning): 102.003170 seconds 
Time execution (load saved model): 0.002143 seconds 
Time execution (use saved model): 0.000277 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.15583118438721

num_try : 958 | val_loss = 33.15583118438721 | val acc = 4.7233805656433105
Time execution (tranning): 123.804926 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 374
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.16682804107666

num_try : 823 | val_loss = 33.16682804107666 | val acc = 4.618709087371826
Time execution (tranning): 133.627353 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.21392902374268

num_try : 2 | val_loss = 33.21392902374268 | val acc = 6.669390678405762
Time execution (tranning): 104.767073 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

33.296143798828126

num_try : 661 | val_loss = 33.296143798828126 | val acc = 4.75045108795166
Time execution (tranning): 102.191467 seconds 
Time execution (load saved model): 0.002064 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.306747589111325

num_try : 654 | val_loss = 33.306747589111325 | val acc = 4.684533596038818
Time execution (tranning): 100.013800 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.308802375793455

num_try : 960 | val_loss = 33.308802375793455 | val acc = 4.569156169891357
Time execution (tranning): 113.198521 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.36709632873535

num_try : 618 | val_loss = 33.36709632873535 | val acc = 4.630876064300537
Time execution (tranning): 78.578830 seconds 
Time execution (load saved model): 0.002101 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.42701377868652

num_try : 967 | val_loss = 33.42701377868652 | val acc = 4.665824890136719
Time execution (tranning): 135.577734 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 395
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.52443218231201

num_try : 751 | val_loss = 33.52443218231201 | val acc = 4.6436944007873535
Time execution (tranning): 149.156837 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 460
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.582441329956055

num_try : 461 | val_loss = 33.582441329956055 | val acc = 6.782069206237793
Time execution (tranning): 98.766784 seconds 
Time execution (load saved model): 0.002072 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 322
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

33.64949687957764

num_try : 897 | val_loss = 33.64949687957764 | val acc = 4.545504570007324
Time execution (tranning): 137.388656 seconds 
Time execution (load saved model): 0.002182 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.75170997619629

num_try : 20 | val_loss = 33.75170997619629 | val acc = 7.172852039337158
Time execution (tranning): 111.506547 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

33.82364498138428

num_try : 852 | val_loss = 33.82364498138428 | val acc = 4.615201473236084
Time execution (tranning): 142.101337 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 450
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

33.864380264282225

num_try : 895 | val_loss = 33.864380264282225 | val acc = 4.704696178436279
Time execution (tranning): 148.784462 seconds 
Time execution (load saved model): 0.002240 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 424
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

33.88454795837402

num_try : 353 | val_loss = 33.88454795837402 | val acc = 6.928686141967773
Time execution (tranning): 140.380524 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 462
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

34.01875

num_try : 762 | val_loss = 34.01875 | val acc = 4.805084705352783
Time execution (tranning): 77.730056 seconds 
Time execution (load saved model): 0.002127 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

34.05803155899048

num_try : 1005 | val_loss = 34.05803155899048 | val acc = 4.508241653442383
Time execution (tranning): 145.199020 seconds 
Time execution (load saved model): 0.002164 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

34.088351821899415

num_try : 735 | val_loss = 34.088351821899415 | val acc = 4.543323993682861
Time execution (tranning): 80.214153 seconds 
Time execution (load saved model): 0.002106 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

34.13489879608154

num_try : 994 | val_loss = 34.13489879608154 | val acc = 4.8209638595581055
Time execution (tranning): 112.542181 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

34.14333885192871

num_try : 589 | val_loss = 34.14333885192871 | val acc = 4.827841281890869
Time execution (tranning): 79.400226 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

34.18614624023437

num_try : 497 | val_loss = 34.18614624023437 | val acc = 7.014804840087891
Time execution (tranning): 119.490305 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000214 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 393
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

34.3831909942627

num_try : 697 | val_loss = 34.3831909942627 | val acc = 4.679389953613281
Time execution (tranning): 119.027748 seconds 
Time execution (load saved model): 0.002142 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 379
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

34.52080192565918

num_try : 996 | val_loss = 34.52080192565918 | val acc = 4.676868915557861
Time execution (tranning): 107.458499 seconds 
Time execution (load saved model): 0.002161 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

34.55736633300781

num_try : 416 | val_loss = 34.55736633300781 | val acc = 7.131706714630127
Time execution (tranning): 92.636775 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

34.60244415283203

num_try : 84 | val_loss = 34.60244415283203 | val acc = 7.702227592468262
Time execution (tranning): 98.787860 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

34.66039722442627

num_try : 742 | val_loss = 34.66039722442627 | val acc = 4.913794040679932
Time execution (tranning): 110.641483 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

34.66339797973633

num_try : 30 | val_loss = 34.66339797973633 | val acc = 7.636282444000244
Time execution (tranning): 140.655272 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 470
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

34.685940704345704

num_try : 191 | val_loss = 34.685940704345704 | val acc = 7.097967147827148
Time execution (tranning): 81.387811 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

34.85549343109131

num_try : 807 | val_loss = 34.85549343109131 | val acc = 4.653559684753418
Time execution (tranning): 78.621635 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.022138671875

num_try : 66 | val_loss = 35.022138671875 | val acc = 7.715824127197266
Time execution (tranning): 103.246041 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.06498634338379

num_try : 129 | val_loss = 35.06498634338379 | val acc = 7.708532810211182
Time execution (tranning): 82.894118 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.105691299438476

num_try : 246 | val_loss = 35.105691299438476 | val acc = 7.672049522399902
Time execution (tranning): 64.530254 seconds 
Time execution (load saved model): 0.002023 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.14882064819336

num_try : 789 | val_loss = 35.14882064819336 | val acc = 4.613619804382324
Time execution (tranning): 131.555400 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 403
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.17665596008301

num_try : 119 | val_loss = 35.17665596008301 | val acc = 7.347486972808838
Time execution (tranning): 58.193205 seconds 
Time execution (load saved model): 0.002013 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

35.23743354797363

num_try : 922 | val_loss = 35.23743354797363 | val acc = 4.927400588989258
Time execution (tranning): 115.973762 seconds 
Time execution (load saved model): 0.002166 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

35.3739966583252

num_try : 690 | val_loss = 35.3739966583252 | val acc = 4.861570358276367
Time execution (tranning): 65.840228 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.40627540588379

num_try : 138 | val_loss = 35.40627540588379 | val acc = 7.689016342163086
Time execution (tranning): 81.052897 seconds 
Time execution (load saved model): 0.002029 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.45763114929199

num_try : 389 | val_loss = 35.45763114929199 | val acc = 7.181034088134766
Time execution (tranning): 137.524398 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 453
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

35.47288196563721

num_try : 969 | val_loss = 35.47288196563721 | val acc = 4.704654216766357
Time execution (tranning): 135.563640 seconds 
Time execution (load saved model): 0.002185 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 387
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.52996166229248

num_try : 627 | val_loss = 35.52996166229248 | val acc = 4.764338970184326
Time execution (tranning): 85.404038 seconds 
Time execution (load saved model): 0.002064 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.57356731414795

num_try : 425 | val_loss = 35.57356731414795 | val acc = 7.177648544311523
Time execution (tranning): 109.643458 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 361
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

35.68918872833252

num_try : 699 | val_loss = 35.68918872833252 | val acc = 4.848862648010254
Time execution (tranning): 75.316277 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.78844429016113

num_try : 21 | val_loss = 35.78844429016113 | val acc = 7.7461113929748535
Time execution (tranning): 71.774549 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.80768325805664

num_try : 120 | val_loss = 35.80768325805664 | val acc = 7.908201217651367
Time execution (tranning): 101.425345 seconds 
Time execution (load saved model): 0.002016 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.81489868164063

num_try : 744 | val_loss = 35.81489868164063 | val acc = 4.85903263092041
Time execution (tranning): 114.813612 seconds 
Time execution (load saved model): 0.002112 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 367
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.93671333312988

num_try : 861 | val_loss = 35.93671333312988 | val acc = 4.745659351348877
Time execution (tranning): 128.201261 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

35.94649513244629

num_try : 317 | val_loss = 35.94649513244629 | val acc = 7.221808910369873
Time execution (tranning): 91.685319 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

36.19656486511231

num_try : 273 | val_loss = 36.19656486511231 | val acc = 7.818640232086182
Time execution (tranning): 68.407922 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

36.25132007598877

num_try : 778 | val_loss = 36.25132007598877 | val acc = 5.062852382659912
Time execution (tranning): 101.317652 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

36.28235145568848

num_try : 227 | val_loss = 36.28235145568848 | val acc = 7.274570465087891
Time execution (tranning): 69.299719 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

36.33700679779053

num_try : 472 | val_loss = 36.33700679779053 | val acc = 5.117047309875488
Time execution (tranning): 59.695144 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

36.389377212524415

num_try : 200 | val_loss = 36.389377212524415 | val acc = 7.404451847076416
Time execution (tranning): 78.204087 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000244 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

36.508670005798336

num_try : 591 | val_loss = 36.508670005798336 | val acc = 4.863950729370117
Time execution (tranning): 89.210990 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

36.61995826721191

num_try : 155 | val_loss = 36.61995826721191 | val acc = 7.3245110511779785
Time execution (tranning): 64.753180 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

36.71048755645752

num_try : 544 | val_loss = 36.71048755645752 | val acc = 5.195690155029297
Time execution (tranning): 68.627635 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

37.03659069061279

num_try : 607 | val_loss = 37.03659069061279 | val acc = 5.047063827514648
Time execution (tranning): 153.150705 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 482
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

37.05137939453125

num_try : 82 | val_loss = 37.05137939453125 | val acc = 9.361883163452148
Time execution (tranning): 40.536673 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 133
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

37.07395576477051

num_try : 210 | val_loss = 37.07395576477051 | val acc = 7.8939032554626465
Time execution (tranning): 62.345790 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 203
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

37.44279251098633

num_try : 787 | val_loss = 37.44279251098633 | val acc = 5.061598300933838
Time execution (tranning): 114.419508 seconds 
Time execution (load saved model): 0.002115 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 350
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

37.45946868896485

num_try : 670 | val_loss = 37.45946868896485 | val acc = 5.309542179107666
Time execution (tranning): 133.675433 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

37.46910224914551

num_try : 92 | val_loss = 37.46910224914551 | val acc = 7.535429000854492
Time execution (tranning): 78.387694 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

37.575889625549316

num_try : 600 | val_loss = 37.575889625549316 | val acc = 5.0100297927856445
Time execution (tranning): 152.009404 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 493
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

37.59865997314453

num_try : 192 | val_loss = 37.59865997314453 | val acc = 7.929678916931152
Time execution (tranning): 47.185503 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 155
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

37.65734474182129

num_try : 753 | val_loss = 37.65734474182129 | val acc = 4.851577281951904
Time execution (tranning): 137.783726 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 422
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

37.75917709350586

num_try : 282 | val_loss = 37.75917709350586 | val acc = 8.003240585327148
Time execution (tranning): 64.070966 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

37.76721862792969

num_try : 780 | val_loss = 37.76721862792969 | val acc = 5.032626152038574
Time execution (tranning): 111.025382 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

37.8296590423584

num_try : 102 | val_loss = 37.8296590423584 | val acc = 7.995128631591797
Time execution (tranning): 70.931226 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

37.87398498535156

num_try : 209 | val_loss = 37.87398498535156 | val acc = 7.427478790283203
Time execution (tranning): 130.491321 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 429
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

37.95085300445557

num_try : 706 | val_loss = 37.95085300445557 | val acc = 5.2213311195373535
Time execution (tranning): 97.915342 seconds 
Time execution (load saved model): 0.002095 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

37.961518096923825

num_try : 533 | val_loss = 37.961518096923825 | val acc = 7.527044296264648
Time execution (tranning): 125.477328 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000213 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 409
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

37.978916282653806

num_try : 236 | val_loss = 37.978916282653806 | val acc = 7.47481632232666
Time execution (tranning): 84.670990 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

37.98823673248291

num_try : 825 | val_loss = 37.98823673248291 | val acc = 4.9358673095703125
Time execution (tranning): 101.900965 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

38.106659469604494

num_try : 48 | val_loss = 38.106659469604494 | val acc = 8.135364532470703
Time execution (tranning): 65.370157 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

38.113123664855955

num_try : 715 | val_loss = 38.113123664855955 | val acc = 5.128652572631836
Time execution (tranning): 159.549891 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 507
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

38.248866386413575

num_try : 681 | val_loss = 38.248866386413575 | val acc = 4.981654167175293
Time execution (tranning): 167.349598 seconds 
Time execution (load saved model): 0.002080 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 531
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

38.25577033996582

num_try : 663 | val_loss = 38.25577033996582 | val acc = 5.018725395202637
Time execution (tranning): 96.905324 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

38.27908447265625

num_try : 12 | val_loss = 38.27908447265625 | val acc = 8.18073558807373
Time execution (tranning): 65.657227 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

38.34808059692383

num_try : 426 | val_loss = 38.34808059692383 | val acc = 8.082755088806152
Time execution (tranning): 59.286406 seconds 
Time execution (load saved model): 0.002100 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

38.35146156311035

num_try : 335 | val_loss = 38.35146156311035 | val acc = 7.483032703399658
Time execution (tranning): 96.398522 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

38.46275726318359

num_try : 508 | val_loss = 38.46275726318359 | val acc = 5.276179313659668
Time execution (tranning): 87.968278 seconds 
Time execution (load saved model): 0.002072 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

38.4795662689209

num_try : 546 | val_loss = 38.4795662689209 | val acc = 5.173382759094238
Time execution (tranning): 90.061074 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

38.52190788269043

num_try : 299 | val_loss = 38.52190788269043 | val acc = 7.531872749328613
Time execution (tranning): 68.937536 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

38.80017143249512

num_try : 643 | val_loss = 38.80017143249512 | val acc = 5.230091571807861
Time execution (tranning): 143.428129 seconds 
Time execution (load saved model): 0.002093 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 455
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

38.83953170776367

num_try : 708 | val_loss = 38.83953170776367 | val acc = 5.2095947265625
Time execution (tranning): 133.786767 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 432
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

38.85446647644043

num_try : 454 | val_loss = 38.85446647644043 | val acc = 5.344342231750488
Time execution (tranning): 177.274179 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 583
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

38.878799247741696

num_try : 380 | val_loss = 38.878799247741696 | val acc = 7.6372809410095215
Time execution (tranning): 68.239521 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

38.93686241149902

num_try : 83 | val_loss = 38.93686241149902 | val acc = 7.6736040115356445
Time execution (tranning): 80.421017 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

39.06833160400391

num_try : 816 | val_loss = 39.06833160400391 | val acc = 5.13762092590332
Time execution (tranning): 93.860916 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

39.13901428222656

num_try : 717 | val_loss = 39.13901428222656 | val acc = 5.07219123840332
Time execution (tranning): 121.906446 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

39.18753890991211

num_try : 438 | val_loss = 39.18753890991211 | val acc = 5.216746807098389
Time execution (tranning): 60.920018 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

39.39585929870606

num_try : 598 | val_loss = 39.39585929870606 | val acc = 5.278735160827637
Time execution (tranning): 134.947579 seconds 
Time execution (load saved model): 0.002085 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 437
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

39.738097190856934

num_try : 456 | val_loss = 39.738097190856934 | val acc = 5.215219497680664
Time execution (tranning): 151.926151 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 502
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

40.11672386169434

num_try : 281 | val_loss = 40.11672386169434 | val acc = 7.710682392120361
Time execution (tranning): 138.354660 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 457
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

40.5395092010498

num_try : 328 | val_loss = 40.5395092010498 | val acc = 5.496946334838867
Time execution (tranning): 163.009027 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 544
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

40.59067825317383

num_try : 528 | val_loss = 40.59067825317383 | val acc = 5.2631120681762695
Time execution (tranning): 158.422053 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 531
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

40.8694743347168

num_try : 137 | val_loss = 40.8694743347168 | val acc = 7.864940166473389
Time execution (tranning): 82.981622 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

40.98159149169922

num_try : 245 | val_loss = 40.98159149169922 | val acc = 7.828848838806152
Time execution (tranning): 96.650362 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

40.989114913940426

num_try : 609 | val_loss = 40.989114913940426 | val acc = 5.177342414855957
Time execution (tranning): 154.303791 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 483
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

41.09727684020996

num_try : 977 | val_loss = 41.09727684020996 | val acc = 4.260901927947998
Time execution (tranning): 102.313740 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

41.18288097381592

num_try : 436 | val_loss = 41.18288097381592 | val acc = 5.550182342529297
Time execution (tranning): 79.242775 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 263
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

41.408211135864256

num_try : 562 | val_loss = 41.408211135864256 | val acc = 5.546545505523682
Time execution (tranning): 125.511385 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 422
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

41.71496765136719

num_try : 173 | val_loss = 41.71496765136719 | val acc = 7.83873176574707
Time execution (tranning): 66.148688 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

41.96458435058594

num_try : 634 | val_loss = 41.96458435058594 | val acc = 5.540134906768799
Time execution (tranning): 102.221249 seconds 
Time execution (load saved model): 0.002093 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

42.11970844268799

num_try : 833 | val_loss = 42.11970844268799 | val acc = 4.305686950683594
Time execution (tranning): 110.169619 seconds 
Time execution (load saved model): 0.002101 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

42.19107669830322

num_try : 445 | val_loss = 42.19107669830322 | val acc = 5.669288158416748
Time execution (tranning): 99.734588 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

42.339723663330076

num_try : 492 | val_loss = 42.339723663330076 | val acc = 5.542007923126221
Time execution (tranning): 149.254979 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 496
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

42.34531089782715

num_try : 672 | val_loss = 42.34531089782715 | val acc = 5.512847900390625
Time execution (tranning): 120.831755 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 391
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

42.51601844787598

num_try : 526 | val_loss = 42.51601844787598 | val acc = 5.6960883140563965
Time execution (tranning): 105.635512 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

42.58457878112793

num_try : 402 | val_loss = 42.58457878112793 | val acc = 5.532595157623291
Time execution (tranning): 63.734513 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

42.6057160949707

num_try : 569 | val_loss = 42.6057160949707 | val acc = 8.014690399169922
Time execution (tranning): 87.093052 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

42.63873825073242

num_try : 294 | val_loss = 42.63873825073242 | val acc = 5.582789897918701
Time execution (tranning): 92.997610 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

42.65137149810791

num_try : 474 | val_loss = 42.65137149810791 | val acc = 5.607151985168457
Time execution (tranning): 75.498766 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

42.75649406433106

num_try : 400 | val_loss = 42.75649406433106 | val acc = 5.731892108917236
Time execution (tranning): 80.187592 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

42.959844741821286

num_try : 510 | val_loss = 42.959844741821286 | val acc = 5.593050956726074
Time execution (tranning): 73.116810 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

43.01851123809814

num_try : 869 | val_loss = 43.01851123809814 | val acc = 4.2853474617004395
Time execution (tranning): 70.162703 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

43.04864082336426

num_try : 47 | val_loss = 43.04864082336426 | val acc = 8.10654067993164
Time execution (tranning): 55.670439 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

43.584496307373044

num_try : 905 | val_loss = 43.584496307373044 | val acc = 4.367954730987549
Time execution (tranning): 117.739463 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

43.65956199645996

num_try : 490 | val_loss = 43.65956199645996 | val acc = 5.781001567840576
Time execution (tranning): 144.186126 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 480
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

43.70522613525391

num_try : 148 | val_loss = 43.70522613525391 | val acc = 5.767086029052734
Time execution (tranning): 85.296302 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

44.15099449157715

num_try : 636 | val_loss = 44.15099449157715 | val acc = 5.6732001304626465
Time execution (tranning): 103.942205 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 333
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

44.16819076538086

num_try : 364 | val_loss = 44.16819076538086 | val acc = 5.8934125900268555
Time execution (tranning): 94.570774 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

44.44423069000244

num_try : 914 | val_loss = 44.44423069000244 | val acc = 4.321154594421387
Time execution (tranning): 107.607089 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

44.57724643707275

num_try : 941 | val_loss = 44.57724643707275 | val acc = 4.40184211730957
Time execution (tranning): 99.862262 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

44.74244346618652

num_try : 564 | val_loss = 44.74244346618652 | val acc = 5.764441013336182
Time execution (tranning): 127.736156 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 422
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

44.8585929107666

num_try : 986 | val_loss = 44.8585929107666 | val acc = 4.355595588684082
Time execution (tranning): 117.652078 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 333
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

44.93872459411621

num_try : 483 | val_loss = 44.93872459411621 | val acc = 5.652132511138916
Time execution (tranning): 92.006326 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

44.957082443237304

num_try : 679 | val_loss = 44.957082443237304 | val acc = 5.811000347137451
Time execution (tranning): 122.788777 seconds 
Time execution (load saved model): 0.002081 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 387
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

44.97992858886719

num_try : 366 | val_loss = 44.97992858886719 | val acc = 5.761041641235352
Time execution (tranning): 68.415419 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

45.046569480896

num_try : 761 | val_loss = 45.046569480896 | val acc = 4.655431270599365
Time execution (tranning): 91.274136 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.15438278198242

num_try : 878 | val_loss = 45.15438278198242 | val acc = 4.336874485015869
Time execution (tranning): 112.729840 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.235246658325195

num_try : 101 | val_loss = 45.235246658325195 | val acc = 8.302962303161621
Time execution (tranning): 59.018367 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

45.290609436035155

num_try : 950 | val_loss = 45.290609436035155 | val acc = 4.368253707885742
Time execution (tranning): 89.805134 seconds 
Time execution (load saved model): 0.002175 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.599307479858396

num_try : 29 | val_loss = 45.599307479858396 | val acc = 8.321843147277832
Time execution (tranning): 82.106495 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

45.62001049041748

num_try : 932 | val_loss = 45.62001049041748 | val acc = 4.410398483276367
Time execution (tranning): 161.769448 seconds 
Time execution (load saved model): 0.002164 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 460
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.692807540893554

num_try : 734 | val_loss = 45.692807540893554 | val acc = 4.419037818908691
Time execution (tranning): 84.868325 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 263
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.73416198730469

num_try : 842 | val_loss = 45.73416198730469 | val acc = 4.528982162475586
Time execution (tranning): 122.663704 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 377
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

45.7418058013916

num_try : 645 | val_loss = 45.7418058013916 | val acc = 5.643328666687012
Time execution (tranning): 94.413456 seconds 
Time execution (load saved model): 0.002096 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

45.8269312286377

num_try : 481 | val_loss = 45.8269312286377 | val acc = 5.954986572265625
Time execution (tranning): 74.433674 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

45.91827049255371

num_try : 111 | val_loss = 45.91827049255371 | val acc = 9.076598167419434
Time execution (tranning): 58.484400 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

46.16455390930176

num_try : 725 | val_loss = 46.16455390930176 | val acc = 4.513569355010986
Time execution (tranning): 70.679545 seconds 
Time execution (load saved model): 0.002093 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

46.191306838989256

num_try : 76 | val_loss = 46.191306838989256 | val acc = 5.988336563110352
Time execution (tranning): 99.439806 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

46.36634002685547

num_try : 995 | val_loss = 46.36634002685547 | val acc = 4.742375373840332
Time execution (tranning): 195.244576 seconds 
Time execution (load saved model): 0.002163 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 580
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

46.45238243103027

num_try : 222 | val_loss = 46.45238243103027 | val acc = 5.871409893035889
Time execution (tranning): 69.463677 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

46.53866477966309

num_try : 330 | val_loss = 46.53866477966309 | val acc = 5.8183488845825195
Time execution (tranning): 141.282791 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 474
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

46.62020118713379

num_try : 770 | val_loss = 46.62020118713379 | val acc = 4.477202892303467
Time execution (tranning): 86.913359 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

46.675256881713864

num_try : 887 | val_loss = 46.675256881713864 | val acc = 4.63432502746582
Time execution (tranning): 145.914542 seconds 
Time execution (load saved model): 0.002145 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

46.83445724487305

num_try : 447 | val_loss = 46.83445724487305 | val acc = 5.760336399078369
Time execution (tranning): 106.279226 seconds 
Time execution (load saved model): 0.002136 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 346
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

46.86512908935547

num_try : 22 | val_loss = 46.86512908935547 | val acc = 6.298515796661377
Time execution (tranning): 99.249491 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

46.947963638305666

num_try : 555 | val_loss = 46.947963638305666 | val acc = 5.870710372924805
Time execution (tranning): 67.159841 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

47.14750442504883

num_try : 959 | val_loss = 47.14750442504883 | val acc = 4.609149932861328
Time execution (tranning): 163.192909 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 490
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

47.20344245910645

num_try : 418 | val_loss = 47.20344245910645 | val acc = 6.205582141876221
Time execution (tranning): 129.148383 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 430
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

47.368114929199216

num_try : 797 | val_loss = 47.368114929199216 | val acc = 4.584081649780273
Time execution (tranning): 62.386897 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

47.4483911895752

num_try : 204 | val_loss = 47.4483911895752 | val acc = 5.9914069175720215
Time execution (tranning): 119.655095 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 397
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

47.59463256835937

num_try : 382 | val_loss = 47.59463256835937 | val acc = 6.201727867126465
Time execution (tranning): 115.446228 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 386
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

47.659195556640626

num_try : 689 | val_loss = 47.659195556640626 | val acc = 4.715310573577881
Time execution (tranning): 89.646339 seconds 
Time execution (load saved model): 0.002096 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

47.68164474487305

num_try : 310 | val_loss = 47.68164474487305 | val acc = 6.329123497009277
Time execution (tranning): 107.826868 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 359
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

47.83340072631836

num_try : 968 | val_loss = 47.83340072631836 | val acc = 4.606720447540283
Time execution (tranning): 139.464178 seconds 
Time execution (load saved model): 0.002180 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 413
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

47.875770797729494

num_try : 860 | val_loss = 47.875770797729494 | val acc = 4.547629356384277
Time execution (tranning): 174.478811 seconds 
Time execution (load saved model): 0.002126 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 541
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.19053283691406

num_try : 662 | val_loss = 48.19053283691406 | val acc = 4.640997886657715
Time execution (tranning): 79.095598 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.2076237487793

num_try : 94 | val_loss = 48.2076237487793 | val acc = 6.363214015960693
Time execution (tranning): 132.879065 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 452
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

48.37569389343262

num_try : 1004 | val_loss = 48.37569389343262 | val acc = 4.622664451599121
Time execution (tranning): 117.321061 seconds 
Time execution (load saved model): 0.002169 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.395191802978516

num_try : 509 | val_loss = 48.395191802978516 | val acc = 4.855370998382568
Time execution (tranning): 100.902625 seconds 
Time execution (load saved model): 0.002078 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 332
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.51934005737305

num_try : 519 | val_loss = 48.51934005737305 | val acc = 5.976345062255859
Time execution (tranning): 105.260967 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

48.6376749420166

num_try : 806 | val_loss = 48.6376749420166 | val acc = 4.589937210083008
Time execution (tranning): 79.047269 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.87129173278809

num_try : 923 | val_loss = 48.87129173278809 | val acc = 4.791686534881592
Time execution (tranning): 133.007452 seconds 
Time execution (load saved model): 0.002159 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 395
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.90619911193848

num_try : 617 | val_loss = 48.90619911193848 | val acc = 4.832459449768066
Time execution (tranning): 120.199572 seconds 
Time execution (load saved model): 0.002084 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 388
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

48.97398040771484

num_try : 337 | val_loss = 48.97398040771484 | val acc = 6.231342792510986
Time execution (tranning): 66.234536 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

49.20387924194336

num_try : 573 | val_loss = 49.20387924194336 | val acc = 6.075278282165527
Time execution (tranning): 133.736723 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 439
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

49.270138092041016

num_try : 896 | val_loss = 49.270138092041016 | val acc = 4.69774866104126
Time execution (tranning): 143.075981 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 411
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

49.556974716186524

num_try : 517 | val_loss = 49.556974716186524 | val acc = 6.282537460327148
Time execution (tranning): 68.657326 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

49.96672119140625

num_try : 743 | val_loss = 49.96672119140625 | val acc = 4.827164173126221
Time execution (tranning): 122.849742 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

50.21224861145019

num_try : 78 | val_loss = 50.21224861145019 | val acc = 6.207850933074951
Time execution (tranning): 86.515346 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

50.28926055908203

num_try : 698 | val_loss = 50.28926055908203 | val acc = 4.7422099113464355
Time execution (tranning): 63.579882 seconds 
Time execution (load saved model): 0.002072 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

50.742034072875974

num_try : 752 | val_loss = 50.742034072875974 | val acc = 4.8090291023254395
Time execution (tranning): 108.536376 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

50.792453384399415

num_try : 58 | val_loss = 50.792453384399415 | val acc = 6.652716636657715
Time execution (tranning): 105.041187 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

50.90564888000488

num_try : 671 | val_loss = 50.90564888000488 | val acc = 4.9159626960754395
Time execution (tranning): 159.035027 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 516
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

51.011874771118165

num_try : 788 | val_loss = 51.011874771118165 | val acc = 4.808754920959473
Time execution (tranning): 145.887744 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 448
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

51.20939643859863

num_try : 292 | val_loss = 51.20939643859863 | val acc = 6.242556571960449
Time execution (tranning): 58.798550 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

51.496475067138675

num_try : 166 | val_loss = 51.496475067138675 | val acc = 6.61037540435791
Time execution (tranning): 103.206546 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

51.51268791198731

num_try : 590 | val_loss = 51.51268791198731 | val acc = 4.840051651000977
Time execution (tranning): 70.248145 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

51.61767997741699

num_try : 653 | val_loss = 51.61767997741699 | val acc = 4.929052352905273
Time execution (tranning): 81.966228 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 257
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

51.635351943969724

num_try : 258 | val_loss = 51.635351943969724 | val acc = 6.243527889251709
Time execution (tranning): 66.846998 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

51.95177848815918

num_try : 581 | val_loss = 51.95177848815918 | val acc = 5.02120304107666
Time execution (tranning): 66.257969 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

52.06061920166016

num_try : 815 | val_loss = 52.06061920166016 | val acc = 4.990045547485352
Time execution (tranning): 108.182713 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

52.243597717285155

num_try : 110 | val_loss = 52.243597717285155 | val acc = 9.030999183654785
Time execution (tranning): 56.946789 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

52.245830307006834

num_try : 114 | val_loss = 52.245830307006834 | val acc = 6.385904312133789
Time execution (tranning): 67.420305 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

52.438512077331545

num_try : 824 | val_loss = 52.438512077331545 | val acc = 4.909744739532471
Time execution (tranning): 120.315728 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 373
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

52.48490013122559

num_try : 6 | val_loss = 52.48490013122559 | val acc = 6.378634452819824
Time execution (tranning): 76.436364 seconds 
Time execution (load saved model): 0.002030 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 257
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

52.6218936920166

num_try : 501 | val_loss = 52.6218936920166 | val acc = 6.507503509521484
Time execution (tranning): 139.378014 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 455
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

52.905465545654295

num_try : 626 | val_loss = 52.905465545654295 | val acc = 4.976010322570801
Time execution (tranning): 89.079109 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 282
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

53.112979888916016

num_try : 256 | val_loss = 53.112979888916016 | val acc = 6.48770809173584
Time execution (tranning): 74.671910 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

53.3519938659668

num_try : 779 | val_loss = 53.3519938659668 | val acc = 5.06925630569458
Time execution (tranning): 113.859109 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

54.14296813964844

num_try : 150 | val_loss = 54.14296813964844 | val acc = 6.4073567390441895
Time execution (tranning): 79.701801 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

54.173668670654294

num_try : 11 | val_loss = 54.173668670654294 | val acc = 9.311700820922852
Time execution (tranning): 35.093373 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 115
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

54.36766319274902

num_try : 348 | val_loss = 54.36766319274902 | val acc = 6.519216537475586
Time execution (tranning): 135.014269 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 450
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

54.51479278564453

num_try : 851 | val_loss = 54.51479278564453 | val acc = 5.101597309112549
Time execution (tranning): 92.402359 seconds 
Time execution (load saved model): 0.002115 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

54.51594062805176

num_try : 473 | val_loss = 54.51594062805176 | val acc = 5.167260646820068
Time execution (tranning): 86.759643 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

54.917422943115234

num_try : 65 | val_loss = 54.917422943115234 | val acc = 9.389269828796387
Time execution (tranning): 74.600605 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.5}
----------

54.94536819458008

num_try : 24 | val_loss = 54.94536819458008 | val acc = 6.747286319732666
Time execution (tranning): 81.859042 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

55.26241157531738

num_try : 193 | val_loss = 55.26241157531738 | val acc = 6.938457012176514
Time execution (tranning): 126.665431 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 419
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

55.40170402526856

num_try : 112 | val_loss = 55.40170402526856 | val acc = 6.745087146759033
Time execution (tranning): 76.535800 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

55.42048377990723

num_try : 716 | val_loss = 55.42048377990723 | val acc = 5.064842700958252
Time execution (tranning): 151.832025 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 484
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

55.462011642456055

num_try : 907 | val_loss = 55.462011642456055 | val acc = 4.327731132507324
Time execution (tranning): 78.542026 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

55.93593902587891

num_try : 301 | val_loss = 55.93593902587891 | val acc = 6.879702568054199
Time execution (tranning): 71.054229 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

56.02278175354004

num_try : 707 | val_loss = 56.02278175354004 | val acc = 5.2162065505981445
Time execution (tranning): 105.309508 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

56.04303077697754

num_try : 499 | val_loss = 56.04303077697754 | val acc = 6.753504753112793
Time execution (tranning): 84.673474 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

56.533682861328124

num_try : 599 | val_loss = 56.533682861328124 | val acc = 5.2455244064331055
Time execution (tranning): 117.034753 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 377
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

56.57603515625

num_try : 276 | val_loss = 56.57603515625 | val acc = 6.667794704437256
Time execution (tranning): 152.031103 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 510
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

56.64372055053711

num_try : 871 | val_loss = 56.64372055053711 | val acc = 4.3184404373168945
Time execution (tranning): 94.271796 seconds 
Time execution (load saved model): 0.002171 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

56.73594009399414

num_try : 130 | val_loss = 56.73594009399414 | val acc = 7.155216693878174
Time execution (tranning): 103.246495 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 346
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

56.972080307006834

num_try : 373 | val_loss = 56.972080307006834 | val acc = 6.938176155090332
Time execution (tranning): 70.148146 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.05666275024414

num_try : 4 | val_loss = 57.05666275024414 | val acc = 6.800711631774902
Time execution (tranning): 61.529720 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.237139587402346

num_try : 229 | val_loss = 57.237139587402346 | val acc = 6.971466541290283
Time execution (tranning): 101.967700 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.29128646850586

num_try : 553 | val_loss = 57.29128646850586 | val acc = 6.764168739318848
Time execution (tranning): 59.137353 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.40312927246094

num_try : 943 | val_loss = 57.40312927246094 | val acc = 4.307990550994873
Time execution (tranning): 91.377004 seconds 
Time execution (load saved model): 0.002169 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

57.44219192504883

num_try : 491 | val_loss = 57.44219192504883 | val acc = 5.389563083648682
Time execution (tranning): 129.443841 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 429
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

57.69119598388672

num_try : 799 | val_loss = 57.69119598388672 | val acc = 4.3705339431762695
Time execution (tranning): 87.712379 seconds 
Time execution (load saved model): 0.002114 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

57.69601455688476

num_try : 979 | val_loss = 57.69601455688476 | val acc = 4.401202201843262
Time execution (tranning): 85.519880 seconds 
Time execution (load saved model): 0.002178 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

57.736497192382814

num_try : 40 | val_loss = 57.736497192382814 | val acc = 6.924663543701172
Time execution (tranning): 76.821998 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 257
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.8628500366211

num_try : 238 | val_loss = 57.8628500366211 | val acc = 7.1684722900390625
Time execution (tranning): 120.260164 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 408
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

57.871408004760745

num_try : 168 | val_loss = 57.871408004760745 | val acc = 6.869572639465332
Time execution (tranning): 148.234970 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 496
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

57.90103286743164

num_try : 312 | val_loss = 57.90103286743164 | val acc = 6.905057907104492
Time execution (tranning): 144.364886 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 478
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

58.043690032958985

num_try : 763 | val_loss = 58.043690032958985 | val acc = 4.383578300476074
Time execution (tranning): 85.451743 seconds 
Time execution (load saved model): 0.002127 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

58.04598861694336

num_try : 571 | val_loss = 58.04598861694336 | val acc = 7.0543341636657715
Time execution (tranning): 125.955831 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

58.293319854736325

num_try : 437 | val_loss = 58.293319854736325 | val acc = 5.452868461608887
Time execution (tranning): 103.417226 seconds 
Time execution (load saved model): 0.002064 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

58.71218643188477

num_try : 202 | val_loss = 58.71218643188477 | val acc = 7.225675582885742
Time execution (tranning): 90.848636 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

59.26587905883789

num_try : 835 | val_loss = 59.26587905883789 | val acc = 4.407391548156738
Time execution (tranning): 82.600366 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

59.30348419189453

num_try : 916 | val_loss = 59.30348419189453 | val acc = 4.355761528015137
Time execution (tranning): 127.530909 seconds 
Time execution (load saved model): 0.002171 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 362
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

59.34865280151367

num_try : 635 | val_loss = 59.34865280151367 | val acc = 5.416360855102539
Time execution (tranning): 131.794109 seconds 
Time execution (load saved model): 0.002085 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 423
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

59.36543502807617

num_try : 303 | val_loss = 59.36543502807617 | val acc = 7.051774501800537
Time execution (tranning): 99.310449 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

59.527766723632816

num_try : 49 | val_loss = 59.527766723632816 | val acc = 7.272542953491211
Time execution (tranning): 81.072507 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

59.59672233581543

num_try : 132 | val_loss = 59.59672233581543 | val acc = 7.167474746704102
Time execution (tranning): 128.378616 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 429
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

59.653790664672854

num_try : 346 | val_loss = 59.653790664672854 | val acc = 7.259085178375244
Time execution (tranning): 86.195788 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

59.719833297729494

num_try : 554 | val_loss = 59.719833297729494 | val acc = 5.421704292297363
Time execution (tranning): 127.732624 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 416
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

59.82174743652344

num_try : 240 | val_loss = 59.82174743652344 | val acc = 7.083216667175293
Time execution (tranning): 97.058455 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

59.914959564208985

num_try : 880 | val_loss = 59.914959564208985 | val acc = 4.426974296569824
Time execution (tranning): 101.569311 seconds 
Time execution (load saved model): 0.002188 seconds 
Time execution (use saved model): 0.000816 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

59.93331192016601

num_try : 563 | val_loss = 59.93331192016601 | val acc = 5.475837230682373
Time execution (tranning): 119.349921 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000244 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 395
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

60.160931777954104

num_try : 545 | val_loss = 60.160931777954104 | val acc = 5.46389627456665
Time execution (tranning): 39.073015 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 128
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

60.496355056762695

num_try : 952 | val_loss = 60.496355056762695 | val acc = 4.411420822143555
Time execution (tranning): 103.948920 seconds 
Time execution (load saved model): 0.002176 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

60.64311164855957

num_try : 265 | val_loss = 60.64311164855957 | val acc = 7.2367143630981445
Time execution (tranning): 69.618351 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000213 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

60.70754829406738

num_try : 988 | val_loss = 60.70754829406738 | val acc = 4.445242404937744
Time execution (tranning): 113.172501 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

60.815215301513675

num_try : 409 | val_loss = 60.815215301513675 | val acc = 7.26993465423584
Time execution (tranning): 85.144288 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

60.9691429901123

num_try : 644 | val_loss = 60.9691429901123 | val acc = 5.515432357788086
Time execution (tranning): 133.038220 seconds 
Time execution (load saved model): 0.002089 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 420
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

61.03088775634765

num_try : 231 | val_loss = 61.03088775634765 | val acc = 7.105880260467529
Time execution (tranning): 59.912970 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

61.06298599243164

num_try : 420 | val_loss = 61.06298599243164 | val acc = 7.170469284057617
Time execution (tranning): 109.714069 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

61.15660018920899

num_try : 446 | val_loss = 61.15660018920899 | val acc = 5.512869834899902
Time execution (tranning): 75.158934 seconds 
Time execution (load saved model): 0.002068 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

61.24148544311524

num_try : 772 | val_loss = 61.24148544311524 | val acc = 4.448827743530273
Time execution (tranning): 121.336773 seconds 
Time execution (load saved model): 0.002096 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

61.37463150024414

num_try : 1006 | val_loss = 61.37463150024414 | val acc = 4.452106952667236
Time execution (tranning): 135.381434 seconds 
Time execution (load saved model): 0.002159 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 389
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

61.53742874145508

num_try : 184 | val_loss = 61.53742874145508 | val acc = 7.213395595550537
Time execution (tranning): 64.100791 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

61.74084030151367

num_try : 680 | val_loss = 61.74084030151367 | val acc = 5.542238712310791
Time execution (tranning): 123.623844 seconds 
Time execution (load saved model): 0.002076 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 391
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

61.76675270080566

num_try : 391 | val_loss = 61.76675270080566 | val acc = 7.328640937805176
Time execution (tranning): 72.610060 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

61.77992691040039

num_try : 727 | val_loss = 61.77992691040039 | val acc = 4.531224250793457
Time execution (tranning): 80.715891 seconds 
Time execution (load saved model): 0.002191 seconds 
Time execution (use saved model): 0.000338 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

61.938948974609374

num_try : 211 | val_loss = 61.938948974609374 | val acc = 7.403360366821289
Time execution (tranning): 97.041290 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

61.999561080932615

num_try : 961 | val_loss = 61.999561080932615 | val acc = 4.544661045074463
Time execution (tranning): 117.093309 seconds 
Time execution (load saved model): 0.002181 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

62.14511901855469

num_try : 427 | val_loss = 62.14511901855469 | val acc = 7.333298206329346
Time execution (tranning): 83.306980 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

62.18092567443848

num_try : 889 | val_loss = 62.18092567443848 | val acc = 4.607609272003174
Time execution (tranning): 137.959426 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 409
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

62.241967010498044

num_try : 321 | val_loss = 62.241967010498044 | val acc = 7.200427055358887
Time execution (tranning): 119.019571 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 393
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

62.3678840637207

num_try : 85 | val_loss = 62.3678840637207 | val acc = 7.484643459320068
Time execution (tranning): 65.990649 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

62.441304473876954

num_try : 527 | val_loss = 62.441304473876954 | val acc = 5.644202709197998
Time execution (tranning): 121.612192 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 402
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

62.50784759521484

num_try : 274 | val_loss = 62.50784759521484 | val acc = 7.464249134063721
Time execution (tranning): 99.068507 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

62.58967979431152

num_try : 537 | val_loss = 62.58967979431152 | val acc = 7.201200008392334
Time execution (tranning): 92.032403 seconds 
Time execution (load saved model): 0.002072 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

62.83180145263672

num_try : 736 | val_loss = 62.83180145263672 | val acc = 4.491694450378418
Time execution (tranning): 111.991699 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 343
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

62.86801483154297

num_try : 96 | val_loss = 62.86801483154297 | val acc = 7.395322799682617
Time execution (tranning): 118.577835 seconds 
Time execution (load saved model): 0.002017 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 403
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

62.88437553405762

num_try : 790 | val_loss = 62.88437553405762 | val acc = 4.532679557800293
Time execution (tranning): 156.071782 seconds 
Time execution (load saved model): 0.002110 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 479
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

62.93301498413086

num_try : 608 | val_loss = 62.93301498413086 | val acc = 5.622682094573975
Time execution (tranning): 119.404362 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

63.00966972351074

num_try : 844 | val_loss = 63.00966972351074 | val acc = 4.557668685913086
Time execution (tranning): 97.293286 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

63.17554412841797

num_try : 455 | val_loss = 63.17554412841797 | val acc = 5.789550304412842
Time execution (tranning): 107.048554 seconds 
Time execution (load saved model): 0.002067 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

63.42719215393066

num_try : 997 | val_loss = 63.42719215393066 | val acc = 4.633785724639893
Time execution (tranning): 173.747908 seconds 
Time execution (load saved model): 0.002163 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 517
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

63.5126057434082

num_try : 970 | val_loss = 63.5126057434082 | val acc = 4.568446636199951
Time execution (tranning): 150.604898 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 424
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

63.567475967407226

num_try : 149 | val_loss = 63.567475967407226 | val acc = 5.799386978149414
Time execution (tranning): 88.017980 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 296
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

63.59250328063965

num_try : 583 | val_loss = 63.59250328063965 | val acc = 4.692951202392578
Time execution (tranning): 98.983694 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

63.651358642578124

num_try : 384 | val_loss = 63.651358642578124 | val acc = 7.3451409339904785
Time execution (tranning): 108.173034 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

63.71794555664062

num_try : 42 | val_loss = 63.71794555664062 | val acc = 7.150218963623047
Time execution (tranning): 96.880944 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

63.85749206542969

num_try : 826 | val_loss = 63.85749206542969 | val acc = 4.638830184936523
Time execution (tranning): 167.890076 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 518
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

64.10518585205078

num_try : 463 | val_loss = 64.10518585205078 | val acc = 7.464841365814209
Time execution (tranning): 91.398380 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

64.31523193359375

num_try : 123 | val_loss = 64.31523193359375 | val acc = 7.438488960266113
Time execution (tranning): 88.943775 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

64.64358085632324

num_try : 808 | val_loss = 64.64358085632324 | val acc = 4.5872602462768555
Time execution (tranning): 75.360334 seconds 
Time execution (load saved model): 0.002108 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

64.70759315490723

num_try : 411 | val_loss = 64.70759315490723 | val acc = 7.32259464263916
Time execution (tranning): 56.138172 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

64.73109348297119

num_try : 655 | val_loss = 64.73109348297119 | val acc = 4.811360836029053
Time execution (tranning): 83.685817 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

64.8612368774414

num_try : 247 | val_loss = 64.8612368774414 | val acc = 7.583803176879883
Time execution (tranning): 83.110952 seconds 
Time execution (load saved model): 0.002022 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

65.01609062194824

num_try : 862 | val_loss = 65.01609062194824 | val acc = 4.659864902496338
Time execution (tranning): 154.487080 seconds 
Time execution (load saved model): 0.002125 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 474
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

65.15137672424316

num_try : 934 | val_loss = 65.15137672424316 | val acc = 4.635372638702393
Time execution (tranning): 141.915134 seconds 
Time execution (load saved model): 0.002161 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 403
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

65.30064208984375

num_try : 925 | val_loss = 65.30064208984375 | val acc = 4.745392322540283
Time execution (tranning): 125.000356 seconds 
Time execution (load saved model): 0.002162 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 373
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

65.35019989013672

num_try : 853 | val_loss = 65.35019989013672 | val acc = 4.757902145385742
Time execution (tranning): 110.295874 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

65.37717147827148

num_try : 429 | val_loss = 65.37717147827148 | val acc = 7.440089225769043
Time execution (tranning): 167.780140 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 552
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

65.62021133422851

num_try : 401 | val_loss = 65.62021133422851 | val acc = 5.859189033508301
Time execution (tranning): 81.608649 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

65.64124938964844

num_try : 619 | val_loss = 65.64124938964844 | val acc = 4.8252458572387695
Time execution (tranning): 69.512041 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

66.37758476257324

num_try : 249 | val_loss = 66.37758476257324 | val acc = 7.562637805938721
Time execution (tranning): 97.943463 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

66.56013763427734

num_try : 283 | val_loss = 66.56013763427734 | val acc = 7.683796405792236
Time execution (tranning): 92.122035 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

66.57965034484863

num_try : 121 | val_loss = 66.57965034484863 | val acc = 7.8558759689331055
Time execution (tranning): 97.962023 seconds 
Time execution (load saved model): 0.002018 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

66.6315382385254

num_try : 781 | val_loss = 66.6315382385254 | val acc = 4.9025139808654785
Time execution (tranning): 136.838254 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 437
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

66.91720588684082

num_try : 221 | val_loss = 66.91720588684082 | val acc = 5.897924423217773
Time execution (tranning): 62.328929 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

66.95313781738281

num_try : 175 | val_loss = 66.95313781738281 | val acc = 7.674985408782959
Time execution (tranning): 63.857070 seconds 
Time execution (load saved model): 0.002023 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

67.06739868164063

num_try : 285 | val_loss = 67.06739868164063 | val acc = 7.569057464599609
Time execution (tranning): 79.801300 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000214 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

67.12247825622559

num_try : 482 | val_loss = 67.12247825622559 | val acc = 5.826597690582275
Time execution (tranning): 90.032807 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

67.20444213867188

num_try : 691 | val_loss = 67.20444213867188 | val acc = 4.907773494720459
Time execution (tranning): 71.409958 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

67.2897673034668

num_try : 535 | val_loss = 67.2897673034668 | val acc = 7.687629222869873
Time execution (tranning): 110.995539 seconds 
Time execution (load saved model): 0.002078 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

67.45102752685547

num_try : 213 | val_loss = 67.45102752685547 | val acc = 7.549194812774658
Time execution (tranning): 90.448669 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

67.57988662719727

num_try : 267 | val_loss = 67.57988662719727 | val acc = 7.577978610992432
Time execution (tranning): 62.640394 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

67.6259154510498

num_try : 817 | val_loss = 67.6259154510498 | val acc = 4.963630199432373
Time execution (tranning): 147.698371 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 472
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

67.68502182006836

num_try : 15 | val_loss = 67.68502182006836 | val acc = 7.697030067443848
Time execution (tranning): 75.467907 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

67.9347412109375

num_try : 745 | val_loss = 67.9347412109375 | val acc = 4.865884304046631
Time execution (tranning): 127.739104 seconds 
Time execution (load saved model): 0.002107 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 406
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

68.17319847106934

num_try : 592 | val_loss = 68.17319847106934 | val acc = 4.90372371673584
Time execution (tranning): 78.638030 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

68.45241584777833

num_try : 898 | val_loss = 68.45241584777833 | val acc = 4.824831962585449
Time execution (tranning): 132.101545 seconds 
Time execution (load saved model): 0.002188 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 370
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

68.51348098754883

num_try : 518 | val_loss = 68.51348098754883 | val acc = 5.964283466339111
Time execution (tranning): 94.440460 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

68.52929351806641

num_try : 754 | val_loss = 68.52929351806641 | val acc = 4.785879135131836
Time execution (tranning): 124.802302 seconds 
Time execution (load saved model): 0.002128 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 383
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

68.870298538208

num_try : 664 | val_loss = 68.870298538208 | val acc = 4.851461410522461
Time execution (tranning): 86.785466 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

69.16141403198242

num_try : 419 | val_loss = 69.16141403198242 | val acc = 6.328313827514648
Time execution (tranning): 124.337361 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

69.18709991455079

num_try : 60 | val_loss = 69.18709991455079 | val acc = 7.726390361785889
Time execution (tranning): 84.576815 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

69.32326484680176

num_try : 536 | val_loss = 69.32326484680176 | val acc = 5.989741802215576
Time execution (tranning): 126.230758 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 411
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

69.3403288269043

num_try : 113 | val_loss = 69.3403288269043 | val acc = 6.037509918212891
Time execution (tranning): 127.189476 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 427
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

69.41325531005859

num_try : 637 | val_loss = 69.41325531005859 | val acc = 5.0604777336120605
Time execution (tranning): 132.245746 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 424
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

69.94596649169922

num_try : 103 | val_loss = 69.94596649169922 | val acc = 7.909204006195068
Time execution (tranning): 97.934828 seconds 
Time execution (load saved model): 0.002018 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

70.24265892028808

num_try : 700 | val_loss = 70.24265892028808 | val acc = 4.915506362915039
Time execution (tranning): 60.664461 seconds 
Time execution (load saved model): 0.002074 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

70.35027053833008

num_try : 365 | val_loss = 70.35027053833008 | val acc = 6.068180561065674
Time execution (tranning): 81.457753 seconds 
Time execution (load saved model): 0.002027 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

70.38300354003906

num_try : 87 | val_loss = 70.38300354003906 | val acc = 7.819606304168701
Time execution (tranning): 66.463881 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

70.55461990356446

num_try : 628 | val_loss = 70.55461990356446 | val acc = 4.932272434234619
Time execution (tranning): 102.166376 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

70.84467224121094

num_try : 329 | val_loss = 70.84467224121094 | val acc = 6.140228748321533
Time execution (tranning): 79.818764 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

70.94832748413086

num_try : 465 | val_loss = 70.94832748413086 | val acc = 7.757174015045166
Time execution (tranning): 67.865059 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

71.29042556762695

num_try : 319 | val_loss = 71.29042556762695 | val acc = 8.003188133239746
Time execution (tranning): 93.487850 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

71.62318023681641

num_try : 105 | val_loss = 71.62318023681641 | val acc = 7.884757041931152
Time execution (tranning): 92.232358 seconds 
Time execution (load saved model): 0.002019 seconds 
Time execution (use saved model): 0.000213 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

71.9741163635254

num_try : 95 | val_loss = 71.9741163635254 | val acc = 6.477474212646484
Time execution (tranning): 135.248463 seconds 
Time execution (load saved model): 0.002019 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 462
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

72.14161926269531

num_try : 393 | val_loss = 72.14161926269531 | val acc = 7.886090278625488
Time execution (tranning): 70.208772 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

72.71541259765625

num_try : 159 | val_loss = 72.71541259765625 | val acc = 7.937417984008789
Time execution (tranning): 83.623061 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

72.78388442993165

num_try : 195 | val_loss = 72.78388442993165 | val acc = 7.874242782592773
Time execution (tranning): 62.798507 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

72.90357650756836

num_try : 355 | val_loss = 72.90357650756836 | val acc = 8.148124694824219
Time execution (tranning): 86.213107 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

73.17144348144531

num_try : 375 | val_loss = 73.17144348144531 | val acc = 7.9007673263549805
Time execution (tranning): 60.487931 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

73.43137161254883

num_try : 339 | val_loss = 73.43137161254883 | val acc = 7.855533599853516
Time execution (tranning): 53.848402 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 175
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

73.43746871948242

num_try : 31 | val_loss = 73.43746871948242 | val acc = 8.157794952392578
Time execution (tranning): 72.213396 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000214 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

73.54706344604492

num_try : 157 | val_loss = 73.54706344604492 | val acc = 8.103899955749512
Time execution (tranning): 69.118120 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

73.73542846679688

num_try : 13 | val_loss = 73.73542846679688 | val acc = 8.210790634155273
Time execution (tranning): 39.081754 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 128
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

73.82288513183593

num_try : 33 | val_loss = 73.82288513183593 | val acc = 7.936871528625488
Time execution (tranning): 78.341860 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

74.34302459716797

num_try : 41 | val_loss = 74.34302459716797 | val acc = 6.360147476196289
Time execution (tranning): 82.235653 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 275
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

74.37180297851563

num_try : 357 | val_loss = 74.37180297851563 | val acc = 8.034233093261719
Time execution (tranning): 81.029988 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

74.69923873901367

num_try : 139 | val_loss = 74.69923873901367 | val acc = 8.167489051818848
Time execution (tranning): 85.586053 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

74.78203231811523

num_try : 439 | val_loss = 74.78203231811523 | val acc = 5.344723701477051
Time execution (tranning): 99.917452 seconds 
Time execution (load saved model): 0.002072 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

74.94947761535644

num_try : 257 | val_loss = 74.94947761535644 | val acc = 6.35462760925293
Time execution (tranning): 61.300779 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

74.9554133605957

num_try : 511 | val_loss = 74.9554133605957 | val acc = 5.278421401977539
Time execution (tranning): 80.362203 seconds 
Time execution (load saved model): 0.002065 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

75.1467970275879

num_try : 67 | val_loss = 75.1467970275879 | val acc = 8.259142875671387
Time execution (tranning): 78.701568 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

75.19391983032227

num_try : 275 | val_loss = 75.19391983032227 | val acc = 6.551126003265381
Time execution (tranning): 115.829191 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 388
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

75.26987197875977

num_try : 51 | val_loss = 75.26987197875977 | val acc = 8.17011547088623
Time execution (tranning): 110.730133 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

75.53581069946289

num_try : 141 | val_loss = 75.53581069946289 | val acc = 8.074285507202148
Time execution (tranning): 57.789296 seconds 
Time execution (load saved model): 0.002030 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

75.61850387573242

num_try : 709 | val_loss = 75.61850387573242 | val acc = 5.313042163848877
Time execution (tranning): 139.037598 seconds 
Time execution (load saved model): 0.002097 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 445
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

75.73195175170899

num_try : 610 | val_loss = 75.73195175170899 | val acc = 5.168272018432617
Time execution (tranning): 146.247899 seconds 
Time execution (load saved model): 0.002090 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 459
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

76.27808883666992

num_try : 464 | val_loss = 76.27808883666992 | val acc = 6.585073471069336
Time execution (tranning): 154.016721 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 503
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

76.39494277954101

num_try : 239 | val_loss = 76.39494277954101 | val acc = 6.668457508087158
Time execution (tranning): 92.021157 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

76.77239318847656

num_try : 79 | val_loss = 76.77239318847656 | val acc = 5.3259477615356445
Time execution (tranning): 96.991518 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

76.89858337402343

num_try : 5 | val_loss = 76.89858337402343 | val acc = 6.575190544128418
Time execution (tranning): 63.088279 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

76.90547012329101

num_try : 293 | val_loss = 76.90547012329101 | val acc = 6.434972763061523
Time execution (tranning): 105.242400 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 348
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

76.96045211791993

num_try : 177 | val_loss = 76.96045211791993 | val acc = 8.169811248779297
Time execution (tranning): 58.275080 seconds 
Time execution (load saved model): 0.002025 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

77.0016089630127

num_try : 529 | val_loss = 77.0016089630127 | val acc = 5.386167526245117
Time execution (tranning): 166.371894 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 559
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

77.06788192749023

num_try : 69 | val_loss = 77.06788192749023 | val acc = 8.179084777832031
Time execution (tranning): 64.496539 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

77.222201461792

num_try : 475 | val_loss = 77.222201461792 | val acc = 5.434849739074707
Time execution (tranning): 81.621964 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

77.39882675170898

num_try : 601 | val_loss = 77.39882675170898 | val acc = 5.444331645965576
Time execution (tranning): 106.709102 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

78.28272773742675

num_try : 682 | val_loss = 78.28272773742675 | val acc = 5.321627616882324
Time execution (tranning): 117.942186 seconds 
Time execution (load saved model): 0.002079 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

78.40225128173829

num_try : 547 | val_loss = 78.40225128173829 | val acc = 5.552402496337891
Time execution (tranning): 57.846226 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

78.42735870361328

num_try : 383 | val_loss = 78.42735870361328 | val acc = 6.667168617248535
Time execution (tranning): 94.834150 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

78.43698974609374

num_try : 457 | val_loss = 78.43698974609374 | val acc = 5.510203838348389
Time execution (tranning): 132.075238 seconds 
Time execution (load saved model): 0.002067 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 438
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

78.46747772216797

num_try : 673 | val_loss = 78.46747772216797 | val acc = 5.516036510467529
Time execution (tranning): 118.535155 seconds 
Time execution (load saved model): 0.002082 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

79.19423400878907

num_try : 565 | val_loss = 79.19423400878907 | val acc = 5.455028533935547
Time execution (tranning): 134.538149 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 442
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

79.28806205749511

num_try : 646 | val_loss = 79.28806205749511 | val acc = 5.403642654418945
Time execution (tranning): 152.165276 seconds 
Time execution (load saved model): 0.002088 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 477
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

79.4975961303711

num_try : 374 | val_loss = 79.4975961303711 | val acc = 6.780405044555664
Time execution (tranning): 67.219317 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

79.85853424072266

num_try : 403 | val_loss = 79.85853424072266 | val acc = 5.611114025115967
Time execution (tranning): 102.513675 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

79.95881469726562

num_try : 367 | val_loss = 79.95881469726562 | val acc = 5.564886093139648
Time execution (tranning): 84.902548 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

79.97749160766601

num_try : 347 | val_loss = 79.97749160766601 | val acc = 6.7474141120910645
Time execution (tranning): 95.076192 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

80.09740463256836

num_try : 295 | val_loss = 80.09740463256836 | val acc = 5.53858757019043
Time execution (tranning): 78.893808 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

80.87721298217774

num_try : 167 | val_loss = 80.87721298217774 | val acc = 6.922950267791748
Time execution (tranning): 111.243728 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 373
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

81.06572250366212

num_try : 331 | val_loss = 81.06572250366212 | val acc = 5.611831188201904
Time execution (tranning): 105.895173 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

81.93954238891601

num_try : 311 | val_loss = 81.93954238891601 | val acc = 6.870660305023193
Time execution (tranning): 85.860494 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

82.65257293701171

num_try : 77 | val_loss = 82.65257293701171 | val acc = 6.740485668182373
Time execution (tranning): 94.439224 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

83.15640640258789

num_try : 718 | val_loss = 83.15640640258789 | val acc = 5.547330856323242
Time execution (tranning): 126.483052 seconds 
Time execution (load saved model): 0.002085 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

83.42829238891602

num_try : 187 | val_loss = 83.42829238891602 | val acc = 5.76312255859375
Time execution (tranning): 81.379700 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

83.94653259277344

num_try : 131 | val_loss = 83.94653259277344 | val acc = 7.176236629486084
Time execution (tranning): 105.136556 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

84.0397410583496

num_try : 500 | val_loss = 84.0397410583496 | val acc = 7.001284599304199
Time execution (tranning): 138.100527 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 451
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

84.61077865600586

num_try : 944 | val_loss = 84.61077865600586 | val acc = 4.340891361236572
Time execution (tranning): 96.600142 seconds 
Time execution (load saved model): 0.002173 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

84.7296678161621

num_try : 338 | val_loss = 84.7296678161621 | val acc = 6.988253116607666
Time execution (tranning): 82.340572 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

84.84917907714843

num_try : 259 | val_loss = 84.84917907714843 | val acc = 5.776866436004639
Time execution (tranning): 114.271613 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 380
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

84.92523101806641

num_try : 158 | val_loss = 84.92523101806641 | val acc = 7.0720391273498535
Time execution (tranning): 93.651180 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

85.42877319335938

num_try : 412 | val_loss = 85.42877319335938 | val acc = 5.8548431396484375
Time execution (tranning): 78.231995 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

85.5893276977539

num_try : 203 | val_loss = 85.5893276977539 | val acc = 7.094203948974609
Time execution (tranning): 69.645521 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

86.13076080322266

num_try : 23 | val_loss = 86.13076080322266 | val acc = 7.2736992835998535
Time execution (tranning): 140.483056 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 476
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

86.26960136413574

num_try : 908 | val_loss = 86.26960136413574 | val acc = 4.3938069343566895
Time execution (tranning): 92.202517 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

86.2972329711914

num_try : 284 | val_loss = 86.2972329711914 | val acc = 7.0935587882995605
Time execution (tranning): 94.452945 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

86.36889198303223

num_try : 872 | val_loss = 86.36889198303223 | val acc = 4.467183589935303
Time execution (tranning): 76.828950 seconds 
Time execution (load saved model): 0.002169 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

86.73685668945312

num_try : 205 | val_loss = 86.73685668945312 | val acc = 6.010255336761475
Time execution (tranning): 118.862743 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 395
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

86.86104942321778

num_try : 764 | val_loss = 86.86104942321778 | val acc = 4.3495707511901855
Time execution (tranning): 94.386720 seconds 
Time execution (load saved model): 0.002130 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

86.95214233398437

num_try : 484 | val_loss = 86.95214233398437 | val acc = 5.814487934112549
Time execution (tranning): 103.718195 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

87.1081364440918

num_try : 448 | val_loss = 87.1081364440918 | val acc = 5.687513828277588
Time execution (tranning): 80.032131 seconds 
Time execution (load saved model): 0.002066 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

87.22273719787597

num_try : 728 | val_loss = 87.22273719787597 | val acc = 4.472033977508545
Time execution (tranning): 93.103809 seconds 
Time execution (load saved model): 0.002119 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

87.6079411315918

num_try : 809 | val_loss = 87.6079411315918 | val acc = 4.392669200897217
Time execution (tranning): 90.348385 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

87.70310928344726

num_try : 572 | val_loss = 87.70310928344726 | val acc = 7.169791221618652
Time execution (tranning): 103.708354 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

87.74132888793946

num_try : 230 | val_loss = 87.74132888793946 | val acc = 7.235132217407227
Time execution (tranning): 87.390893 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

87.77711151123047

num_try : 881 | val_loss = 87.77711151123047 | val acc = 4.432920932769775
Time execution (tranning): 123.756504 seconds 
Time execution (load saved model): 0.002141 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

87.77864837646484

num_try : 980 | val_loss = 87.77864837646484 | val acc = 4.488070487976074
Time execution (tranning): 83.263077 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

88.05951721191406

num_try : 220 | val_loss = 88.05951721191406 | val acc = 9.069260597229004
Time execution (tranning): 31.781123 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 105
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

88.39581909179688

num_try : 421 | val_loss = 88.39581909179688 | val acc = 6.147867202758789
Time execution (tranning): 124.601553 seconds 
Time execution (load saved model): 0.002065 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

88.5386050415039

num_try : 493 | val_loss = 88.5386050415039 | val acc = 5.912741661071777
Time execution (tranning): 97.204535 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

88.55213287353516

num_try : 302 | val_loss = 88.55213287353516 | val acc = 7.168317794799805
Time execution (tranning): 68.357417 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

88.55335388183593

num_try : 223 | val_loss = 88.55335388183593 | val acc = 5.903536319732666
Time execution (tranning): 73.266200 seconds 
Time execution (load saved model): 0.002027 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

89.00945236206054

num_try : 935 | val_loss = 89.00945236206054 | val acc = 4.403541564941406
Time execution (tranning): 156.689314 seconds 
Time execution (load saved model): 0.002181 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

89.0378092956543

num_try : 953 | val_loss = 89.0378092956543 | val acc = 4.4348344802856445
Time execution (tranning): 90.782741 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

89.25085189819336

num_try : 917 | val_loss = 89.25085189819336 | val acc = 4.5152716636657715
Time execution (tranning): 120.593915 seconds 
Time execution (load saved model): 0.002179 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

89.25564918518066

num_try : 836 | val_loss = 89.25564918518066 | val acc = 4.474491596221924
Time execution (tranning): 63.983971 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

89.4835888671875

num_try : 845 | val_loss = 89.4835888671875 | val acc = 4.462231159210205
Time execution (tranning): 94.819152 seconds 
Time execution (load saved model): 0.002111 seconds 
Time execution (use saved model): 0.000237 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

89.91728958129883

num_try : 186 | val_loss = 89.91728958129883 | val acc = 8.97347640991211
Time execution (tranning): 35.636949 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 116
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 0.5}
----------

90.16838104248046

num_try : 313 | val_loss = 90.16838104248046 | val acc = 6.046654224395752
Time execution (tranning): 128.147846 seconds 
Time execution (load saved model): 0.002065 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 424
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

90.77984130859375

num_try : 556 | val_loss = 90.77984130859375 | val acc = 5.952913761138916
Time execution (tranning): 72.760628 seconds 
Time execution (load saved model): 0.002073 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

90.9465870666504

num_try : 266 | val_loss = 90.9465870666504 | val acc = 7.31004524230957
Time execution (tranning): 79.673918 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

91.06466979980469

num_try : 899 | val_loss = 91.06466979980469 | val acc = 4.4810261726379395
Time execution (tranning): 170.083633 seconds 
Time execution (load saved model): 0.002181 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 477
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

91.07789779663086

num_try : 890 | val_loss = 91.07789779663086 | val acc = 4.560809135437012
Time execution (tranning): 132.697506 seconds 
Time execution (load saved model): 0.002174 seconds 
Time execution (use saved model): 0.000240 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

91.3785189819336

num_try : 971 | val_loss = 91.3785189819336 | val acc = 4.473450183868408
Time execution (tranning): 132.353866 seconds 
Time execution (load saved model): 0.002177 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 372
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

91.39338043212891

num_try : 854 | val_loss = 91.39338043212891 | val acc = 4.6210408210754395
Time execution (tranning): 184.324141 seconds 
Time execution (load saved model): 0.002122 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 585
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

91.45693298339843

num_try : 773 | val_loss = 91.45693298339843 | val acc = 4.475391387939453
Time execution (tranning): 85.556461 seconds 
Time execution (load saved model): 0.002098 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

91.67139526367187

num_try : 520 | val_loss = 91.67139526367187 | val acc = 6.044985771179199
Time execution (tranning): 84.725508 seconds 
Time execution (load saved model): 0.002119 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

92.12965103149413

num_try : 692 | val_loss = 92.12965103149413 | val acc = 4.6235671043396
Time execution (tranning): 88.624695 seconds 
Time execution (load saved model): 0.002081 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

92.43913803100585

num_try : 320 | val_loss = 92.43913803100585 | val acc = 7.410000801086426
Time execution (tranning): 106.914615 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

92.76277633666992

num_try : 989 | val_loss = 92.76277633666992 | val acc = 4.538799285888672
Time execution (tranning): 91.323403 seconds 
Time execution (load saved model): 0.002188 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

93.24698989868165

num_try : 248 | val_loss = 93.24698989868165 | val acc = 7.41615104675293
Time execution (tranning): 93.281340 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

93.2554360961914

num_try : 122 | val_loss = 93.2554360961914 | val acc = 7.545322418212891
Time execution (tranning): 59.339297 seconds 
Time execution (load saved model): 0.002019 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

93.43912368774414

num_try : 169 | val_loss = 93.43912368774414 | val acc = 6.3091230392456055
Time execution (tranning): 144.549911 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 484
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

93.67490158081054

num_try : 656 | val_loss = 93.67490158081054 | val acc = 4.7767438888549805
Time execution (tranning): 94.230260 seconds 
Time execution (load saved model): 0.002127 seconds 
Time execution (use saved model): 0.000228 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

93.83422271728516

num_try : 212 | val_loss = 93.83422271728516 | val acc = 7.461904525756836
Time execution (tranning): 74.700488 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

93.87023818969726

num_try : 61 | val_loss = 93.87023818969726 | val acc = 6.3941168785095215
Time execution (tranning): 159.795498 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 539
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

94.25259513854981

num_try : 791 | val_loss = 94.25259513854981 | val acc = 4.550360679626465
Time execution (tranning): 150.681384 seconds 
Time execution (load saved model): 0.002101 seconds 
Time execution (use saved model): 0.000230 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 464
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

94.33133743286133

num_try : 755 | val_loss = 94.33133743286133 | val acc = 4.561809062957764
Time execution (tranning): 126.336796 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 386
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

94.72311538696289

num_try : 998 | val_loss = 94.72311538696289 | val acc = 4.754101276397705
Time execution (tranning): 139.942987 seconds 
Time execution (load saved model): 0.002229 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 416
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

95.30400497436523

num_try : 800 | val_loss = 95.30400497436523 | val acc = 4.724427700042725
Time execution (tranning): 63.416196 seconds 
Time execution (load saved model): 0.002114 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

95.76171005249023

num_try : 782 | val_loss = 95.76171005249023 | val acc = 4.796519756317139
Time execution (tranning): 144.088988 seconds 
Time execution (load saved model): 0.002122 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 454
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

95.79403732299805

num_try : 701 | val_loss = 95.79403732299805 | val acc = 4.6369853019714355
Time execution (tranning): 91.943126 seconds 
Time execution (load saved model): 0.002077 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

96.52986404418945

num_try : 962 | val_loss = 96.52986404418945 | val acc = 4.816384792327881
Time execution (tranning): 117.039443 seconds 
Time execution (load saved model): 0.002150 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

96.84721450805664

num_try : 59 | val_loss = 96.84721450805664 | val acc = 7.671318531036377
Time execution (tranning): 78.561615 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

97.64986297607422

num_try : 104 | val_loss = 97.64986297607422 | val acc = 7.647758960723877
Time execution (tranning): 85.368856 seconds 
Time execution (load saved model): 0.002022 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

97.71869567871094

num_try : 863 | val_loss = 97.71869567871094 | val acc = 4.706254482269287
Time execution (tranning): 150.869054 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 464
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

97.88209144592285

num_try : 620 | val_loss = 97.88209144592285 | val acc = 4.877854347229004
Time execution (tranning): 67.379961 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

98.54074188232421

num_try : 818 | val_loss = 98.54074188232421 | val acc = 4.896690845489502
Time execution (tranning): 159.301347 seconds 
Time execution (load saved model): 0.002109 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 505
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

99.27196411132813

num_try : 593 | val_loss = 99.27196411132813 | val acc = 4.800135612487793
Time execution (tranning): 64.108207 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

99.41991638183593

num_try : 737 | val_loss = 99.41991638183593 | val acc = 4.795534610748291
Time execution (tranning): 56.110450 seconds 
Time execution (load saved model): 0.002106 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 171
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

99.75282363891601

num_try : 140 | val_loss = 99.75282363891601 | val acc = 7.763327598571777
Time execution (tranning): 75.583451 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

100.24525131225586

num_try : 746 | val_loss = 100.24525131225586 | val acc = 4.918880462646484
Time execution (tranning): 112.874830 seconds 
Time execution (load saved model): 0.002104 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

100.40137924194336

num_try : 50 | val_loss = 100.40137924194336 | val acc = 7.820223808288574
Time execution (tranning): 66.514844 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

101.13517822265625

num_try : 194 | val_loss = 101.13517822265625 | val acc = 7.803143501281738
Time execution (tranning): 85.380125 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

101.2129345703125

num_try : 356 | val_loss = 101.2129345703125 | val acc = 7.81748104095459
Time execution (tranning): 79.379945 seconds 
Time execution (load saved model): 0.002030 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

101.31025970458984

num_try : 376 | val_loss = 101.31025970458984 | val acc = 6.643953323364258
Time execution (tranning): 109.855459 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

101.62176208496093

num_try : 410 | val_loss = 101.62176208496093 | val acc = 7.788911819458008
Time execution (tranning): 70.103576 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

101.71869125366212

num_try : 392 | val_loss = 101.71869125366212 | val acc = 7.84896993637085
Time execution (tranning): 71.965992 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

101.72103126525879

num_try : 629 | val_loss = 101.72103126525879 | val acc = 4.850376129150391
Time execution (tranning): 88.485911 seconds 
Time execution (load saved model): 0.002092 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

102.43764465332032

num_try : 43 | val_loss = 102.43764465332032 | val acc = 6.405760288238525
Time execution (tranning): 65.520146 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

102.47272567749023

num_try : 548 | val_loss = 102.47272567749023 | val acc = 5.189124584197998
Time execution (tranning): 85.910196 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

102.48418014526368

num_try : 86 | val_loss = 102.48418014526368 | val acc = 8.067361831665039
Time execution (tranning): 70.902318 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

102.79322174072266

num_try : 827 | val_loss = 102.79322174072266 | val acc = 4.876081943511963
Time execution (tranning): 147.941148 seconds 
Time execution (load saved model): 0.002106 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 457
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

102.99520111083984

num_try : 176 | val_loss = 102.99520111083984 | val acc = 7.877178192138672
Time execution (tranning): 82.040188 seconds 
Time execution (load saved model): 0.002023 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

103.89663665771485

num_try : 68 | val_loss = 103.89663665771485 | val acc = 7.907956600189209
Time execution (tranning): 73.481043 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

103.94731338500976

num_try : 584 | val_loss = 103.94731338500976 | val acc = 5.074218273162842
Time execution (tranning): 127.941959 seconds 
Time execution (load saved model): 0.002064 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 418
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

104.05539581298828

num_try : 494 | val_loss = 104.05539581298828 | val acc = 5.164448261260986
Time execution (tranning): 183.161339 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 607
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

104.77058059692382

num_try : 151 | val_loss = 104.77058059692382 | val acc = 6.529162406921387
Time execution (tranning): 66.335053 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

105.21519393920899

num_try : 385 | val_loss = 105.21519393920899 | val acc = 6.737478733062744
Time execution (tranning): 129.512043 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000236 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 434
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

105.9662971496582

num_try : 476 | val_loss = 105.9662971496582 | val acc = 5.2167277336120605
Time execution (tranning): 95.035061 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

106.4101171875

num_try : 674 | val_loss = 106.4101171875 | val acc = 5.227129936218262
Time execution (tranning): 145.422779 seconds 
Time execution (load saved model): 0.002075 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 474
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

106.67163986206054

num_try : 32 | val_loss = 106.67163986206054 | val acc = 8.028764724731445
Time execution (tranning): 56.507160 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 187
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

106.84701736450195

num_try : 428 | val_loss = 106.84701736450195 | val acc = 8.082771301269531
Time execution (tranning): 75.400307 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

106.9162759399414

num_try : 349 | val_loss = 106.9162759399414 | val acc = 6.758459568023682
Time execution (tranning): 97.823547 seconds 
Time execution (load saved model): 0.002062 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

107.17540344238282

num_try : 611 | val_loss = 107.17540344238282 | val acc = 5.041630744934082
Time execution (tranning): 176.960598 seconds 
Time execution (load saved model): 0.002088 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 557
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

107.55607315063476

num_try : 665 | val_loss = 107.55607315063476 | val acc = 4.990100860595703
Time execution (tranning): 56.207247 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 179
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

107.8466650390625

num_try : 1007 | val_loss = 107.8466650390625 | val acc = 5.072483062744141
Time execution (tranning): 130.817919 seconds 
Time execution (load saved model): 0.002172 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 376
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

107.88976608276367

num_try : 602 | val_loss = 107.88976608276367 | val acc = 5.150417327880859
Time execution (tranning): 124.225420 seconds 
Time execution (load saved model): 0.002075 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 404
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

108.88089096069336

num_try : 14 | val_loss = 108.88089096069336 | val acc = 8.144559860229492
Time execution (tranning): 79.696235 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000229 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

108.89669128417968

num_try : 440 | val_loss = 108.89669128417968 | val acc = 5.291147232055664
Time execution (tranning): 99.315708 seconds 
Time execution (load saved model): 0.002069 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

109.93963333129882

num_try : 926 | val_loss = 109.93963333129882 | val acc = 5.249566555023193
Time execution (tranning): 70.365554 seconds 
Time execution (load saved model): 0.002228 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[1024],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

109.95602661132813

num_try : 304 | val_loss = 109.95602661132813 | val acc = 6.893865585327148
Time execution (tranning): 75.506987 seconds 
Time execution (load saved model): 0.002046 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

110.81993591308594

num_try : 710 | val_loss = 110.81993591308594 | val acc = 5.307615756988525
Time execution (tranning): 111.494454 seconds 
Time execution (load saved model): 0.002095 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

112.41711242675781

num_try : 241 | val_loss = 112.41711242675781 | val acc = 7.045139789581299
Time execution (tranning): 100.253784 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

112.86550689697266

num_try : 647 | val_loss = 112.86550689697266 | val acc = 5.236755847930908
Time execution (tranning): 172.238703 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 543
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

112.90994827270508

num_try : 512 | val_loss = 112.90994827270508 | val acc = 5.434130668640137
Time execution (tranning): 76.804972 seconds 
Time execution (load saved model): 0.002071 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

113.2157144165039

num_try : 115 | val_loss = 113.2157144165039 | val acc = 6.877171516418457
Time execution (tranning): 85.432848 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

113.6205372619629

num_try : 7 | val_loss = 113.6205372619629 | val acc = 6.884038925170898
Time execution (tranning): 55.043773 seconds 
Time execution (load saved model): 0.002045 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

115.97175354003906

num_try : 196 | val_loss = 115.97175354003906 | val acc = 7.122410774230957
Time execution (tranning): 77.672493 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

116.72076202392579

num_try : 538 | val_loss = 116.72076202392579 | val acc = 7.146153450012207
Time execution (tranning): 89.479721 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000234 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

117.78481536865235

num_try : 394 | val_loss = 117.78481536865235 | val acc = 7.205106735229492
Time execution (tranning): 113.521976 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 374
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

117.85000534057617

num_try : 485 | val_loss = 117.85000534057617 | val acc = 5.5200676918029785
Time execution (tranning): 139.118509 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 456
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

118.19238510131837

num_try : 340 | val_loss = 118.19238510131837 | val acc = 7.2383503913879395
Time execution (tranning): 93.015358 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000231 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

118.75689453125

num_try : 268 | val_loss = 118.75689453125 | val acc = 7.281637191772461
Time execution (tranning): 79.759469 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 263
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

118.82108795166016

num_try : 133 | val_loss = 118.82108795166016 | val acc = 7.339727401733398
Time execution (tranning): 71.126926 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

119.06064910888672

num_try : 638 | val_loss = 119.06064910888672 | val acc = 5.576847076416016
Time execution (tranning): 106.683482 seconds 
Time execution (load saved model): 0.002094 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

120.36843658447266

num_try : 683 | val_loss = 120.36843658447266 | val acc = 5.484553337097168
Time execution (tranning): 113.417805 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 362
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

120.86024826049805

num_try : 16 | val_loss = 120.86024826049805 | val acc = 7.439201831817627
Time execution (tranning): 74.222562 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

120.92803375244141

num_try : 88 | val_loss = 120.92803375244141 | val acc = 7.4196648597717285
Time execution (tranning): 66.291699 seconds 
Time execution (load saved model): 0.002040 seconds 
Time execution (use saved model): 0.000226 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

121.35707229614258

num_try : 124 | val_loss = 121.35707229614258 | val acc = 7.407542705535889
Time execution (tranning): 71.072291 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

121.48077484130859

num_try : 277 | val_loss = 121.48077484130859 | val acc = 7.440920829772949
Time execution (tranning): 101.388684 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000238 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

121.59361892700196

num_try : 530 | val_loss = 121.59361892700196 | val acc = 5.639532089233398
Time execution (tranning): 107.604084 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000224 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 361
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

121.87638534545898

num_try : 466 | val_loss = 121.87638534545898 | val acc = 7.364498138427734
Time execution (tranning): 78.310793 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

122.11092605590821

num_try : 719 | val_loss = 122.11092605590821 | val acc = 5.533054351806641
Time execution (tranning): 104.644857 seconds 
Time execution (load saved model): 0.002091 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

122.74532257080078

num_try : 574 | val_loss = 122.74532257080078 | val acc = 7.344368934631348
Time execution (tranning): 115.971970 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 377
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

122.94471313476562

num_try : 386 | val_loss = 122.94471313476562 | val acc = 5.8049492835998535
Time execution (tranning): 113.875656 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 377
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

123.52183670043945

num_try : 422 | val_loss = 123.52183670043945 | val acc = 5.760451793670654
Time execution (tranning): 143.049675 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 474
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

124.1546548461914

num_try : 97 | val_loss = 124.1546548461914 | val acc = 7.538904190063477
Time execution (tranning): 61.336917 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

125.2826628112793

num_try : 214 | val_loss = 125.2826628112793 | val acc = 7.431281566619873
Time execution (tranning): 82.617654 seconds 
Time execution (load saved model): 0.002049 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

125.38980712890626

num_try : 458 | val_loss = 125.38980712890626 | val acc = 5.769686222076416
Time execution (tranning): 123.150810 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 409
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

125.71296447753906

num_try : 52 | val_loss = 125.71296447753906 | val acc = 7.617560386657715
Time execution (tranning): 68.105092 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000235 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

125.82618469238281

num_try : 250 | val_loss = 125.82618469238281 | val acc = 7.478377819061279
Time execution (tranning): 93.280972 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

126.24138549804688

num_try : 502 | val_loss = 126.24138549804688 | val acc = 7.507707595825195
Time execution (tranning): 92.516158 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

126.2807241821289

num_try : 178 | val_loss = 126.2807241821289 | val acc = 7.474636077880859
Time execution (tranning): 65.474971 seconds 
Time execution (load saved model): 0.002022 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

126.30448684692382

num_try : 404 | val_loss = 126.30448684692382 | val acc = 5.911599159240723
Time execution (tranning): 111.336149 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 371
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

127.71605575561523

num_try : 152 | val_loss = 127.71605575561523 | val acc = 5.863886833190918
Time execution (tranning): 88.990617 seconds 
Time execution (load saved model): 0.002054 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 296
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

127.7861134338379

num_try : 566 | val_loss = 127.7861134338379 | val acc = 5.880317211151123
Time execution (tranning): 121.815873 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 401
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

127.90804992675781

num_try : 185 | val_loss = 127.90804992675781 | val acc = 8.981042861938477
Time execution (tranning): 64.193975 seconds 
Time execution (load saved model): 0.002028 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.5}
----------

128.14597534179688

num_try : 358 | val_loss = 128.14597534179688 | val acc = 7.5529279708862305
Time execution (tranning): 93.108183 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

130.1228190612793

num_try : 25 | val_loss = 130.1228190612793 | val acc = 7.647063732147217
Time execution (tranning): 89.251054 seconds 
Time execution (load saved model): 0.002029 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

132.72076492309571

num_try : 332 | val_loss = 132.72076492309571 | val acc = 5.976311206817627
Time execution (tranning): 117.839807 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 391
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

133.99475128173827

num_try : 98 | val_loss = 133.99475128173827 | val acc = 6.233546733856201
Time execution (tranning): 160.076767 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 535
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

134.17774261474608

num_try : 188 | val_loss = 134.17774261474608 | val acc = 6.039051532745361
Time execution (tranning): 76.745220 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

134.27991760253906

num_try : 322 | val_loss = 134.27991760253906 | val acc = 7.753612041473389
Time execution (tranning): 88.223678 seconds 
Time execution (load saved model): 0.002053 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

134.57185913085937

num_try : 34 | val_loss = 134.57185913085937 | val acc = 7.769073009490967
Time execution (tranning): 78.005914 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

135.02998107910156

num_try : 106 | val_loss = 135.02998107910156 | val acc = 7.796095371246338
Time execution (tranning): 60.781604 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

135.1344955444336

num_try : 521 | val_loss = 135.1344955444336 | val acc = 6.074518203735352
Time execution (tranning): 82.310036 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

135.45908782958983

num_try : 242 | val_loss = 135.45908782958983 | val acc = 6.268294811248779
Time execution (tranning): 153.420394 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 519
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

137.1167073059082

num_try : 449 | val_loss = 137.1167073059082 | val acc = 6.010986328125
Time execution (tranning): 55.205349 seconds 
Time execution (load saved model): 0.002067 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 177
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

137.46648223876954

num_try : 286 | val_loss = 137.46648223876954 | val acc = 7.896207332611084
Time execution (tranning): 63.885904 seconds 
Time execution (load saved model): 0.002038 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

138.3495294189453

num_try : 160 | val_loss = 138.3495294189453 | val acc = 7.9278998374938965
Time execution (tranning): 63.277972 seconds 
Time execution (load saved model): 0.002123 seconds 
Time execution (use saved model): 0.000227 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

139.29803649902342

num_try : 557 | val_loss = 139.29803649902342 | val acc = 6.159732818603516
Time execution (tranning): 74.672923 seconds 
Time execution (load saved model): 0.002063 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

139.71526031494142

num_try : 142 | val_loss = 139.71526031494142 | val acc = 7.908320903778076
Time execution (tranning): 85.683760 seconds 
Time execution (load saved model): 0.002031 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

139.930888671875

num_try : 170 | val_loss = 139.930888671875 | val acc = 6.350596904754639
Time execution (tranning): 136.511744 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 458
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

140.00015594482423

num_try : 350 | val_loss = 140.00015594482423 | val acc = 6.355340480804443
Time execution (tranning): 98.017708 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

140.71959350585936

num_try : 70 | val_loss = 140.71959350585936 | val acc = 8.003101348876953
Time execution (tranning): 87.612400 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000218 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

140.73452880859375

num_try : 232 | val_loss = 140.73452880859375 | val acc = 7.986350059509277
Time execution (tranning): 57.847923 seconds 
Time execution (load saved model): 0.002058 seconds 
Time execution (use saved model): 0.000239 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

145.950244140625

num_try : 503 | val_loss = 145.950244140625 | val acc = 6.312190532684326
Time execution (tranning): 94.239411 seconds 
Time execution (load saved model): 0.002052 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

146.02061462402344

num_try : 296 | val_loss = 146.02061462402344 | val acc = 6.266627788543701
Time execution (tranning): 61.035235 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

147.47984649658204

num_try : 305 | val_loss = 147.47984649658204 | val acc = 6.310126304626465
Time execution (tranning): 68.601620 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

149.6661668395996

num_try : 413 | val_loss = 149.6661668395996 | val acc = 6.629047393798828
Time execution (tranning): 68.444234 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

156.4740789794922

num_try : 224 | val_loss = 156.4740789794922 | val acc = 6.582517147064209
Time execution (tranning): 86.473917 seconds 
Time execution (load saved model): 0.002087 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

157.89561126708983

num_try : 260 | val_loss = 157.89561126708983 | val acc = 6.5830888748168945
Time execution (tranning): 97.637672 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

160.05390228271483

num_try : 206 | val_loss = 160.05390228271483 | val acc = 6.979465961456299
Time execution (tranning): 100.505569 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

163.74390960693358

num_try : 233 | val_loss = 163.74390960693358 | val acc = 7.004235744476318
Time execution (tranning): 75.163268 seconds 
Time execution (load saved model): 0.002059 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

166.72506622314452

num_try : 26 | val_loss = 166.72506622314452 | val acc = 7.105291366577148
Time execution (tranning): 86.077353 seconds 
Time execution (load saved model): 0.002037 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

167.31372894287108

num_try : 8 | val_loss = 167.31372894287108 | val acc = 6.939044952392578
Time execution (tranning): 48.079576 seconds 
Time execution (load saved model): 0.002044 seconds 
Time execution (use saved model): 0.000232 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 161
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

168.68732788085939

num_try : 539 | val_loss = 168.68732788085939 | val acc = 7.081605911254883
Time execution (tranning): 99.947611 seconds 
Time execution (load saved model): 0.002051 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

169.2494610595703

num_try : 80 | val_loss = 169.2494610595703 | val acc = 6.991451263427734
Time execution (tranning): 57.379637 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

170.3800894165039

num_try : 341 | val_loss = 170.3800894165039 | val acc = 7.072555065155029
Time execution (tranning): 70.096624 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

171.71530364990235

num_try : 467 | val_loss = 171.71530364990235 | val acc = 7.114924907684326
Time execution (tranning): 94.928461 seconds 
Time execution (load saved model): 0.002070 seconds 
Time execution (use saved model): 0.000233 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

171.84126861572267

num_try : 314 | val_loss = 171.84126861572267 | val acc = 7.249786376953125
Time execution (tranning): 95.933839 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000242 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

171.85342376708985

num_try : 269 | val_loss = 171.85342376708985 | val acc = 7.159050464630127
Time execution (tranning): 78.092648 seconds 
Time execution (load saved model): 0.002055 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

172.32400970458986

num_try : 395 | val_loss = 172.32400970458986 | val acc = 7.184004306793213
Time execution (tranning): 127.507573 seconds 
Time execution (load saved model): 0.002124 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 423
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

175.85201049804687

num_try : 430 | val_loss = 175.85201049804687 | val acc = 9.142546653747559
Time execution (tranning): 64.455745 seconds 
Time execution (load saved model): 0.002041 seconds 
Time execution (use saved model): 0.000241 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

175.95714294433594

num_try : 323 | val_loss = 175.95714294433594 | val acc = 7.278820991516113
Time execution (tranning): 102.739336 seconds 
Time execution (load saved model): 0.002061 seconds 
Time execution (use saved model): 0.000243 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

176.29370727539063

num_try : 197 | val_loss = 176.29370727539063 | val acc = 7.2809224128723145
Time execution (tranning): 59.406832 seconds 
Time execution (load saved model): 0.002057 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

176.51144897460938

num_try : 431 | val_loss = 176.51144897460938 | val acc = 7.306046962738037
Time execution (tranning): 125.652976 seconds 
Time execution (load saved model): 0.002042 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 414
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

177.2267266845703

num_try : 116 | val_loss = 177.2267266845703 | val acc = 7.1774091720581055
Time execution (tranning): 81.850200 seconds 
Time execution (load saved model): 0.002047 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

178.68860748291016

num_try : 161 | val_loss = 178.68860748291016 | val acc = 7.380276679992676
Time execution (tranning): 69.913980 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

179.5526837158203

num_try : 62 | val_loss = 179.5526837158203 | val acc = 7.455023765563965
Time execution (tranning): 82.608554 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000223 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

179.98630981445314

num_try : 17 | val_loss = 179.98630981445314 | val acc = 7.467910289764404
Time execution (tranning): 85.718355 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

180.71208129882814

num_try : 125 | val_loss = 180.71208129882814 | val acc = 7.452020645141602
Time execution (tranning): 89.982923 seconds 
Time execution (load saved model): 0.002048 seconds 
Time execution (use saved model): 0.000225 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

183.63439697265625

num_try : 377 | val_loss = 183.63439697265625 | val acc = 7.43980598449707
Time execution (tranning): 81.242758 seconds 
Time execution (load saved model): 0.002056 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

184.89214172363282

num_try : 278 | val_loss = 184.89214172363282 | val acc = 7.508022308349609
Time execution (tranning): 85.312237 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000221 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

184.97544647216796

num_try : 53 | val_loss = 184.97544647216796 | val acc = 7.61390495300293
Time execution (tranning): 105.765212 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

185.37259368896486

num_try : 134 | val_loss = 185.37259368896486 | val acc = 7.5686516761779785
Time execution (tranning): 73.304633 seconds 
Time execution (load saved model): 0.002034 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

185.42941772460938

num_try : 251 | val_loss = 185.42941772460938 | val acc = 7.498326301574707
Time execution (tranning): 100.832834 seconds 
Time execution (load saved model): 0.002039 seconds 
Time execution (use saved model): 0.000220 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

189.49016326904297

num_try : 575 | val_loss = 189.49016326904297 | val acc = 7.637005805969238
Time execution (tranning): 106.124138 seconds 
Time execution (load saved model): 0.002060 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

195.4883755493164

num_try : 359 | val_loss = 195.4883755493164 | val acc = 7.742827892303467
Time execution (tranning): 76.298203 seconds 
Time execution (load saved model): 0.002024 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

195.80466430664063

num_try : 71 | val_loss = 195.80466430664063 | val acc = 7.7515177726745605
Time execution (tranning): 88.077026 seconds 
Time execution (load saved model): 0.002043 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

198.5835433959961

num_try : 89 | val_loss = 198.5835433959961 | val acc = 7.872293472290039
Time execution (tranning): 50.122677 seconds 
Time execution (load saved model): 0.002033 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 165
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

200.7462307739258

num_try : 215 | val_loss = 200.7462307739258 | val acc = 7.792233467102051
Time execution (tranning): 67.946124 seconds 
Time execution (load saved model): 0.002050 seconds 
Time execution (use saved model): 0.000222 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

212.86285400390625

num_try : 107 | val_loss = 212.86285400390625 | val acc = 8.048762321472168
Time execution (tranning): 39.618083 seconds 
Time execution (load saved model): 0.002020 seconds 
Time execution (use saved model): 0.000211 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 132
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

213.48259338378907

num_try : 179 | val_loss = 213.48259338378907 | val acc = 8.128907203674316
Time execution (tranning): 52.245888 seconds 
Time execution (load saved model): 0.002022 seconds 
Time execution (use saved model): 0.000215 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

215.13152160644532

num_try : 35 | val_loss = 215.13152160644532 | val acc = 8.157644271850586
Time execution (tranning): 42.841408 seconds 
Time execution (load saved model): 0.002032 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 141
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

220.6851712036133

num_try : 143 | val_loss = 220.6851712036133 | val acc = 8.339242935180664
Time execution (tranning): 69.652557 seconds 
Time execution (load saved model): 0.002035 seconds 
Time execution (use saved model): 0.000216 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

255.2262060546875

num_try : 368 | val_loss = 255.2262060546875 | val acc = 9.139010429382324
Time execution (tranning): 84.373291 seconds 
Time execution (load saved model): 0.002026 seconds 
Time execution (use saved model): 0.000219 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

261.0513876342773

num_try : 44 | val_loss = 261.0513876342773 | val acc = 9.267361640930176
Time execution (tranning): 52.067483 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[16],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

264.8838671875

num_try : 287 | val_loss = 264.8838671875 | val acc = 9.20823860168457
Time execution (tranning): 44.134876 seconds 
Time execution (load saved model): 0.002036 seconds 
Time execution (use saved model): 0.000217 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 145
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.5}
----------

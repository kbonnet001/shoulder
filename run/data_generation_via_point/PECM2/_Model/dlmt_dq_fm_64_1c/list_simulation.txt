12.107143783569336

num_try : 432 | val_loss = 12.107143783569336 | val acc = 2.5465173721313477
val_error = -19.48600560426712 | val_abs_error = 19.48600560426712
Time execution (tranning): 90.822451 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 382
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

13.95498224258423

num_try : 408 | val_loss = 13.95498224258423 | val acc = 2.7283384799957275
val_error = -68.28193664550781 | val_abs_error = 68.28193664550781
Time execution (tranning): 121.101588 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 503
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

15.834717254638672

num_try : 312 | val_loss = 15.834717254638672 | val acc = 2.9151806831359863
val_error = -85.98372340202332 | val_abs_error = 85.98372340202332
Time execution (tranning): 82.922384 seconds 
Time execution (load saved model): 0.001598 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 357
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

16.46043815612793

num_try : 360 | val_loss = 16.46043815612793 | val acc = 2.971079111099243
val_error = -44.19573247432709 | val_abs_error = 44.19573247432709
Time execution (tranning): 103.965572 seconds 
Time execution (load saved model): 0.001596 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 439
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

16.61625118255615

num_try : 336 | val_loss = 16.61625118255615 | val acc = 2.987708806991577
val_error = -125.01546144485474 | val_abs_error = 125.01546144485474
Time execution (tranning): 173.311323 seconds 
Time execution (load saved model): 0.001528 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 749
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.23722702026367

num_try : 436 | val_loss = 17.23722702026367 | val acc = 3.0263774394989014
val_error = -38.83112967014313 | val_abs_error = 38.83112967014313
Time execution (tranning): 122.093212 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 499
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.39017105102539

num_try : 384 | val_loss = 17.39017105102539 | val acc = 3.09218692779541
val_error = -27.77070701122284 | val_abs_error = 27.77070701122284
Time execution (tranning): 93.756831 seconds 
Time execution (load saved model): 0.001570 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 387
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.788426666259767

num_try : 412 | val_loss = 17.788426666259767 | val acc = 3.0412652492523193
val_error = -61.09245419502258 | val_abs_error = 61.09245419502258
Time execution (tranning): 104.245224 seconds 
Time execution (load saved model): 0.001567 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 418
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.881558456420898

num_try : 388 | val_loss = 17.881558456420898 | val acc = 3.1046926975250244
val_error = -35.36156415939331 | val_abs_error = 35.36156415939331
Time execution (tranning): 117.736924 seconds 
Time execution (load saved model): 0.001623 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 457
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.94029308319092

num_try : 460 | val_loss = 17.94029308319092 | val acc = 3.0378854274749756
val_error = -104.16125059127808 | val_abs_error = 104.16125059127808
Time execution (tranning): 108.438259 seconds 
Time execution (load saved model): 0.001637 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

17.968042907714842

num_try : 420 | val_loss = 17.968042907714842 | val acc = 3.158205032348633
val_error = -141.7362093925476 | val_abs_error = 141.7362093925476
Time execution (tranning): 174.625168 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 725
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

19.967744522094726

num_try : 396 | val_loss = 19.967744522094726 | val acc = 3.3083598613739014
val_error = -120.92680931091309 | val_abs_error = 120.92680931091309
Time execution (tranning): 130.983738 seconds 
Time execution (load saved model): 0.001643 seconds 
Time execution (use saved model): 0.000180 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 538
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

20.079724655151367

num_try : 444 | val_loss = 20.079724655151367 | val acc = 3.338043689727783
val_error = -96.76924347877502 | val_abs_error = 96.76924347877502
Time execution (tranning): 177.886049 seconds 
Time execution (load saved model): 0.001620 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 747
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

21.27228225708008

num_try : 288 | val_loss = 21.27228225708008 | val acc = 3.4480230808258057
val_error = 11.130499839782715 | val_abs_error = 11.130499839782715
Time execution (tranning): 177.236498 seconds 
Time execution (load saved model): 0.001532 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 765
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

21.585517921447753

num_try : 464 | val_loss = 21.585517921447753 | val acc = 3.4204037189483643
val_error = -164.41336870193481 | val_abs_error = 164.41336870193481
Time execution (tranning): 124.307359 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 498
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

21.742432250976563

num_try : 456 | val_loss = 21.742432250976563 | val acc = 3.438100814819336
val_error = -125.57772397994995 | val_abs_error = 125.57772397994995
Time execution (tranning): 58.888021 seconds 
Time execution (load saved model): 0.001579 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

21.83999279022217

num_try : 392 | val_loss = 21.83999279022217 | val acc = 3.4521501064300537
val_error = -160.9353542327881 | val_abs_error = 160.9353542327881
Time execution (tranning): 133.677940 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 537
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

23.746319122314453

num_try : 416 | val_loss = 23.746319122314453 | val acc = 3.5921754837036133
val_error = -233.54134559631348 | val_abs_error = 233.54134559631348
Time execution (tranning): 91.644061 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

23.80175621032715

num_try : 440 | val_loss = 23.80175621032715 | val acc = 3.5952587127685547
val_error = -141.3940191268921 | val_abs_error = 141.3940191268921
Time execution (tranning): 84.024390 seconds 
Time execution (load saved model): 0.001552 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

23.94290958404541

num_try : 468 | val_loss = 23.94290958404541 | val acc = 3.661869764328003
val_error = -140.65169095993042 | val_abs_error = 140.65169095993042
Time execution (tranning): 129.561137 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 545
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

24.134762573242188

num_try : 340 | val_loss = 24.134762573242188 | val acc = 3.666515350341797
val_error = -143.29595565795898 | val_abs_error = 143.29595565795898
Time execution (tranning): 107.993414 seconds 
Time execution (load saved model): 0.001603 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 450
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

26.234011840820312

num_try : 433 | val_loss = 26.234011840820312 | val acc = 2.699777603149414
val_error = 6.369097530841827 | val_abs_error = 6.369097530841827
Time execution (tranning): 107.694869 seconds 
Time execution (load saved model): 0.001636 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 449
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

28.745588302612305

num_try : 361 | val_loss = 28.745588302612305 | val acc = 2.796560287475586
val_error = -6.836805492639542 | val_abs_error = 6.836805492639542
Time execution (tranning): 85.866299 seconds 
Time execution (load saved model): 0.001601 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 365
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

29.423494567871092

num_try : 457 | val_loss = 29.423494567871092 | val acc = 2.84390926361084
val_error = -170.32982110977173 | val_abs_error = 170.32982110977173
Time execution (tranning): 107.177378 seconds 
Time execution (load saved model): 0.001546 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 446
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

29.61780975341797

num_try : 409 | val_loss = 29.61780975341797 | val acc = 2.8828368186950684
val_error = -17.86816120147705 | val_abs_error = 17.86816120147705
Time execution (tranning): 91.034162 seconds 
Time execution (load saved model): 0.001558 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 383
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

31.608377075195314

num_try : 434 | val_loss = 31.608377075195314 | val acc = 2.570056915283203
val_error = -23.256947100162506 | val_abs_error = 23.256947100162506
Time execution (tranning): 116.266520 seconds 
Time execution (load saved model): 0.001635 seconds 
Time execution (use saved model): 0.000177 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 481
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

32.47018203735352

num_try : 413 | val_loss = 32.47018203735352 | val acc = 2.9357075691223145
val_error = -81.69796466827393 | val_abs_error = 81.69796466827393
Time execution (tranning): 101.765300 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 413
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

32.90830841064453

num_try : 461 | val_loss = 32.90830841064453 | val acc = 2.959113597869873
val_error = 9.10637080669403 | val_abs_error = 9.10637080669403
Time execution (tranning): 118.480750 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 475
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

33.038147354125975

num_try : 472 | val_loss = 33.038147354125975 | val acc = 4.265436172485352
val_error = -243.18859577178955 | val_abs_error = 243.18859577178955
Time execution (tranning): 130.899274 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 534
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

34.320138473510745

num_try : 445 | val_loss = 34.320138473510745 | val acc = 3.0729665756225586
val_error = -50.9303092956543 | val_abs_error = 50.9303092956543
Time execution (tranning): 163.001283 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 675
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

34.63218879699707

num_try : 410 | val_loss = 34.63218879699707 | val acc = 2.7363052368164062
val_error = -34.73948836326599 | val_abs_error = 34.73948836326599
Time execution (tranning): 95.094316 seconds 
Time execution (load saved model): 0.001597 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 388
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

35.68467544555664

num_try : 389 | val_loss = 35.68467544555664 | val acc = 3.1105666160583496
val_error = -14.700968563556671 | val_abs_error = 14.700968563556671
Time execution (tranning): 97.223649 seconds 
Time execution (load saved model): 0.001583 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 383
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

37.13927467346191

num_try : 421 | val_loss = 37.13927467346191 | val acc = 3.244978189468384
val_error = -69.746333360672 | val_abs_error = 69.746333360672
Time execution (tranning): 145.191504 seconds 
Time execution (load saved model): 0.001650 seconds 
Time execution (use saved model): 0.000179 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 601
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

37.14665725708008

num_try : 385 | val_loss = 37.14665725708008 | val acc = 3.1987383365631104
val_error = -26.235783100128174 | val_abs_error = 26.235783100128174
Time execution (tranning): 55.883289 seconds 
Time execution (load saved model): 0.001586 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

37.54501792907715

num_try : 437 | val_loss = 37.54501792907715 | val acc = 3.19174861907959
val_error = -14.596307277679443 | val_abs_error = 14.596307277679443
Time execution (tranning): 94.876820 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 387
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

38.175562057495114

num_try : 400 | val_loss = 38.175562057495114 | val acc = 4.619034290313721
val_error = -206.5528392791748 | val_abs_error = 206.5528392791748
Time execution (tranning): 138.444354 seconds 
Time execution (load saved model): 0.001566 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 561
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

39.517818756103516

num_try : 362 | val_loss = 39.517818756103516 | val acc = 2.8787174224853516
val_error = -14.077553153038025 | val_abs_error = 14.077553153038025
Time execution (tranning): 107.545810 seconds 
Time execution (load saved model): 0.001584 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 462
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

40.393683166503905

num_try : 417 | val_loss = 40.393683166503905 | val acc = 3.351144790649414
val_error = -89.23137784004211 | val_abs_error = 89.23137784004211
Time execution (tranning): 128.444138 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 516
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

40.661453323364256

num_try : 462 | val_loss = 40.661453323364256 | val acc = 2.907367706298828
val_error = -42.079952359199524 | val_abs_error = 42.079952359199524
Time execution (tranning): 121.722445 seconds 
Time execution (load saved model): 0.001552 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 497
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

40.739805450439455

num_try : 458 | val_loss = 40.739805450439455 | val acc = 2.9708821773529053
val_error = -158.9574933052063 | val_abs_error = 158.9574933052063
Time execution (tranning): 92.790683 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 381
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

41.48361221313476

num_try : 424 | val_loss = 41.48361221313476 | val acc = 4.833615303039551
val_error = -197.04558849334717 | val_abs_error = 197.04558849334717
Time execution (tranning): 148.745358 seconds 
Time execution (load saved model): 0.001588 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 594
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

41.85643005371094

num_try : 438 | val_loss = 41.85643005371094 | val acc = 2.9395980834960938
val_error = 12.109185755252838 | val_abs_error = 12.109185755252838
Time execution (tranning): 106.598457 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

45.25768859863281

num_try : 393 | val_loss = 45.25768859863281 | val acc = 3.572312355041504
val_error = -84.30970311164856 | val_abs_error = 84.30970311164856
Time execution (tranning): 95.133217 seconds 
Time execution (load saved model): 0.001628 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 383
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

45.5997917175293

num_try : 386 | val_loss = 45.5997917175293 | val acc = 3.1331374645233154
val_error = -74.0591824054718 | val_abs_error = 74.0591824054718
Time execution (tranning): 74.352745 seconds 
Time execution (load saved model): 0.001563 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

46.1192138671875

num_try : 398 | val_loss = 46.1192138671875 | val acc = 3.2199060916900635
val_error = -76.48961544036865 | val_abs_error = 76.48961544036865
Time execution (tranning): 154.747258 seconds 
Time execution (load saved model): 0.001564 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 634
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

46.5315412902832

num_try : 316 | val_loss = 46.5315412902832 | val acc = 5.093576431274414
val_error = -232.45837688446045 | val_abs_error = 232.45837688446045
Time execution (tranning): 53.431744 seconds 
Time execution (load saved model): 0.001521 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

47.57838615417481

num_try : 390 | val_loss = 47.57838615417481 | val acc = 3.2016351222991943
val_error = -73.12862873077393 | val_abs_error = 73.12862873077393
Time execution (tranning): 96.704237 seconds 
Time execution (load saved model): 0.001540 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 387
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

49.70632080078125

num_try : 465 | val_loss = 49.70632080078125 | val acc = 3.7252445220947266
val_error = -148.09287786483765 | val_abs_error = 148.09287786483765
Time execution (tranning): 97.205710 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 396
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

49.987502059936524

num_try : 446 | val_loss = 49.987502059936524 | val acc = 3.328648090362549
val_error = -115.98867177963257 | val_abs_error = 115.98867177963257
Time execution (tranning): 143.160882 seconds 
Time execution (load saved model): 0.001588 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 595
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

52.420223770141604

num_try : 422 | val_loss = 52.420223770141604 | val acc = 3.413269281387329
val_error = -131.57083988189697 | val_abs_error = 131.57083988189697
Time execution (tranning): 154.886568 seconds 
Time execution (load saved model): 0.001628 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 639
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

53.59872589111328

num_try : 476 | val_loss = 53.59872589111328 | val acc = 5.5998969078063965
val_error = -277.16312408447266 | val_abs_error = 277.16312408447266
Time execution (tranning): 109.156507 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 433
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

54.01021873474121

num_try : 366 | val_loss = 54.01021873474121 | val acc = 3.4150173664093018
val_error = -26.928257942199707 | val_abs_error = 26.928257942199707
Time execution (tranning): 111.829874 seconds 
Time execution (load saved model): 0.001520 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 476
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

54.15295097351074

num_try : 428 | val_loss = 54.15295097351074 | val acc = 5.63824987411499
val_error = -237.1060848236084 | val_abs_error = 237.1060848236084
Time execution (tranning): 114.659175 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 465
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

55.387454681396484

num_try : 414 | val_loss = 55.387454681396484 | val acc = 3.5123887062072754
val_error = -50.68458318710327 | val_abs_error = 50.68458318710327
Time execution (tranning): 90.047463 seconds 
Time execution (load saved model): 0.001556 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 366
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

55.62654075622559

num_try : 466 | val_loss = 55.62654075622559 | val acc = 3.4776711463928223
val_error = -112.86118030548096 | val_abs_error = 112.86118030548096
Time execution (tranning): 111.782089 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 457
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

55.726189880371095

num_try : 441 | val_loss = 55.726189880371095 | val acc = 3.944465160369873
val_error = -123.28966856002808 | val_abs_error = 123.28966856002808
Time execution (tranning): 65.134111 seconds 
Time execution (load saved model): 0.001623 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

56.99356307983398

num_try : 216 | val_loss = 56.99356307983398 | val acc = 5.7734246253967285
val_error = -210.62664985656738 | val_abs_error = 210.62664985656738
Time execution (tranning): 45.419414 seconds 
Time execution (load saved model): 0.001501 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.05822067260742

num_try : 364 | val_loss = 57.05822067260742 | val acc = 5.783569812774658
val_error = -246.81744575500488 | val_abs_error = 246.81744575500488
Time execution (tranning): 65.322693 seconds 
Time execution (load saved model): 0.001617 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 275
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.10758926391602

num_try : 292 | val_loss = 57.10758926391602 | val acc = 5.78364896774292
val_error = -172.94543981552124 | val_abs_error = 172.94543981552124
Time execution (tranning): 52.728315 seconds 
Time execution (load saved model): 0.001516 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.29338424682617

num_try : 240 | val_loss = 57.29338424682617 | val acc = 5.819499969482422
val_error = -194.96841430664062 | val_abs_error = 194.96841430664062
Time execution (tranning): 47.694992 seconds 
Time execution (load saved model): 0.001589 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.52210601806641

num_try : 192 | val_loss = 57.52210601806641 | val acc = 5.826938152313232
val_error = -200.01647472381592 | val_abs_error = 200.01647472381592
Time execution (tranning): 50.113015 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.60427551269531

num_try : 96 | val_loss = 57.60427551269531 | val acc = 5.806232452392578
val_error = -188.6351466178894 | val_abs_error = 188.6351466178894
Time execution (tranning): 42.561666 seconds 
Time execution (load saved model): 0.001524 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.60584274291992

num_try : 264 | val_loss = 57.60584274291992 | val acc = 5.843914985656738
val_error = -221.5700387954712 | val_abs_error = 221.5700387954712
Time execution (tranning): 39.825239 seconds 
Time execution (load saved model): 0.001592 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 173
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.85525634765625

num_try : 0 | val_loss = 57.85525634765625 | val acc = 5.862021446228027
val_error = -277.1791696548462 | val_abs_error = 277.1791696548462
Time execution (tranning): 51.037245 seconds 
Time execution (load saved model): 0.001438 seconds 
Time execution (use saved model): 0.000158 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.87018829345703

num_try : 172 | val_loss = 57.87018829345703 | val acc = 5.874615669250488
val_error = -309.39979553222656 | val_abs_error = 309.39979553222656
Time execution (tranning): 65.029549 seconds 
Time execution (load saved model): 0.001483 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.91497039794922

num_try : 296 | val_loss = 57.91497039794922 | val acc = 5.872033596038818
val_error = -407.1441650390625 | val_abs_error = 407.1441650390625
Time execution (tranning): 61.061427 seconds 
Time execution (load saved model): 0.001539 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

57.94724517822266

num_try : 196 | val_loss = 57.94724517822266 | val acc = 5.836225986480713
val_error = -277.30767726898193 | val_abs_error = 277.30767726898193
Time execution (tranning): 44.013950 seconds 
Time execution (load saved model): 0.001512 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.0933952331543

num_try : 168 | val_loss = 58.0933952331543 | val acc = 5.898541450500488
val_error = -175.684654712677 | val_abs_error = 175.684654712677
Time execution (tranning): 59.771656 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.231024169921874

num_try : 124 | val_loss = 58.231024169921874 | val acc = 5.8831787109375
val_error = -370.61564922332764 | val_abs_error = 370.61564922332764
Time execution (tranning): 53.346946 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.275639038085934

num_try : 220 | val_loss = 58.275639038085934 | val acc = 5.855836391448975
val_error = -232.14550018310547 | val_abs_error = 232.14550018310547
Time execution (tranning): 48.215580 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.33046379089355

num_try : 120 | val_loss = 58.33046379089355 | val acc = 5.839230537414551
val_error = -164.34624195098877 | val_abs_error = 164.34624195098877
Time execution (tranning): 41.362593 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.4057494354248

num_try : 244 | val_loss = 58.4057494354248 | val acc = 5.905864715576172
val_error = -255.75153827667236 | val_abs_error = 255.75153827667236
Time execution (tranning): 40.034923 seconds 
Time execution (load saved model): 0.001533 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 168
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.45754684448242

num_try : 72 | val_loss = 58.45754684448242 | val acc = 5.898135662078857
val_error = -218.4906244277954 | val_abs_error = 218.4906244277954
Time execution (tranning): 66.011969 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.51264236450195

num_try : 344 | val_loss = 58.51264236450195 | val acc = 5.906847953796387
val_error = -393.95010471343994 | val_abs_error = 393.95010471343994
Time execution (tranning): 47.718845 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 203
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.576627044677736

num_try : 148 | val_loss = 58.576627044677736 | val acc = 5.8612141609191895
val_error = -398.3022689819336 | val_abs_error = 398.3022689819336
Time execution (tranning): 48.703501 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.604799041748045

num_try : 24 | val_loss = 58.604799041748045 | val acc = 5.883765697479248
val_error = -270.11029720306396 | val_abs_error = 270.11029720306396
Time execution (tranning): 56.188510 seconds 
Time execution (load saved model): 0.001818 seconds 
Time execution (use saved model): 0.000190 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.816760864257816

num_try : 320 | val_loss = 58.816760864257816 | val acc = 5.93630313873291
val_error = -414.3671989440918 | val_abs_error = 414.3671989440918
Time execution (tranning): 61.395787 seconds 
Time execution (load saved model): 0.001537 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

58.8743896484375

num_try : 76 | val_loss = 58.8743896484375 | val acc = 5.930811405181885
val_error = -509.56101417541504 | val_abs_error = 509.56101417541504
Time execution (tranning): 70.199185 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.0310920715332

num_try : 144 | val_loss = 59.0310920715332 | val acc = 5.931333541870117
val_error = -190.8469319343567 | val_abs_error = 190.8469319343567
Time execution (tranning): 37.180747 seconds 
Time execution (load saved model): 0.001534 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 165
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.14922393798828

num_try : 4 | val_loss = 59.14922393798828 | val acc = 5.944614887237549
val_error = -428.8295269012451 | val_abs_error = 428.8295269012451
Time execution (tranning): 57.778992 seconds 
Time execution (load saved model): 0.001476 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.16701385498047

num_try : 48 | val_loss = 59.16701385498047 | val acc = 5.985564231872559
val_error = -285.7530117034912 | val_abs_error = 285.7530117034912
Time execution (tranning): 58.855055 seconds 
Time execution (load saved model): 0.001492 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.173438262939456

num_try : 368 | val_loss = 59.173438262939456 | val acc = 5.882441997528076
val_error = -322.20866680145264 | val_abs_error = 322.20866680145264
Time execution (tranning): 53.262125 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.18319160461426

num_try : 248 | val_loss = 59.18319160461426 | val acc = 5.950127124786377
val_error = -447.9642868041992 | val_abs_error = 447.9642868041992
Time execution (tranning): 66.797740 seconds 
Time execution (load saved model): 0.001527 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.743548736572265

num_try : 268 | val_loss = 59.743548736572265 | val acc = 5.841245651245117
val_error = -280.6166887283325 | val_abs_error = 280.6166887283325
Time execution (tranning): 56.501789 seconds 
Time execution (load saved model): 0.001629 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.80223770141602

num_try : 328 | val_loss = 59.80223770141602 | val acc = 6.019577503204346
val_error = -235.46745777130127 | val_abs_error = 235.46745777130127
Time execution (tranning): 97.208241 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 419
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.828336486816404

num_try : 224 | val_loss = 59.828336486816404 | val acc = 6.020633697509766
val_error = -449.7391700744629 | val_abs_error = 449.7391700744629
Time execution (tranning): 81.534771 seconds 
Time execution (load saved model): 0.001497 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.82852874755859

num_try : 52 | val_loss = 59.82852874755859 | val acc = 5.916402816772461
val_error = -467.07186698913574 | val_abs_error = 467.07186698913574
Time execution (tranning): 56.508707 seconds 
Time execution (load saved model): 0.001473 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.90668258666992

num_try : 100 | val_loss = 59.90668258666992 | val acc = 5.999425411224365
val_error = -383.31892490386963 | val_abs_error = 383.31892490386963
Time execution (tranning): 65.191378 seconds 
Time execution (load saved model): 0.001482 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.91626388549805

num_try : 200 | val_loss = 59.91626388549805 | val acc = 5.9554667472839355
val_error = -414.84246253967285 | val_abs_error = 414.84246253967285
Time execution (tranning): 51.686241 seconds 
Time execution (load saved model): 0.001493 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

59.97138458251953

num_try : 348 | val_loss = 59.97138458251953 | val acc = 6.017129898071289
val_error = -189.6172046661377 | val_abs_error = 189.6172046661377
Time execution (tranning): 77.834885 seconds 
Time execution (load saved model): 0.001526 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

60.17222213745117

num_try : 272 | val_loss = 60.17222213745117 | val acc = 5.978167533874512
val_error = -429.45923805236816 | val_abs_error = 429.45923805236816
Time execution (tranning): 52.964587 seconds 
Time execution (load saved model): 0.001567 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

60.29758644104004

num_try : 452 | val_loss = 60.29758644104004 | val acc = 5.97897481918335
val_error = -237.76566982269287 | val_abs_error = 237.76566982269287
Time execution (tranning): 95.650602 seconds 
Time execution (load saved model): 0.001634 seconds 
Time execution (use saved model): 0.000177 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 378
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

61.33940231323242

num_try : 128 | val_loss = 61.33940231323242 | val acc = 6.066163063049316
val_error = -491.1649227142334 | val_abs_error = 491.1649227142334
Time execution (tranning): 60.910939 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

61.442889556884765

num_try : 28 | val_loss = 61.442889556884765 | val acc = 6.035937309265137
val_error = -411.6302013397217 | val_abs_error = 411.6302013397217
Time execution (tranning): 56.289125 seconds 
Time execution (load saved model): 0.001483 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

61.608323669433595

num_try : 152 | val_loss = 61.608323669433595 | val acc = 6.121617317199707
val_error = -519.1120147705078 | val_abs_error = 519.1120147705078
Time execution (tranning): 55.731777 seconds 
Time execution (load saved model): 0.001483 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

61.61543167114258

num_try : 442 | val_loss = 61.61543167114258 | val acc = 3.7104058265686035
val_error = -185.7063889503479 | val_abs_error = 185.7063889503479
Time execution (tranning): 101.842227 seconds 
Time execution (load saved model): 0.001616 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 400
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

61.89779754638672

num_try : 176 | val_loss = 61.89779754638672 | val acc = 6.15278959274292
val_error = -494.26889419555664 | val_abs_error = 494.26889419555664
Time execution (tranning): 75.676466 seconds 
Time execution (load saved model): 0.001501 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

62.10204574584961

num_try : 300 | val_loss = 62.10204574584961 | val acc = 6.136763095855713
val_error = -196.24686241149902 | val_abs_error = 196.24686241149902
Time execution (tranning): 79.946263 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

62.248928985595704

num_try : 418 | val_loss = 62.248928985595704 | val acc = 3.7156965732574463
val_error = -211.51790618896484 | val_abs_error = 211.51790618896484
Time execution (tranning): 79.314209 seconds 
Time execution (load saved model): 0.001541 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

62.57991851806641

num_try : 304 | val_loss = 62.57991851806641 | val acc = 6.173232555389404
val_error = -186.8403196334839 | val_abs_error = 186.8403196334839
Time execution (tranning): 73.002759 seconds 
Time execution (load saved model): 0.001590 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 306
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

62.9165731048584

num_try : 332 | val_loss = 62.9165731048584 | val acc = 6.1331682205200195
val_error = -239.63146209716797 | val_abs_error = 239.63146209716797
Time execution (tranning): 91.830270 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 391
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

62.93895278930664

num_try : 372 | val_loss = 62.93895278930664 | val acc = 6.209723949432373
val_error = -175.09087324142456 | val_abs_error = 175.09087324142456
Time execution (tranning): 71.149649 seconds 
Time execution (load saved model): 0.001620 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

62.94911193847656

num_try : 212 | val_loss = 62.94911193847656 | val acc = 6.140374183654785
val_error = -325.67646503448486 | val_abs_error = 325.67646503448486
Time execution (tranning): 104.957627 seconds 
Time execution (load saved model): 0.001541 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 456
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

63.30906387329102

num_try : 108 | val_loss = 63.30906387329102 | val acc = 6.198233604431152
val_error = -195.40746212005615 | val_abs_error = 195.40746212005615
Time execution (tranning): 96.257452 seconds 
Time execution (load saved model): 0.001488 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 438
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

63.31414375305176

num_try : 356 | val_loss = 63.31414375305176 | val acc = 6.114686489105225
val_error = -243.24700832366943 | val_abs_error = 243.24700832366943
Time execution (tranning): 82.745478 seconds 
Time execution (load saved model): 0.001524 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

63.63566070556641

num_try : 104 | val_loss = 63.63566070556641 | val acc = 6.18703556060791
val_error = -462.7810001373291 | val_abs_error = 462.7810001373291
Time execution (tranning): 70.885761 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

63.937483367919924

num_try : 256 | val_loss = 63.937483367919924 | val acc = 6.19915246963501
val_error = -220.1638698577881 | val_abs_error = 220.1638698577881
Time execution (tranning): 71.734870 seconds 
Time execution (load saved model): 0.001489 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

63.94106262207031

num_try : 252 | val_loss = 63.94106262207031 | val acc = 6.241232872009277
val_error = -152.41626501083374 | val_abs_error = 152.41626501083374
Time execution (tranning): 68.698013 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

64.03148094177246

num_try : 387 | val_loss = 64.03148094177246 | val acc = 2.6160361766815186
val_error = -42.53887236118317 | val_abs_error = 42.53887236118317
Time execution (tranning): 93.385235 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 382
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

64.56501403808593

num_try : 208 | val_loss = 64.56501403808593 | val acc = 6.269109725952148
val_error = -231.5894603729248 | val_abs_error = 231.5894603729248
Time execution (tranning): 86.133100 seconds 
Time execution (load saved model): 0.001510 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.08000839233398

num_try : 324 | val_loss = 65.08000839233398 | val acc = 6.2772135734558105
val_error = -171.15426063537598 | val_abs_error = 171.15426063537598
Time execution (tranning): 55.841135 seconds 
Time execution (load saved model): 0.001509 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.13505706787109

num_try : 276 | val_loss = 65.13505706787109 | val acc = 6.2719831466674805
val_error = -151.94226503372192 | val_abs_error = 151.94226503372192
Time execution (tranning): 56.385221 seconds 
Time execution (load saved model): 0.001537 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.49374603271484

num_try : 308 | val_loss = 65.49374603271484 | val acc = 6.256012439727783
val_error = -234.31971073150635 | val_abs_error = 234.31971073150635
Time execution (tranning): 79.655738 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.5577781677246

num_try : 448 | val_loss = 65.5577781677246 | val acc = 6.308836460113525
val_error = -223.15495014190674 | val_abs_error = 223.15495014190674
Time execution (tranning): 51.748068 seconds 
Time execution (load saved model): 0.001554 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.76270309448242

num_try : 352 | val_loss = 65.76270309448242 | val acc = 6.300253868103027
val_error = -167.84037351608276 | val_abs_error = 167.84037351608276
Time execution (tranning): 62.704894 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.77575622558594

num_try : 132 | val_loss = 65.77575622558594 | val acc = 6.297554969787598
val_error = -251.94647312164307 | val_abs_error = 251.94647312164307
Time execution (tranning): 72.123945 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 320
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.78214797973632

num_try : 80 | val_loss = 65.78214797973632 | val acc = 6.3760175704956055
val_error = -490.11073112487793 | val_abs_error = 490.11073112487793
Time execution (tranning): 61.218209 seconds 
Time execution (load saved model): 0.001541 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

65.87331832885742

num_try : 204 | val_loss = 65.87331832885742 | val acc = 6.313508033752441
val_error = -230.94494342803955 | val_abs_error = 230.94494342803955
Time execution (tranning): 57.401289 seconds 
Time execution (load saved model): 0.001556 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

66.62980331420898

num_try : 376 | val_loss = 66.62980331420898 | val acc = 6.2993083000183105
val_error = -167.41881370544434 | val_abs_error = 167.41881370544434
Time execution (tranning): 58.168913 seconds 
Time execution (load saved model): 0.001582 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

66.80303970336914

num_try : 56 | val_loss = 66.80303970336914 | val acc = 6.43379545211792
val_error = -480.8051586151123 | val_abs_error = 480.8051586151123
Time execution (tranning): 71.442933 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 322
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.08584777832031

num_try : 180 | val_loss = 67.08584777832031 | val acc = 6.399535179138184
val_error = -172.835111618042 | val_abs_error = 172.835111618042
Time execution (tranning): 71.193820 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.09842468261719

num_try : 228 | val_loss = 67.09842468261719 | val acc = 6.3952178955078125
val_error = -184.32213068008423 | val_abs_error = 184.32213068008423
Time execution (tranning): 58.995821 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 257
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.20938644409179

num_try : 280 | val_loss = 67.20938644409179 | val acc = 6.3457255363464355
val_error = -245.59884071350098 | val_abs_error = 245.59884071350098
Time execution (tranning): 67.584930 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.31078140258789

num_try : 8 | val_loss = 67.31078140258789 | val acc = 6.4780988693237305
val_error = -506.2074661254883 | val_abs_error = 506.2074661254883
Time execution (tranning): 70.436528 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.4531332397461

num_try : 260 | val_loss = 67.4531332397461 | val acc = 6.345275402069092
val_error = -317.5065040588379 | val_abs_error = 317.5065040588379
Time execution (tranning): 72.432459 seconds 
Time execution (load saved model): 0.001507 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.48224182128907

num_try : 136 | val_loss = 67.48224182128907 | val acc = 6.340624809265137
val_error = -335.32893657684326 | val_abs_error = 335.32893657684326
Time execution (tranning): 67.004416 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.78086532592773

num_try : 32 | val_loss = 67.78086532592773 | val acc = 6.38435173034668
val_error = -471.8810558319092 | val_abs_error = 471.8810558319092
Time execution (tranning): 73.461617 seconds 
Time execution (load saved model): 0.001539 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

67.9011669921875

num_try : 40 | val_loss = 67.9011669921875 | val acc = 6.405490398406982
val_error = -362.6704216003418 | val_abs_error = 362.6704216003418
Time execution (tranning): 97.448751 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

68.17037246704102

num_try : 232 | val_loss = 68.17037246704102 | val acc = 6.430113792419434
val_error = -226.3728380203247 | val_abs_error = 226.3728380203247
Time execution (tranning): 55.072833 seconds 
Time execution (load saved model): 0.001576 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

68.27916366577148

num_try : 36 | val_loss = 68.27916366577148 | val acc = 6.442540168762207
val_error = -139.23348188400269 | val_abs_error = 139.23348188400269
Time execution (tranning): 68.227797 seconds 
Time execution (load saved model): 0.001539 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

68.58832702636718

num_try : 401 | val_loss = 68.58832702636718 | val acc = 4.436474323272705
val_error = -120.94212770462036 | val_abs_error = 120.94212770462036
Time execution (tranning): 165.891112 seconds 
Time execution (load saved model): 0.001637 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 657
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

68.72901229858398

num_try : 60 | val_loss = 68.72901229858398 | val acc = 6.412429332733154
val_error = -307.4803829193115 | val_abs_error = 307.4803829193115
Time execution (tranning): 73.055158 seconds 
Time execution (load saved model): 0.001464 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

68.80603042602539

num_try : 284 | val_loss = 68.80603042602539 | val acc = 6.429793357849121
val_error = -287.16840744018555 | val_abs_error = 287.16840744018555
Time execution (tranning): 75.287441 seconds 
Time execution (load saved model): 0.001495 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

68.85229080200196

num_try : 184 | val_loss = 68.85229080200196 | val acc = 6.399760723114014
val_error = -312.07826137542725 | val_abs_error = 312.07826137542725
Time execution (tranning): 67.305037 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.09447952270507

num_try : 88 | val_loss = 69.09447952270507 | val acc = 6.432032108306885
val_error = -327.95238494873047 | val_abs_error = 327.95238494873047
Time execution (tranning): 74.992365 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.09766662597656

num_try : 380 | val_loss = 69.09766662597656 | val acc = 6.427493572235107
val_error = -219.45223808288574 | val_abs_error = 219.45223808288574
Time execution (tranning): 61.429079 seconds 
Time execution (load saved model): 0.001543 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.13475372314453

num_try : 394 | val_loss = 69.13475372314453 | val acc = 3.9145214557647705
val_error = -223.1745481491089 | val_abs_error = 223.1745481491089
Time execution (tranning): 89.184428 seconds 
Time execution (load saved model): 0.001554 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 357
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

69.14024765014648

num_try : 156 | val_loss = 69.14024765014648 | val acc = 6.475491046905518
val_error = -195.7545042037964 | val_abs_error = 195.7545042037964
Time execution (tranning): 44.595642 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.25471588134765

num_try : 404 | val_loss = 69.25471588134765 | val acc = 6.497752666473389
val_error = -179.62323427200317 | val_abs_error = 179.62323427200317
Time execution (tranning): 73.538623 seconds 
Time execution (load saved model): 0.001629 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.2565641784668

num_try : 12 | val_loss = 69.2565641784668 | val acc = 6.434834957122803
val_error = -274.3786811828613 | val_abs_error = 274.3786811828613
Time execution (tranning): 57.747515 seconds 
Time execution (load saved model): 0.001477 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

69.53958984375

num_try : 16 | val_loss = 69.53958984375 | val acc = 6.4310736656188965
val_error = -324.0567207336426 | val_abs_error = 324.0567207336426
Time execution (tranning): 72.133808 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

70.65999374389648

num_try : 160 | val_loss = 70.65999374389648 | val acc = 6.49540376663208
val_error = -301.80327892303467 | val_abs_error = 301.80327892303467
Time execution (tranning): 45.356390 seconds 
Time execution (load saved model): 0.001565 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

70.70895584106445

num_try : 236 | val_loss = 70.70895584106445 | val acc = 6.503992080688477
val_error = -322.5698471069336 | val_abs_error = 322.5698471069336
Time execution (tranning): 65.643067 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

70.87485229492188

num_try : 188 | val_loss = 70.87485229492188 | val acc = 6.478278636932373
val_error = -395.7149028778076 | val_abs_error = 395.7149028778076
Time execution (tranning): 60.869447 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

70.97826843261718

num_try : 64 | val_loss = 70.97826843261718 | val acc = 6.5426836013793945
val_error = -340.70234298706055 | val_abs_error = 340.70234298706055
Time execution (tranning): 68.550182 seconds 
Time execution (load saved model): 0.001529 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

71.03864578247071

num_try : 112 | val_loss = 71.03864578247071 | val acc = 6.540793418884277
val_error = -297.5598335266113 | val_abs_error = 297.5598335266113
Time execution (tranning): 62.783739 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

71.22499404907227

num_try : 84 | val_loss = 71.22499404907227 | val acc = 6.53187370300293
val_error = -205.69207668304443 | val_abs_error = 205.69207668304443
Time execution (tranning): 59.883390 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

71.80543960571289

num_try : 116 | val_loss = 71.80543960571289 | val acc = 6.4909796714782715
val_error = -368.8535451889038 | val_abs_error = 368.8535451889038
Time execution (tranning): 64.127276 seconds 
Time execution (load saved model): 0.001500 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

73.54474182128907

num_try : 425 | val_loss = 73.54474182128907 | val acc = 4.582594871520996
val_error = -228.79178524017334 | val_abs_error = 228.79178524017334
Time execution (tranning): 125.584920 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 500
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

73.64186691284179

num_try : 164 | val_loss = 73.64186691284179 | val acc = 6.618119239807129
val_error = -419.3646430969238 | val_abs_error = 419.3646430969238
Time execution (tranning): 52.881131 seconds 
Time execution (load saved model): 0.001485 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

74.0721826171875

num_try : 140 | val_loss = 74.0721826171875 | val acc = 6.6419548988342285
val_error = -425.2514362335205 | val_abs_error = 425.2514362335205
Time execution (tranning): 51.576754 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

76.74861083984375

num_try : 473 | val_loss = 76.74861083984375 | val acc = 4.649381160736084
val_error = -210.0963592529297 | val_abs_error = 210.0963592529297
Time execution (tranning): 118.895148 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 480
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

77.253671875

num_try : 411 | val_loss = 77.253671875 | val acc = 2.8915224075317383
val_error = -119.05077695846558 | val_abs_error = 119.05077695846558
Time execution (tranning): 76.243419 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

79.98167114257812

num_try : 44 | val_loss = 79.98167114257812 | val acc = 6.861536026000977
val_error = -472.8721618652344 | val_abs_error = 472.8721618652344
Time execution (tranning): 71.147882 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

80.61364196777343

num_try : 459 | val_loss = 80.61364196777343 | val acc = 2.9271280765533447
val_error = -43.10137927532196 | val_abs_error = 43.10137927532196
Time execution (tranning): 79.942075 seconds 
Time execution (load saved model): 0.001565 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

81.32232711791993

num_try : 426 | val_loss = 81.32232711791993 | val acc = 4.240384578704834
val_error = -213.27195167541504 | val_abs_error = 213.27195167541504
Time execution (tranning): 170.533566 seconds 
Time execution (load saved model): 0.001631 seconds 
Time execution (use saved model): 0.000177 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 686
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

81.385380859375

num_try : 92 | val_loss = 81.385380859375 | val acc = 6.93548059463501
val_error = -474.6197700500488 | val_abs_error = 474.6197700500488
Time execution (tranning): 64.145459 seconds 
Time execution (load saved model): 0.001493 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

81.56468872070313

num_try : 68 | val_loss = 81.56468872070313 | val acc = 6.932488918304443
val_error = -505.54041862487793 | val_abs_error = 505.54041862487793
Time execution (tranning): 48.537910 seconds 
Time execution (load saved model): 0.001464 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

84.62965835571289

num_try : 402 | val_loss = 84.62965835571289 | val acc = 4.296257972717285
val_error = -221.05998992919922 | val_abs_error = 221.05998992919922
Time execution (tranning): 159.724554 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 635
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

84.78079208374024

num_try : 415 | val_loss = 84.78079208374024 | val acc = 3.021592617034912
val_error = -2.871188707649708 | val_abs_error = 2.871188707649708
Time execution (tranning): 85.275604 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 345
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

85.0984115600586

num_try : 20 | val_loss = 85.0984115600586 | val acc = 7.076503276824951
val_error = -556.5686225891113 | val_abs_error = 556.5686225891113
Time execution (tranning): 52.289895 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 0.5}
----------

85.92177825927735

num_try : 391 | val_loss = 85.92177825927735 | val acc = 3.0304882526397705
val_error = -41.89315438270569 | val_abs_error = 41.89315438270569
Time execution (tranning): 98.205571 seconds 
Time execution (load saved model): 0.001599 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 384
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

85.93165092468261

num_try : 439 | val_loss = 85.93165092468261 | val acc = 3.030853509902954
val_error = -88.33765983581543 | val_abs_error = 88.33765983581543
Time execution (tranning): 100.225695 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 405
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

86.54660385131837

num_try : 463 | val_loss = 86.54660385131837 | val acc = 3.0322518348693848
val_error = -60.586220026016235 | val_abs_error = 60.586220026016235
Time execution (tranning): 113.241033 seconds 
Time execution (load saved model): 0.001558 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 463
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

87.50455276489258

num_try : 435 | val_loss = 87.50455276489258 | val acc = 3.094686985015869
val_error = -73.43469262123108 | val_abs_error = 73.43469262123108
Time execution (tranning): 77.477263 seconds 
Time execution (load saved model): 0.001639 seconds 
Time execution (use saved model): 0.000177 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

88.5662712097168

num_try : 450 | val_loss = 88.5662712097168 | val acc = 4.4485344886779785
val_error = -190.85568189620972 | val_abs_error = 190.85568189620972
Time execution (tranning): 152.058929 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 619
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

91.56541381835937

num_try : 317 | val_loss = 91.56541381835937 | val acc = 5.093137264251709
val_error = -223.034405708313 | val_abs_error = 223.034405708313
Time execution (tranning): 125.836638 seconds 
Time execution (load saved model): 0.001520 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 534
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

92.06620544433594

num_try : 423 | val_loss = 92.06620544433594 | val acc = 3.2000460624694824
val_error = -142.5378441810608 | val_abs_error = 142.5378441810608
Time execution (tranning): 185.663700 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 773
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

103.03577865600586

num_try : 339 | val_loss = 103.03577865600586 | val acc = 3.3685975074768066
val_error = -5.396928638219833 | val_abs_error = 5.396928638219833
Time execution (tranning): 188.198573 seconds 
Time execution (load saved model): 0.001516 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 805
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

103.99641555786133

num_try : 429 | val_loss = 103.99641555786133 | val acc = 5.567707061767578
val_error = -252.29473114013672 | val_abs_error = 252.29473114013672
Time execution (tranning): 153.122963 seconds 
Time execution (load saved model): 0.001568 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 620
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

107.94624252319336

num_try : 399 | val_loss = 107.94624252319336 | val acc = 3.510283946990967
val_error = -107.68135786056519 | val_abs_error = 107.68135786056519
Time execution (tranning): 157.711698 seconds 
Time execution (load saved model): 0.001564 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 660
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

112.28421783447266

num_try : 197 | val_loss = 112.28421783447266 | val acc = 5.763826847076416
val_error = -295.48027515411377 | val_abs_error = 295.48027515411377
Time execution (tranning): 68.422810 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

112.35954681396484

num_try : 293 | val_loss = 112.35954681396484 | val acc = 5.782222747802734
val_error = -248.7743854522705 | val_abs_error = 248.7743854522705
Time execution (tranning): 58.137648 seconds 
Time execution (load saved model): 0.001608 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

112.47675598144531

num_try : 341 | val_loss = 112.47675598144531 | val acc = 5.736746788024902
val_error = -199.00282621383667 | val_abs_error = 199.00282621383667
Time execution (tranning): 85.094081 seconds 
Time execution (load saved model): 0.001512 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 364
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

112.68506072998046

num_try : 365 | val_loss = 112.68506072998046 | val acc = 5.788414478302002
val_error = -244.0800666809082 | val_abs_error = 244.0800666809082
Time execution (tranning): 52.708153 seconds 
Time execution (load saved model): 0.001597 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 217
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

113.2212452697754

num_try : 217 | val_loss = 113.2212452697754 | val acc = 5.83018159866333
val_error = -193.82234811782837 | val_abs_error = 193.82234811782837
Time execution (tranning): 38.391048 seconds 
Time execution (load saved model): 0.001514 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 169
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

113.42120422363281

num_try : 241 | val_loss = 113.42120422363281 | val acc = 5.799158096313477
val_error = -206.51333332061768 | val_abs_error = 206.51333332061768
Time execution (tranning): 44.282870 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

113.53576477050781

num_try : 313 | val_loss = 113.53576477050781 | val acc = 5.824361801147461
val_error = -193.49292516708374 | val_abs_error = 193.49292516708374
Time execution (tranning): 38.050409 seconds 
Time execution (load saved model): 0.001516 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 161
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

113.78883163452149

num_try : 269 | val_loss = 113.78883163452149 | val acc = 5.835415363311768
val_error = -259.9449634552002 | val_abs_error = 259.9449634552002
Time execution (tranning): 54.450069 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

113.88542510986328

num_try : 97 | val_loss = 113.88542510986328 | val acc = 5.82787561416626
val_error = -187.09853887557983 | val_abs_error = 187.09853887557983
Time execution (tranning): 47.325976 seconds 
Time execution (load saved model): 0.001496 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.01120834350586

num_try : 265 | val_loss = 114.01120834350586 | val acc = 5.844613552093506
val_error = -205.3049087524414 | val_abs_error = 205.3049087524414
Time execution (tranning): 53.478218 seconds 
Time execution (load saved model): 0.001575 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.06467864990235

num_try : 337 | val_loss = 114.06467864990235 | val acc = 5.7904839515686035
val_error = -217.85759925842285 | val_abs_error = 217.85759925842285
Time execution (tranning): 59.311856 seconds 
Time execution (load saved model): 0.001515 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.32101104736329

num_try : 101 | val_loss = 114.32101104736329 | val acc = 5.844498634338379
val_error = -323.8929033279419 | val_abs_error = 323.8929033279419
Time execution (tranning): 56.084743 seconds 
Time execution (load saved model): 0.001541 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.54357727050781

num_try : 193 | val_loss = 114.54357727050781 | val acc = 5.834529399871826
val_error = -212.46118545532227 | val_abs_error = 212.46118545532227
Time execution (tranning): 44.682902 seconds 
Time execution (load saved model): 0.001498 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.61528167724609

num_try : 289 | val_loss = 114.61528167724609 | val acc = 5.893570899963379
val_error = -229.09951210021973 | val_abs_error = 229.09951210021973
Time execution (tranning): 30.930984 seconds 
Time execution (load saved model): 0.001519 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 134
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.65899688720702

num_try : 221 | val_loss = 114.65899688720702 | val acc = 5.8477888107299805
val_error = -265.216064453125 | val_abs_error = 265.216064453125
Time execution (tranning): 58.786775 seconds 
Time execution (load saved model): 0.001523 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.93625183105469

num_try : 321 | val_loss = 114.93625183105469 | val acc = 5.853588104248047
val_error = -397.029709815979 | val_abs_error = 397.029709815979
Time execution (tranning): 70.346786 seconds 
Time execution (load saved model): 0.001510 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

114.96539291381836

num_try : 169 | val_loss = 114.96539291381836 | val acc = 5.889155864715576
val_error = -231.77080154418945 | val_abs_error = 231.77080154418945
Time execution (tranning): 77.869231 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

115.15998016357422

num_try : 145 | val_loss = 115.15998016357422 | val acc = 5.9019856452941895
val_error = -145.89478969573975 | val_abs_error = 145.89478969573975
Time execution (tranning): 39.694349 seconds 
Time execution (load saved model): 0.001474 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 173
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

115.38629974365234

num_try : 121 | val_loss = 115.38629974365234 | val acc = 5.883178234100342
val_error = -168.39005947113037 | val_abs_error = 168.39005947113037
Time execution (tranning): 42.748199 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

116.252783203125

num_try : 149 | val_loss = 116.252783203125 | val acc = 5.930278778076172
val_error = -350.8831977844238 | val_abs_error = 350.8831977844238
Time execution (tranning): 61.123098 seconds 
Time execution (load saved model): 0.001498 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

116.35982299804688

num_try : 369 | val_loss = 116.35982299804688 | val acc = 5.90770149230957
val_error = -376.95329189300537 | val_abs_error = 376.95329189300537
Time execution (tranning): 69.643273 seconds 
Time execution (load saved model): 0.001609 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 296
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

116.91697814941406

num_try : 249 | val_loss = 116.91697814941406 | val acc = 5.928929805755615
val_error = -415.9109592437744 | val_abs_error = 415.9109592437744
Time execution (tranning): 72.656962 seconds 
Time execution (load saved model): 0.001575 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

117.19805465698242

num_try : 77 | val_loss = 117.19805465698242 | val acc = 5.943082809448242
val_error = -468.6779499053955 | val_abs_error = 468.6779499053955
Time execution (tranning): 55.599641 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

117.41215606689452

num_try : 245 | val_loss = 117.41215606689452 | val acc = 5.852982997894287
val_error = -244.48671340942383 | val_abs_error = 244.48671340942383
Time execution (tranning): 59.633483 seconds 
Time execution (load saved model): 0.001529 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

117.41381103515624

num_try : 273 | val_loss = 117.41381103515624 | val acc = 5.99648380279541
val_error = -415.20471572875977 | val_abs_error = 415.20471572875977
Time execution (tranning): 60.888050 seconds 
Time execution (load saved model): 0.001503 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

117.84781845092773

num_try : 1 | val_loss = 117.84781845092773 | val acc = 5.988915920257568
val_error = -230.54242134094238 | val_abs_error = 230.54242134094238
Time execution (tranning): 49.494402 seconds 
Time execution (load saved model): 0.001480 seconds 
Time execution (use saved model): 0.000158 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.02139617919921

num_try : 173 | val_loss = 118.02139617919921 | val acc = 5.967623710632324
val_error = -349.9119281768799 | val_abs_error = 349.9119281768799
Time execution (tranning): 53.270699 seconds 
Time execution (load saved model): 0.001487 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.15834564208984

num_try : 225 | val_loss = 118.15834564208984 | val acc = 5.972414493560791
val_error = -451.54504776000977 | val_abs_error = 451.54504776000977
Time execution (tranning): 48.943781 seconds 
Time execution (load saved model): 0.001628 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.36815277099609

num_try : 53 | val_loss = 118.36815277099609 | val acc = 5.949954986572266
val_error = -419.75340843200684 | val_abs_error = 419.75340843200684
Time execution (tranning): 61.899903 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.57459533691406

num_try : 73 | val_loss = 118.57459533691406 | val acc = 5.986067771911621
val_error = -187.7987504005432 | val_abs_error = 187.7987504005432
Time execution (tranning): 44.039269 seconds 
Time execution (load saved model): 0.001470 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.77117401123047

num_try : 345 | val_loss = 118.77117401123047 | val acc = 5.8935112953186035
val_error = -364.1637086868286 | val_abs_error = 364.1637086868286
Time execution (tranning): 58.331118 seconds 
Time execution (load saved model): 0.001586 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.77219177246094

num_try : 297 | val_loss = 118.77219177246094 | val acc = 6.004674434661865
val_error = -399.15645122528076 | val_abs_error = 399.15645122528076
Time execution (tranning): 86.515220 seconds 
Time execution (load saved model): 0.001518 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 371
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.800810546875

num_try : 453 | val_loss = 118.800810546875 | val acc = 5.958889484405518
val_error = -221.36449813842773 | val_abs_error = 221.36449813842773
Time execution (tranning): 98.706884 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 394
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.84883148193359

num_try : 125 | val_loss = 118.84883148193359 | val acc = 5.889820575714111
val_error = -357.7454090118408 | val_abs_error = 357.7454090118408
Time execution (tranning): 51.234994 seconds 
Time execution (load saved model): 0.001484 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

118.93940734863281

num_try : 5 | val_loss = 118.93940734863281 | val acc = 5.9738335609436035
val_error = -356.13203048706055 | val_abs_error = 356.13203048706055
Time execution (tranning): 63.305830 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

119.25654815673828

num_try : 25 | val_loss = 119.25654815673828 | val acc = 5.955015182495117
val_error = -304.8985481262207 | val_abs_error = 304.8985481262207
Time execution (tranning): 60.916699 seconds 
Time execution (load saved model): 0.001469 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

119.72393127441406

num_try : 201 | val_loss = 119.72393127441406 | val acc = 6.033322811126709
val_error = -423.33226203918457 | val_abs_error = 423.33226203918457
Time execution (tranning): 66.460830 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

119.75260650634766

num_try : 329 | val_loss = 119.75260650634766 | val acc = 6.011379718780518
val_error = -201.28800868988037 | val_abs_error = 201.28800868988037
Time execution (tranning): 77.640778 seconds 
Time execution (load saved model): 0.001602 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

119.97364837646484

num_try : 477 | val_loss = 119.97364837646484 | val acc = 6.000712871551514
val_error = -228.21848392486572 | val_abs_error = 228.21848392486572
Time execution (tranning): 119.782879 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 481
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

119.9928823852539

num_try : 49 | val_loss = 119.9928823852539 | val acc = 6.035966873168945
val_error = -181.42186403274536 | val_abs_error = 181.42186403274536
Time execution (tranning): 33.715260 seconds 
Time execution (load saved model): 0.001471 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 153
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

120.09033599853515

num_try : 177 | val_loss = 120.09033599853515 | val acc = 6.074099540710449
val_error = -512.2071266174316 | val_abs_error = 512.2071266174316
Time execution (tranning): 79.124071 seconds 
Time execution (load saved model): 0.001487 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

121.02962127685547

num_try : 325 | val_loss = 121.02962127685547 | val acc = 6.070741176605225
val_error = -170.28422355651855 | val_abs_error = 170.28422355651855
Time execution (tranning): 78.295389 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 342
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

121.21222351074219

num_try : 129 | val_loss = 121.21222351074219 | val acc = 6.132032871246338
val_error = -527.8289318084717 | val_abs_error = 527.8289318084717
Time execution (tranning): 62.339389 seconds 
Time execution (load saved model): 0.001487 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

121.31490783691406

num_try : 105 | val_loss = 121.31490783691406 | val acc = 6.124362468719482
val_error = -480.7610511779785 | val_abs_error = 480.7610511779785
Time execution (tranning): 73.115840 seconds 
Time execution (load saved model): 0.001482 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

121.45968658447265

num_try : 381 | val_loss = 121.45968658447265 | val acc = 6.033630847930908
val_error = -258.1500291824341 | val_abs_error = 258.1500291824341
Time execution (tranning): 115.053999 seconds 
Time execution (load saved model): 0.001583 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 489
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

122.30606811523438

num_try : 373 | val_loss = 122.30606811523438 | val acc = 6.025468826293945
val_error = -236.2874984741211 | val_abs_error = 236.2874984741211
Time execution (tranning): 80.416032 seconds 
Time execution (load saved model): 0.001517 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 349
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

122.57538787841797

num_try : 305 | val_loss = 122.57538787841797 | val acc = 6.072354793548584
val_error = -182.41047859191895 | val_abs_error = 182.41047859191895
Time execution (tranning): 74.590787 seconds 
Time execution (load saved model): 0.001514 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

122.58319244384765

num_try : 405 | val_loss = 122.58319244384765 | val acc = 6.115884304046631
val_error = -213.76869678497314 | val_abs_error = 213.76869678497314
Time execution (tranning): 99.719440 seconds 
Time execution (load saved model): 0.001563 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 400
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

123.40656799316406

num_try : 419 | val_loss = 123.40656799316406 | val acc = 3.7237260341644287
val_error = -137.37149238586426 | val_abs_error = 137.37149238586426
Time execution (tranning): 87.478367 seconds 
Time execution (load saved model): 0.001560 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 359
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

123.55379333496094

num_try : 467 | val_loss = 123.55379333496094 | val acc = 3.7131736278533936
val_error = -176.73602104187012 | val_abs_error = 176.73602104187012
Time execution (tranning): 83.047272 seconds 
Time execution (load saved model): 0.001554 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

123.95277648925781

num_try : 353 | val_loss = 123.95277648925781 | val acc = 6.139316558837891
val_error = -221.59900665283203 | val_abs_error = 221.59900665283203
Time execution (tranning): 63.978239 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

124.28352600097656

num_try : 257 | val_loss = 124.28352600097656 | val acc = 6.129001140594482
val_error = -217.15655326843262 | val_abs_error = 217.15655326843262
Time execution (tranning): 82.901001 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 364
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

124.40940826416016

num_try : 29 | val_loss = 124.40940826416016 | val acc = 6.077270984649658
val_error = -308.5082769393921 | val_abs_error = 308.5082769393921
Time execution (tranning): 42.676758 seconds 
Time execution (load saved model): 0.001458 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

124.66627731323243

num_try : 153 | val_loss = 124.66627731323243 | val acc = 6.182913303375244
val_error = -431.38318061828613 | val_abs_error = 431.38318061828613
Time execution (tranning): 48.041473 seconds 
Time execution (load saved model): 0.001505 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

124.93278625488281

num_try : 377 | val_loss = 124.93278625488281 | val acc = 6.158303260803223
val_error = -220.3927516937256 | val_abs_error = 220.3927516937256
Time execution (tranning): 78.430860 seconds 
Time execution (load saved model): 0.001590 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 333
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

126.07903076171876

num_try : 357 | val_loss = 126.07903076171876 | val acc = 6.167396068572998
val_error = -263.54877948760986 | val_abs_error = 263.54877948760986
Time execution (tranning): 89.721136 seconds 
Time execution (load saved model): 0.001520 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 380
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

126.54147979736328

num_try : 349 | val_loss = 126.54147979736328 | val acc = 6.222017288208008
val_error = -194.32342052459717 | val_abs_error = 194.32342052459717
Time execution (tranning): 60.612839 seconds 
Time execution (load saved model): 0.001540 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

127.01248992919922

num_try : 309 | val_loss = 127.01248992919922 | val acc = 6.1739630699157715
val_error = -243.20261478424072 | val_abs_error = 243.20261478424072
Time execution (tranning): 98.259305 seconds 
Time execution (load saved model): 0.001523 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

127.71124053955079

num_try : 443 | val_loss = 127.71124053955079 | val acc = 3.779798746109009
val_error = -125.25110244750977 | val_abs_error = 125.25110244750977
Time execution (tranning): 81.103846 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

129.30664916992188

num_try : 469 | val_loss = 129.30664916992188 | val acc = 6.314472675323486
val_error = -219.04704570770264 | val_abs_error = 219.04704570770264
Time execution (tranning): 54.190096 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

129.33896179199218

num_try : 397 | val_loss = 129.33896179199218 | val acc = 6.306149959564209
val_error = -237.79497146606445 | val_abs_error = 237.79497146606445
Time execution (tranning): 56.935765 seconds 
Time execution (load saved model): 0.001572 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

129.34011169433595

num_try : 301 | val_loss = 129.34011169433595 | val acc = 6.242530345916748
val_error = -188.72098922729492 | val_abs_error = 188.72098922729492
Time execution (tranning): 70.827727 seconds 
Time execution (load saved model): 0.001512 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

129.3429232788086

num_try : 277 | val_loss = 129.3429232788086 | val acc = 6.2949628829956055
val_error = -156.42633438110352 | val_abs_error = 156.42633438110352
Time execution (tranning): 60.239297 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

131.68373413085936

num_try : 33 | val_loss = 131.68373413085936 | val acc = 6.491151332855225
val_error = -474.1858959197998 | val_abs_error = 474.1858959197998
Time execution (tranning): 61.144764 seconds 
Time execution (load saved model): 0.001471 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

131.97984527587892

num_try : 205 | val_loss = 131.97984527587892 | val acc = 6.3483734130859375
val_error = -119.09098625183105 | val_abs_error = 119.09098625183105
Time execution (tranning): 51.594292 seconds 
Time execution (load saved model): 0.001494 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.0283218383789

num_try : 185 | val_loss = 132.0283218383789 | val acc = 6.335574150085449
val_error = -288.0989074707031 | val_abs_error = 288.0989074707031
Time execution (tranning): 72.292113 seconds 
Time execution (load saved model): 0.001497 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.1677914428711

num_try : 61 | val_loss = 132.1677914428711 | val acc = 6.355449199676514
val_error = -190.17367362976074 | val_abs_error = 190.17367362976074
Time execution (tranning): 74.198411 seconds 
Time execution (load saved model): 0.001472 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.25047760009767

num_try : 229 | val_loss = 132.25047760009767 | val acc = 6.347332954406738
val_error = -198.16460609436035 | val_abs_error = 198.16460609436035
Time execution (tranning): 46.858478 seconds 
Time execution (load saved model): 0.001573 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.46107879638672

num_try : 133 | val_loss = 132.46107879638672 | val acc = 6.302673816680908
val_error = -266.6483402252197 | val_abs_error = 266.6483402252197
Time execution (tranning): 61.051753 seconds 
Time execution (load saved model): 0.001471 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.5039663696289

num_try : 253 | val_loss = 132.5039663696289 | val acc = 6.362679958343506
val_error = -216.85690879821777 | val_abs_error = 216.85690879821777
Time execution (tranning): 56.116517 seconds 
Time execution (load saved model): 0.001499 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

132.52367492675782

num_try : 181 | val_loss = 132.52367492675782 | val acc = 6.30564546585083
val_error = -209.16321277618408 | val_abs_error = 209.16321277618408
Time execution (tranning): 93.017079 seconds 
Time execution (load saved model): 0.001624 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 414
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

133.46720397949218

num_try : 430 | val_loss = 133.46720397949218 | val acc = 5.602844715118408
val_error = -254.0485143661499 | val_abs_error = 254.0485143661499
Time execution (tranning): 113.655725 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 461
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

133.7539306640625

num_try : 113 | val_loss = 133.7539306640625 | val acc = 6.385580062866211
val_error = -307.8739881515503 | val_abs_error = 307.8739881515503
Time execution (tranning): 72.328515 seconds 
Time execution (load saved model): 0.001495 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

134.11166534423828

num_try : 81 | val_loss = 134.11166534423828 | val acc = 6.446024417877197
val_error = -452.6871681213379 | val_abs_error = 452.6871681213379
Time execution (tranning): 61.411070 seconds 
Time execution (load saved model): 0.001472 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

134.90822570800782

num_try : 37 | val_loss = 134.90822570800782 | val acc = 6.407402515411377
val_error = -252.05624103546143 | val_abs_error = 252.05624103546143
Time execution (tranning): 70.139239 seconds 
Time execution (load saved model): 0.001469 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 320
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

134.92794189453124

num_try : 161 | val_loss = 134.92794189453124 | val acc = 6.391450881958008
val_error = -281.2402009963989 | val_abs_error = 281.2402009963989
Time execution (tranning): 64.001501 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

135.25522491455078

num_try : 333 | val_loss = 135.25522491455078 | val acc = 6.418115139007568
val_error = -262.06581592559814 | val_abs_error = 262.06581592559814
Time execution (tranning): 70.773428 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

135.8914581298828

num_try : 237 | val_loss = 135.8914581298828 | val acc = 6.398733615875244
val_error = -306.1682462692261 | val_abs_error = 306.1682462692261
Time execution (tranning): 71.347740 seconds 
Time execution (load saved model): 0.001495 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.05939636230468

num_try : 261 | val_loss = 136.05939636230468 | val acc = 6.392818927764893
val_error = -298.0513572692871 | val_abs_error = 298.0513572692871
Time execution (tranning): 71.528069 seconds 
Time execution (load saved model): 0.001558 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.21924011230467

num_try : 406 | val_loss = 136.21924011230467 | val acc = 5.629324913024902
val_error = -164.42198753356934 | val_abs_error = 164.42198753356934
Time execution (tranning): 94.765316 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

136.23049438476562

num_try : 281 | val_loss = 136.23049438476562 | val acc = 6.454476833343506
val_error = -240.69314002990723 | val_abs_error = 240.69314002990723
Time execution (tranning): 41.550893 seconds 
Time execution (load saved model): 0.001532 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 178
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.3009994506836

num_try : 449 | val_loss = 136.3009994506836 | val acc = 6.511006832122803
val_error = -187.66428232192993 | val_abs_error = 187.66428232192993
Time execution (tranning): 48.351464 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.32533294677734

num_try : 9 | val_loss = 136.32533294677734 | val acc = 6.405557632446289
val_error = -448.63014221191406 | val_abs_error = 448.63014221191406
Time execution (tranning): 75.623212 seconds 
Time execution (load saved model): 0.001526 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.46630004882812

num_try : 233 | val_loss = 136.46630004882812 | val acc = 6.466238975524902
val_error = -250.57470798492432 | val_abs_error = 250.57470798492432
Time execution (tranning): 71.296095 seconds 
Time execution (load saved model): 0.001569 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.69715240478516

num_try : 209 | val_loss = 136.69715240478516 | val acc = 6.440917491912842
val_error = -267.2039270401001 | val_abs_error = 267.2039270401001
Time execution (tranning): 46.642368 seconds 
Time execution (load saved model): 0.001530 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

136.7021905517578

num_try : 213 | val_loss = 136.7021905517578 | val acc = 6.4307355880737305
val_error = -335.3933811187744 | val_abs_error = 335.3933811187744
Time execution (tranning): 66.591637 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

137.52873809814454

num_try : 314 | val_loss = 137.52873809814454 | val acc = 5.674919128417969
val_error = -151.4132022857666 | val_abs_error = 151.4132022857666
Time execution (tranning): 67.404197 seconds 
Time execution (load saved model): 0.001563 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 290
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

137.54054840087892

num_try : 157 | val_loss = 137.54054840087892 | val acc = 6.458290100097656
val_error = -174.79904890060425 | val_abs_error = 174.79904890060425
Time execution (tranning): 49.585082 seconds 
Time execution (load saved model): 0.001506 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

137.7087924194336

num_try : 454 | val_loss = 137.7087924194336 | val acc = 5.707080841064453
val_error = -224.77939128875732 | val_abs_error = 224.77939128875732
Time execution (tranning): 120.344155 seconds 
Time execution (load saved model): 0.001638 seconds 
Time execution (use saved model): 0.000176 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 480
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

138.11407592773438

num_try : 57 | val_loss = 138.11407592773438 | val acc = 6.448668003082275
val_error = -502.13661193847656 | val_abs_error = 502.13661193847656
Time execution (tranning): 48.310165 seconds 
Time execution (load saved model): 0.001527 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 217
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

138.49957244873048

num_try : 85 | val_loss = 138.49957244873048 | val acc = 6.5272321701049805
val_error = -365.5884027481079 | val_abs_error = 365.5884027481079
Time execution (tranning): 82.201531 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 371
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

138.9939810180664

num_try : 89 | val_loss = 138.9939810180664 | val acc = 6.498982906341553
val_error = -373.6047029495239 | val_abs_error = 373.6047029495239
Time execution (tranning): 81.006966 seconds 
Time execution (load saved model): 0.001474 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

139.85695922851562

num_try : 137 | val_loss = 139.85695922851562 | val acc = 6.517816066741943
val_error = -291.1850929260254 | val_abs_error = 291.1850929260254
Time execution (tranning): 55.975841 seconds 
Time execution (load saved model): 0.001509 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

139.92183013916016

num_try : 109 | val_loss = 139.92183013916016 | val acc = 6.528831958770752
val_error = -240.55848121643066 | val_abs_error = 240.55848121643066
Time execution (tranning): 42.431984 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

140.42209045410155

num_try : 13 | val_loss = 140.42209045410155 | val acc = 6.535552501678467
val_error = -201.52828693389893 | val_abs_error = 201.52828693389893
Time execution (tranning): 46.628605 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

140.94255615234374

num_try : 41 | val_loss = 140.94255615234374 | val acc = 6.507676124572754
val_error = -363.33351135253906 | val_abs_error = 363.33351135253906
Time execution (tranning): 61.175704 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

141.4826123046875

num_try : 246 | val_loss = 141.4826123046875 | val acc = 5.77280855178833
val_error = -301.5287160873413 | val_abs_error = 301.5287160873413
Time execution (tranning): 63.194450 seconds 
Time execution (load saved model): 0.001572 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 275
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

141.9798907470703

num_try : 294 | val_loss = 141.9798907470703 | val acc = 5.775190830230713
val_error = -262.24682331085205 | val_abs_error = 262.24682331085205
Time execution (tranning): 57.079132 seconds 
Time execution (load saved model): 0.001517 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

141.9862255859375

num_try : 338 | val_loss = 141.9862255859375 | val acc = 5.8040289878845215
val_error = -206.0568332672119 | val_abs_error = 206.0568332672119
Time execution (tranning): 35.876389 seconds 
Time execution (load saved model): 0.001593 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 154
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

141.98659149169922

num_try : 17 | val_loss = 141.98659149169922 | val acc = 6.55073356628418
val_error = -324.2806911468506 | val_abs_error = 324.2806911468506
Time execution (tranning): 83.375492 seconds 
Time execution (load saved model): 0.001483 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 381
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

142.19100708007812

num_try : 342 | val_loss = 142.19100708007812 | val acc = 5.768169403076172
val_error = -180.12715578079224 | val_abs_error = 180.12715578079224
Time execution (tranning): 47.099675 seconds 
Time execution (load saved model): 0.001518 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

142.28562042236328

num_try : 170 | val_loss = 142.28562042236328 | val acc = 5.763703346252441
val_error = -131.2225341796875 | val_abs_error = 131.2225341796875
Time execution (tranning): 58.474802 seconds 
Time execution (load saved model): 0.001580 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

142.33367065429687

num_try : 270 | val_loss = 142.33367065429687 | val acc = 5.783517837524414
val_error = -253.47981452941895 | val_abs_error = 253.47981452941895
Time execution (tranning): 64.012963 seconds 
Time execution (load saved model): 0.001536 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

142.35009674072265

num_try : 242 | val_loss = 142.35009674072265 | val acc = 5.793272018432617
val_error = -180.39100170135498 | val_abs_error = 180.39100170135498
Time execution (tranning): 46.369465 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

142.77889923095702

num_try : 146 | val_loss = 142.77889923095702 | val acc = 5.793588161468506
val_error = -192.84979104995728 | val_abs_error = 192.84979104995728
Time execution (tranning): 49.278136 seconds 
Time execution (load saved model): 0.001475 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

142.8635855102539

num_try : 318 | val_loss = 142.8635855102539 | val acc = 5.795748233795166
val_error = -213.18402290344238 | val_abs_error = 213.18402290344238
Time execution (tranning): 44.929928 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

143.08739715576172

num_try : 290 | val_loss = 143.08739715576172 | val acc = 5.821837425231934
val_error = -160.83123683929443 | val_abs_error = 160.83123683929443
Time execution (tranning): 46.309627 seconds 
Time execution (load saved model): 0.001566 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

143.5256753540039

num_try : 194 | val_loss = 143.5256753540039 | val acc = 5.777250289916992
val_error = -184.35490131378174 | val_abs_error = 184.35490131378174
Time execution (tranning): 82.177955 seconds 
Time execution (load saved model): 0.001492 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 365
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

143.7263638305664

num_try : 126 | val_loss = 143.7263638305664 | val acc = 5.86359167098999
val_error = -363.6735200881958 | val_abs_error = 363.6735200881958
Time execution (tranning): 67.638121 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

143.79245239257813

num_try : 266 | val_loss = 143.79245239257813 | val acc = 5.830505847930908
val_error = -199.2985725402832 | val_abs_error = 199.2985725402832
Time execution (tranning): 61.946364 seconds 
Time execution (load saved model): 0.001502 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

143.8221286010742

num_try : 141 | val_loss = 143.8221286010742 | val acc = 6.559288024902344
val_error = -434.1166019439697 | val_abs_error = 434.1166019439697
Time execution (tranning): 60.859190 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

143.82463745117187

num_try : 285 | val_loss = 143.82463745117187 | val acc = 6.570791244506836
val_error = -341.0437822341919 | val_abs_error = 341.0437822341919
Time execution (tranning): 56.734372 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

144.04809814453125

num_try : 102 | val_loss = 144.04809814453125 | val acc = 5.863953113555908
val_error = -374.3356943130493 | val_abs_error = 374.3356943130493
Time execution (tranning): 68.738737 seconds 
Time execution (load saved model): 0.001477 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

144.21307037353515

num_try : 150 | val_loss = 144.21307037353515 | val acc = 5.849505424499512
val_error = -381.39259815216064 | val_abs_error = 381.39259815216064
Time execution (tranning): 72.977659 seconds 
Time execution (load saved model): 0.001495 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

144.23468780517578

num_try : 218 | val_loss = 144.23468780517578 | val acc = 5.846486568450928
val_error = -164.11404609680176 | val_abs_error = 164.11404609680176
Time execution (tranning): 46.228744 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

144.6645037841797

num_try : 189 | val_loss = 144.6645037841797 | val acc = 6.578300952911377
val_error = -412.5324249267578 | val_abs_error = 412.5324249267578
Time execution (tranning): 80.588269 seconds 
Time execution (load saved model): 0.001554 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

145.33246704101563

num_try : 222 | val_loss = 145.33246704101563 | val acc = 5.873810768127441
val_error = -249.97553825378418 | val_abs_error = 249.97553825378418
Time execution (tranning): 44.455752 seconds 
Time execution (load saved model): 0.001499 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

145.50430694580078

num_try : 98 | val_loss = 145.50430694580078 | val acc = 5.871342182159424
val_error = -164.42819833755493 | val_abs_error = 164.42819833755493
Time execution (tranning): 66.599887 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

145.77874053955077

num_try : 117 | val_loss = 145.77874053955077 | val acc = 6.6369123458862305
val_error = -389.5350694656372 | val_abs_error = 389.5350694656372
Time execution (tranning): 52.102015 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

145.85522521972655

num_try : 74 | val_loss = 145.85522521972655 | val acc = 5.893032073974609
val_error = -267.3792839050293 | val_abs_error = 267.3792839050293
Time execution (tranning): 59.690941 seconds 
Time execution (load saved model): 0.001556 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

145.9951837158203

num_try : 198 | val_loss = 145.9951837158203 | val acc = 5.909092426300049
val_error = -278.6659240722656 | val_abs_error = 278.6659240722656
Time execution (tranning): 44.031384 seconds 
Time execution (load saved model): 0.001501 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

146.3492953491211

num_try : 122 | val_loss = 146.3492953491211 | val acc = 5.838744640350342
val_error = -131.6378116607666 | val_abs_error = 131.6378116607666
Time execution (tranning): 47.584587 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

146.61749603271485

num_try : 370 | val_loss = 146.61749603271485 | val acc = 5.874138832092285
val_error = -378.6548852920532 | val_abs_error = 378.6548852920532
Time execution (tranning): 70.748403 seconds 
Time execution (load saved model): 0.001523 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

146.81600646972657

num_try : 298 | val_loss = 146.81600646972657 | val acc = 5.8937554359436035
val_error = -424.7563362121582 | val_abs_error = 424.7563362121582
Time execution (tranning): 55.959906 seconds 
Time execution (load saved model): 0.001539 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

147.02968017578124

num_try : 350 | val_loss = 147.02968017578124 | val acc = 5.92724609375
val_error = -201.45204067230225 | val_abs_error = 201.45204067230225
Time execution (tranning): 98.454204 seconds 
Time execution (load saved model): 0.001617 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 432
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

147.06251770019531

num_try : 274 | val_loss = 147.06251770019531 | val acc = 5.937192440032959
val_error = -423.98314476013184 | val_abs_error = 423.98314476013184
Time execution (tranning): 69.722247 seconds 
Time execution (load saved model): 0.001518 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 306
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

147.5901742553711

num_try : 6 | val_loss = 147.5901742553711 | val acc = 5.998940467834473
val_error = -415.39878845214844 | val_abs_error = 415.39878845214844
Time execution (tranning): 57.636311 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 263
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

148.37318572998046

num_try : 30 | val_loss = 148.37318572998046 | val acc = 5.937031269073486
val_error = -446.7282295227051 | val_abs_error = 446.7282295227051
Time execution (tranning): 81.761789 seconds 
Time execution (load saved model): 0.001466 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

148.68732025146485

num_try : 78 | val_loss = 148.68732025146485 | val acc = 5.9661478996276855
val_error = -469.7783946990967 | val_abs_error = 469.7783946990967
Time execution (tranning): 69.044343 seconds 
Time execution (load saved model): 0.001476 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

148.96424530029296

num_try : 322 | val_loss = 148.96424530029296 | val acc = 5.90239143371582
val_error = -354.7797203063965 | val_abs_error = 354.7797203063965
Time execution (tranning): 59.130495 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.03247833251953

num_try : 26 | val_loss = 149.03247833251953 | val acc = 5.988870620727539
val_error = -281.28600120544434 | val_abs_error = 281.28600120544434
Time execution (tranning): 54.905243 seconds 
Time execution (load saved model): 0.001466 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.0983331298828

num_try : 378 | val_loss = 149.0983331298828 | val acc = 6.010881423950195
val_error = -213.8918399810791 | val_abs_error = 213.8918399810791
Time execution (tranning): 103.791387 seconds 
Time execution (load saved model): 0.001537 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.30868041992187

num_try : 346 | val_loss = 149.30868041992187 | val acc = 6.007087707519531
val_error = -390.87865352630615 | val_abs_error = 390.87865352630615
Time execution (tranning): 65.366035 seconds 
Time execution (load saved model): 0.001602 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.46353393554688

num_try : 50 | val_loss = 149.46353393554688 | val acc = 5.919091701507568
val_error = -270.0549364089966 | val_abs_error = 270.0549364089966
Time execution (tranning): 53.098132 seconds 
Time execution (load saved model): 0.001470 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.48459747314453

num_try : 174 | val_loss = 149.48459747314453 | val acc = 5.92921257019043
val_error = -355.71467876434326 | val_abs_error = 355.71467876434326
Time execution (tranning): 55.265822 seconds 
Time execution (load saved model): 0.001543 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.49433715820314

num_try : 2 | val_loss = 149.49433715820314 | val acc = 5.96655797958374
val_error = -269.41356658935547 | val_abs_error = 269.41356658935547
Time execution (tranning): 53.889114 seconds 
Time execution (load saved model): 0.001467 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

149.89380584716798

num_try : 93 | val_loss = 149.89380584716798 | val acc = 6.708609104156494
val_error = -463.9493942260742 | val_abs_error = 463.9493942260742
Time execution (tranning): 91.703068 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 408
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

150.10297485351563

num_try : 202 | val_loss = 150.10297485351563 | val acc = 6.007466793060303
val_error = -405.7934284210205 | val_abs_error = 405.7934284210205
Time execution (tranning): 53.958306 seconds 
Time execution (load saved model): 0.001498 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

150.98460815429686

num_try : 226 | val_loss = 150.98460815429686 | val acc = 6.044915676116943
val_error = -412.8661632537842 | val_abs_error = 412.8661632537842
Time execution (tranning): 56.643314 seconds 
Time execution (load saved model): 0.001496 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

152.24995697021484

num_try : 254 | val_loss = 152.24995697021484 | val acc = 6.03548002243042
val_error = -200.92623233795166 | val_abs_error = 200.92623233795166
Time execution (tranning): 91.691363 seconds 
Time execution (load saved model): 0.001561 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 410
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

152.34759490966798

num_try : 382 | val_loss = 152.34759490966798 | val acc = 6.055477619171143
val_error = -273.15948009490967 | val_abs_error = 273.15948009490967
Time execution (tranning): 109.992422 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 461
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

152.35020751953124

num_try : 106 | val_loss = 152.35020751953124 | val acc = 6.066692352294922
val_error = -503.21149826049805 | val_abs_error = 503.21149826049805
Time execution (tranning): 68.551115 seconds 
Time execution (load saved model): 0.001475 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

152.51932220458986

num_try : 154 | val_loss = 152.51932220458986 | val acc = 6.1109113693237305
val_error = -509.90772247314453 | val_abs_error = 509.90772247314453
Time execution (tranning): 61.903470 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

152.9627716064453

num_try : 45 | val_loss = 152.9627716064453 | val acc = 6.76426362991333
val_error = -478.0857563018799 | val_abs_error = 478.0857563018799
Time execution (tranning): 66.409311 seconds 
Time execution (load saved model): 0.001473 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

153.25482604980468

num_try : 165 | val_loss = 153.25482604980468 | val acc = 6.789169788360596
val_error = -397.2848415374756 | val_abs_error = 397.2848415374756
Time execution (tranning): 52.930061 seconds 
Time execution (load saved model): 0.001509 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

153.25501556396483

num_try : 130 | val_loss = 153.25501556396483 | val acc = 6.090942859649658
val_error = -473.1717109680176 | val_abs_error = 473.1717109680176
Time execution (tranning): 81.656303 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 366
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

153.47844543457032

num_try : 178 | val_loss = 153.47844543457032 | val acc = 6.113280296325684
val_error = -483.00018310546875 | val_abs_error = 483.00018310546875
Time execution (tranning): 71.345541 seconds 
Time execution (load saved model): 0.001494 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

154.61580352783204

num_try : 330 | val_loss = 154.61580352783204 | val acc = 6.086592674255371
val_error = -210.23807525634766 | val_abs_error = 210.23807525634766
Time execution (tranning): 70.554832 seconds 
Time execution (load saved model): 0.001516 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

154.75889373779296

num_try : 54 | val_loss = 154.75889373779296 | val acc = 6.031254768371582
val_error = -361.5922689437866 | val_abs_error = 361.5922689437866
Time execution (tranning): 48.185077 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

155.75317321777345

num_try : 234 | val_loss = 155.75317321777345 | val acc = 6.1201910972595215
val_error = -196.72077894210815 | val_abs_error = 196.72077894210815
Time execution (tranning): 82.896340 seconds 
Time execution (load saved model): 0.001529 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

155.99084350585937

num_try : 69 | val_loss = 155.99084350585937 | val acc = 6.816490650177002
val_error = -451.4374256134033 | val_abs_error = 451.4374256134033
Time execution (tranning): 71.077785 seconds 
Time execution (load saved model): 0.001478 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

156.77108184814452

num_try : 250 | val_loss = 156.77108184814452 | val acc = 6.125960350036621
val_error = -363.6206865310669 | val_abs_error = 363.6206865310669
Time execution (tranning): 50.797711 seconds 
Time execution (load saved model): 0.001531 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 217
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

158.0109069824219

num_try : 258 | val_loss = 158.0109069824219 | val acc = 6.1744866371154785
val_error = -188.64457607269287 | val_abs_error = 188.64457607269287
Time execution (tranning): 79.652313 seconds 
Time execution (load saved model): 0.001517 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 349
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

159.37135833740234

num_try : 302 | val_loss = 159.37135833740234 | val acc = 6.2061920166015625
val_error = -192.32213497161865 | val_abs_error = 192.32213497161865
Time execution (tranning): 50.681408 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

159.5028811645508

num_try : 478 | val_loss = 159.5028811645508 | val acc = 6.145644664764404
val_error = -193.58090162277222 | val_abs_error = 193.58090162277222
Time execution (tranning): 105.894770 seconds 
Time execution (load saved model): 0.001565 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 429
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

159.80749145507812

num_try : 374 | val_loss = 159.80749145507812 | val acc = 6.204975128173828
val_error = -152.68399715423584 | val_abs_error = 152.68399715423584
Time execution (tranning): 47.339368 seconds 
Time execution (load saved model): 0.001557 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

159.91976013183594

num_try : 65 | val_loss = 159.91976013183594 | val acc = 6.8356852531433105
val_error = -424.4002342224121 | val_abs_error = 424.4002342224121
Time execution (tranning): 55.950816 seconds 
Time execution (load saved model): 0.001469 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

160.3399917602539

num_try : 310 | val_loss = 160.3399917602539 | val acc = 6.189444541931152
val_error = -243.59564781188965 | val_abs_error = 243.59564781188965
Time execution (tranning): 81.336982 seconds 
Time execution (load saved model): 0.001527 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

160.42423461914063

num_try : 306 | val_loss = 160.42423461914063 | val acc = 6.250561714172363
val_error = -178.11740636825562 | val_abs_error = 178.11740636825562
Time execution (tranning): 92.041554 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

160.95148498535156

num_try : 470 | val_loss = 160.95148498535156 | val acc = 6.242464065551758
val_error = -85.87532639503479 | val_abs_error = 85.87532639503479
Time execution (tranning): 70.774991 seconds 
Time execution (load saved model): 0.001607 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

161.1388003540039

num_try : 354 | val_loss = 161.1388003540039 | val acc = 6.253838539123535
val_error = -227.2686004638672 | val_abs_error = 227.2686004638672
Time execution (tranning): 55.604755 seconds 
Time execution (load saved model): 0.001595 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

162.1387661743164

num_try : 138 | val_loss = 162.1387661743164 | val acc = 6.242948055267334
val_error = -271.1562395095825 | val_abs_error = 271.1562395095825
Time execution (tranning): 81.911858 seconds 
Time execution (load saved model): 0.001485 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 360
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

163.04006591796875

num_try : 326 | val_loss = 163.04006591796875 | val acc = 6.25949764251709
val_error = -157.97878503799438 | val_abs_error = 157.97878503799438
Time execution (tranning): 56.882342 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

163.16948974609375

num_try : 395 | val_loss = 163.16948974609375 | val acc = 4.342950820922852
val_error = -233.4508180618286 | val_abs_error = 233.4508180618286
Time execution (tranning): 91.374449 seconds 
Time execution (load saved model): 0.001555 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 366
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

163.26113372802735

num_try : 286 | val_loss = 163.26113372802735 | val acc = 6.25027322769165
val_error = -287.47222423553467 | val_abs_error = 287.47222423553467
Time execution (tranning): 96.893202 seconds 
Time execution (load saved model): 0.001576 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 411
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

164.11195526123046

num_try : 230 | val_loss = 164.11195526123046 | val acc = 6.2532877922058105
val_error = -245.92106342315674 | val_abs_error = 245.92106342315674
Time execution (tranning): 62.449988 seconds 
Time execution (load saved model): 0.001575 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

164.40592712402344

num_try : 210 | val_loss = 164.40592712402344 | val acc = 6.287840843200684
val_error = -226.96607112884521 | val_abs_error = 226.96607112884521
Time execution (tranning): 59.460467 seconds 
Time execution (load saved model): 0.001577 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

164.8965072631836

num_try : 134 | val_loss = 164.8965072631836 | val acc = 6.320351600646973
val_error = -167.17325448989868 | val_abs_error = 167.17325448989868
Time execution (tranning): 62.994394 seconds 
Time execution (load saved model): 0.001492 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

165.41063720703124

num_try : 451 | val_loss = 165.41063720703124 | val acc = 4.297902584075928
val_error = -230.77092170715332 | val_abs_error = 230.77092170715332
Time execution (tranning): 138.646764 seconds 
Time execution (load saved model): 0.001564 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 564
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

166.2793682861328

num_try : 10 | val_loss = 166.2793682861328 | val acc = 6.379196643829346
val_error = -484.40022468566895 | val_abs_error = 484.40022468566895
Time execution (tranning): 47.295220 seconds 
Time execution (load saved model): 0.001467 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

166.80666931152345

num_try : 186 | val_loss = 166.80666931152345 | val acc = 6.354748249053955
val_error = -285.9819173812866 | val_abs_error = 285.9819173812866
Time execution (tranning): 71.160423 seconds 
Time execution (load saved model): 0.001503 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

166.88375457763672

num_try : 21 | val_loss = 166.88375457763672 | val acc = 7.059854507446289
val_error = -520.2212333679199 | val_abs_error = 520.2212333679199
Time execution (tranning): 38.416660 seconds 
Time execution (load saved model): 0.001482 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

168.3332647705078

num_try : 86 | val_loss = 168.3332647705078 | val acc = 6.402913570404053
val_error = -180.0132393836975 | val_abs_error = 180.0132393836975
Time execution (tranning): 77.302416 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

168.90999969482422

num_try : 334 | val_loss = 168.90999969482422 | val acc = 6.3870930671691895
val_error = -242.67373085021973 | val_abs_error = 242.67373085021973
Time execution (tranning): 61.572256 seconds 
Time execution (load saved model): 0.001556 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

169.16107391357423

num_try : 58 | val_loss = 169.16107391357423 | val acc = 6.486014366149902
val_error = -519.3130016326904 | val_abs_error = 519.3130016326904
Time execution (tranning): 50.027509 seconds 
Time execution (load saved model): 0.001503 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

169.66865661621094

num_try : 14 | val_loss = 169.66865661621094 | val acc = 6.368117332458496
val_error = -237.93237209320068 | val_abs_error = 237.93237209320068
Time execution (tranning): 75.722963 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

169.74031555175782

num_try : 62 | val_loss = 169.74031555175782 | val acc = 6.416438579559326
val_error = -182.77422189712524 | val_abs_error = 182.77422189712524
Time execution (tranning): 74.889137 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 337
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

170.30576751708983

num_try : 42 | val_loss = 170.30576751708983 | val acc = 6.414236545562744
val_error = -348.7607955932617 | val_abs_error = 348.7607955932617
Time execution (tranning): 87.397808 seconds 
Time execution (load saved model): 0.001484 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 385
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

171.59287445068358

num_try : 282 | val_loss = 171.59287445068358 | val acc = 6.434525966644287
val_error = -208.22322368621826 | val_abs_error = 208.22322368621826
Time execution (tranning): 53.568820 seconds 
Time execution (load saved model): 0.001583 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

171.87179626464842

num_try : 474 | val_loss = 171.87179626464842 | val acc = 6.453214645385742
val_error = -188.4482979774475 | val_abs_error = 188.4482979774475
Time execution (tranning): 55.292787 seconds 
Time execution (load saved model): 0.001577 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

171.98192749023437

num_try : 262 | val_loss = 171.98192749023437 | val acc = 6.408127784729004
val_error = -315.4524087905884 | val_abs_error = 315.4524087905884
Time execution (tranning): 79.218270 seconds 
Time execution (load saved model): 0.001506 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 342
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

172.13923217773439

num_try : 110 | val_loss = 172.13923217773439 | val acc = 6.463308811187744
val_error = -184.90092754364014 | val_abs_error = 184.90092754364014
Time execution (tranning): 56.233560 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

172.2514810180664

num_try : 358 | val_loss = 172.2514810180664 | val acc = 6.4456467628479
val_error = -241.9712781906128 | val_abs_error = 241.9712781906128
Time execution (tranning): 53.772203 seconds 
Time execution (load saved model): 0.001608 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

172.55273193359375

num_try : 38 | val_loss = 172.55273193359375 | val acc = 6.439074516296387
val_error = -233.22217464447021 | val_abs_error = 233.22217464447021
Time execution (tranning): 74.171209 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 338
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

173.40914916992188

num_try : 182 | val_loss = 173.40914916992188 | val acc = 6.4812140464782715
val_error = -216.46122932434082 | val_abs_error = 216.46122932434082
Time execution (tranning): 41.645456 seconds 
Time execution (load saved model): 0.001511 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 181
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

174.16013916015626

num_try : 82 | val_loss = 174.16013916015626 | val acc = 6.4900031089782715
val_error = -475.1106262207031 | val_abs_error = 475.1106262207031
Time execution (tranning): 59.238643 seconds 
Time execution (load saved model): 0.001475 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

174.55092803955077

num_try : 278 | val_loss = 174.55092803955077 | val acc = 6.475602626800537
val_error = -183.0241560935974 | val_abs_error = 183.0241560935974
Time execution (tranning): 65.471319 seconds 
Time execution (load saved model): 0.001506 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 290
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

174.598359375

num_try : 114 | val_loss = 174.598359375 | val acc = 6.484926223754883
val_error = -291.59913063049316 | val_abs_error = 291.59913063049316
Time execution (tranning): 61.989187 seconds 
Time execution (load saved model): 0.001562 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

175.09251770019532

num_try : 162 | val_loss = 175.09251770019532 | val acc = 6.419673919677734
val_error = -286.6814851760864 | val_abs_error = 286.6814851760864
Time execution (tranning): 58.871642 seconds 
Time execution (load saved model): 0.001517 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

175.47583465576173

num_try : 214 | val_loss = 175.47583465576173 | val acc = 6.4798455238342285
val_error = -328.3482551574707 | val_abs_error = 328.3482551574707
Time execution (tranning): 55.570745 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

175.60253936767577

num_try : 158 | val_loss = 175.60253936767577 | val acc = 6.526420593261719
val_error = -243.1084156036377 | val_abs_error = 243.1084156036377
Time execution (tranning): 42.984900 seconds 
Time execution (load saved model): 0.001580 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

175.71752319335937

num_try : 166 | val_loss = 175.71752319335937 | val acc = 6.480456829071045
val_error = -390.1589632034302 | val_abs_error = 390.1589632034302
Time execution (tranning): 84.210712 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 376
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

176.85222229003907

num_try : 206 | val_loss = 176.85222229003907 | val acc = 6.513018608093262
val_error = -326.35650634765625 | val_abs_error = 326.35650634765625
Time execution (tranning): 29.175064 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 129
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

177.1572708129883

num_try : 34 | val_loss = 177.1572708129883 | val acc = 6.537300109863281
val_error = -469.5910930633545 | val_abs_error = 469.5910930633545
Time execution (tranning): 43.469470 seconds 
Time execution (load saved model): 0.001467 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

177.5126922607422

num_try : 238 | val_loss = 177.5126922607422 | val acc = 6.5055832862854
val_error = -292.2515392303467 | val_abs_error = 292.2515392303467
Time execution (tranning): 76.058651 seconds 
Time execution (load saved model): 0.001494 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

178.1805126953125

num_try : 90 | val_loss = 178.1805126953125 | val acc = 6.516768455505371
val_error = -350.9065866470337 | val_abs_error = 350.9065866470337
Time execution (tranning): 68.520572 seconds 
Time execution (load saved model): 0.001577 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

178.49865905761717

num_try : 66 | val_loss = 178.49865905761717 | val acc = 6.543544769287109
val_error = -364.7967338562012 | val_abs_error = 364.7967338562012
Time execution (tranning): 53.298658 seconds 
Time execution (load saved model): 0.001491 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

178.60792175292968

num_try : 427 | val_loss = 178.60792175292968 | val acc = 4.455066680908203
val_error = -190.88507890701294 | val_abs_error = 190.88507890701294
Time execution (tranning): 151.734647 seconds 
Time execution (load saved model): 0.001562 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 615
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

180.8650747680664

num_try : 190 | val_loss = 180.8650747680664 | val acc = 6.570207118988037
val_error = -419.1534996032715 | val_abs_error = 419.1534996032715
Time execution (tranning): 67.044444 seconds 
Time execution (load saved model): 0.001523 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

181.68670043945312

num_try : 142 | val_loss = 181.68670043945312 | val acc = 6.554703235626221
val_error = -418.0673122406006 | val_abs_error = 418.0673122406006
Time execution (tranning): 47.498549 seconds 
Time execution (load saved model): 0.001512 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

182.35269012451172

num_try : 18 | val_loss = 182.35269012451172 | val acc = 6.556299686431885
val_error = -338.01867961883545 | val_abs_error = 338.01867961883545
Time execution (tranning): 66.258271 seconds 
Time execution (load saved model): 0.001492 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

185.08138977050783

num_try : 118 | val_loss = 185.08138977050783 | val acc = 6.610833644866943
val_error = -402.4794101715088 | val_abs_error = 402.4794101715088
Time execution (tranning): 63.610573 seconds 
Time execution (load saved model): 0.001548 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

188.87696838378906

num_try : 94 | val_loss = 188.87696838378906 | val acc = 6.659317493438721
val_error = -484.419584274292 | val_abs_error = 484.419584274292
Time execution (tranning): 93.264590 seconds 
Time execution (load saved model): 0.001513 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

198.46343383789062

num_try : 46 | val_loss = 198.46343383789062 | val acc = 6.8379998207092285
val_error = -467.18759536743164 | val_abs_error = 467.18759536743164
Time execution (tranning): 64.556184 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

207.85491088867187

num_try : 22 | val_loss = 207.85491088867187 | val acc = 6.9944000244140625
val_error = -506.36258125305176 | val_abs_error = 506.36258125305176
Time execution (tranning): 59.995378 seconds 
Time execution (load saved model): 0.001516 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

214.19715362548828

num_try : 70 | val_loss = 214.19715362548828 | val acc = 7.105894088745117
val_error = -568.3026313781738 | val_abs_error = 568.3026313781738
Time execution (tranning): 42.674819 seconds 
Time execution (load saved model): 0.001475 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 0.5}
----------

252.795810546875

num_try : 475 | val_loss = 252.795810546875 | val acc = 5.503479480743408
val_error = -243.64967346191406 | val_abs_error = 243.64967346191406
Time execution (tranning): 103.730067 seconds 
Time execution (load saved model): 0.001558 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 418
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

256.81298400878904

num_try : 347 | val_loss = 256.81298400878904 | val acc = 5.475255966186523
val_error = -386.25690937042236 | val_abs_error = 386.25690937042236
Time execution (tranning): 65.764700 seconds 
Time execution (load saved model): 0.001598 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

266.8799151611328

num_try : 455 | val_loss = 266.8799151611328 | val acc = 5.68110990524292
val_error = -164.94754552841187 | val_abs_error = 164.94754552841187
Time execution (tranning): 146.691664 seconds 
Time execution (load saved model): 0.001543 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 596
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

279.3234765625

num_try : 343 | val_loss = 279.3234765625 | val acc = 5.776344299316406
val_error = -235.34276485443115 | val_abs_error = 235.34276485443115
Time execution (tranning): 52.693188 seconds 
Time execution (load saved model): 0.001519 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

279.58339538574216

num_try : 479 | val_loss = 279.58339538574216 | val acc = 5.820129871368408
val_error = -231.4316987991333 | val_abs_error = 231.4316987991333
Time execution (tranning): 96.702447 seconds 
Time execution (load saved model): 0.001549 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

279.77392150878904

num_try : 223 | val_loss = 279.77392150878904 | val acc = 5.742213726043701
val_error = -353.3613443374634 | val_abs_error = 353.3613443374634
Time execution (tranning): 62.577155 seconds 
Time execution (load saved model): 0.001518 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

280.7480792236328

num_try : 243 | val_loss = 280.7480792236328 | val acc = 5.779037952423096
val_error = -178.6124587059021 | val_abs_error = 178.6124587059021
Time execution (tranning): 71.456715 seconds 
Time execution (load saved model): 0.001546 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

281.02947509765625

num_try : 291 | val_loss = 281.02947509765625 | val acc = 5.7698869705200195
val_error = -177.2025227546692 | val_abs_error = 177.2025227546692
Time execution (tranning): 48.852238 seconds 
Time execution (load saved model): 0.001543 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

282.427255859375

num_try : 315 | val_loss = 282.427255859375 | val acc = 5.778816223144531
val_error = -144.23632621765137 | val_abs_error = 144.23632621765137
Time execution (tranning): 35.269231 seconds 
Time execution (load saved model): 0.001546 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 152
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

282.53206298828127

num_try : 367 | val_loss = 282.53206298828127 | val acc = 5.765645503997803
val_error = -289.0981435775757 | val_abs_error = 289.0981435775757
Time execution (tranning): 44.343462 seconds 
Time execution (load saved model): 0.001519 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

282.54200622558596

num_try : 363 | val_loss = 282.54200622558596 | val acc = 5.808269500732422
val_error = -139.0834927558899 | val_abs_error = 139.0834927558899
Time execution (tranning): 42.238648 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 179
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

284.46251220703124

num_try : 195 | val_loss = 284.46251220703124 | val acc = 5.800766944885254
val_error = -179.83063459396362 | val_abs_error = 179.83063459396362
Time execution (tranning): 49.122911 seconds 
Time execution (load saved model): 0.001509 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

285.68196960449217

num_try : 219 | val_loss = 285.68196960449217 | val acc = 5.84311056137085
val_error = -134.3645453453064 | val_abs_error = 134.3645453453064
Time execution (tranning): 41.570710 seconds 
Time execution (load saved model): 0.001498 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

286.2837689208984

num_try : 123 | val_loss = 286.2837689208984 | val acc = 5.874371528625488
val_error = -212.25051879882812 | val_abs_error = 212.25051879882812
Time execution (tranning): 44.586968 seconds 
Time execution (load saved model): 0.001501 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

286.5363037109375

num_try : 267 | val_loss = 286.5363037109375 | val acc = 5.878270626068115
val_error = -181.1811923980713 | val_abs_error = 181.1811923980713
Time execution (tranning): 36.866445 seconds 
Time execution (load saved model): 0.001573 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 156
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

286.55589416503904

num_try : 319 | val_loss = 286.55589416503904 | val acc = 5.8109211921691895
val_error = -270.1188802719116 | val_abs_error = 270.1188802719116
Time execution (tranning): 46.869891 seconds 
Time execution (load saved model): 0.001554 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

286.85533020019534

num_try : 199 | val_loss = 286.85533020019534 | val acc = 5.879973411560059
val_error = -293.95740032196045 | val_abs_error = 293.95740032196045
Time execution (tranning): 47.985543 seconds 
Time execution (load saved model): 0.001501 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

288.37065979003904

num_try : 403 | val_loss = 288.37065979003904 | val acc = 5.9198102951049805
val_error = -90.93284606933594 | val_abs_error = 90.93284606933594
Time execution (tranning): 105.452527 seconds 
Time execution (load saved model): 0.001546 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 412
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

289.22208923339844

num_try : 271 | val_loss = 289.22208923339844 | val acc = 5.91356086730957
val_error = -316.4968967437744 | val_abs_error = 316.4968967437744
Time execution (tranning): 55.810398 seconds 
Time execution (load saved model): 0.001497 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

289.4693255615234

num_try : 371 | val_loss = 289.4693255615234 | val acc = 5.889557838439941
val_error = -355.78410625457764 | val_abs_error = 355.78410625457764
Time execution (tranning): 63.992041 seconds 
Time execution (load saved model): 0.001525 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

289.87031921386716

num_try : 147 | val_loss = 289.87031921386716 | val acc = 5.909529209136963
val_error = -210.65945625305176 | val_abs_error = 210.65945625305176
Time execution (tranning): 43.114919 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

289.9058233642578

num_try : 295 | val_loss = 289.9058233642578 | val acc = 5.859959125518799
val_error = -201.83968544006348 | val_abs_error = 201.83968544006348
Time execution (tranning): 39.612245 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 163
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

289.9896765136719

num_try : 323 | val_loss = 289.9896765136719 | val acc = 5.916386604309082
val_error = -359.42797660827637 | val_abs_error = 359.42797660827637
Time execution (tranning): 70.394149 seconds 
Time execution (load saved model): 0.001510 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

290.0046630859375

num_try : 247 | val_loss = 290.0046630859375 | val acc = 5.9019389152526855
val_error = -271.13475799560547 | val_abs_error = 271.13475799560547
Time execution (tranning): 48.669563 seconds 
Time execution (load saved model): 0.001499 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

290.5024658203125

num_try : 227 | val_loss = 290.5024658203125 | val acc = 5.912783145904541
val_error = -463.01770210266113 | val_abs_error = 463.01770210266113
Time execution (tranning): 57.430221 seconds 
Time execution (load saved model): 0.001498 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

290.57042114257814

num_try : 75 | val_loss = 290.57042114257814 | val acc = 5.959639549255371
val_error = -237.76040077209473 | val_abs_error = 237.76040077209473
Time execution (tranning): 54.750437 seconds 
Time execution (load saved model): 0.001573 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

290.7175817871094

num_try : 151 | val_loss = 290.7175817871094 | val acc = 5.8186492919921875
val_error = -380.6406021118164 | val_abs_error = 380.6406021118164
Time execution (tranning): 67.346708 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

292.18119140625

num_try : 251 | val_loss = 292.18119140625 | val acc = 5.966012477874756
val_error = -454.5969009399414 | val_abs_error = 454.5969009399414
Time execution (tranning): 59.503760 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

292.30793395996096

num_try : 299 | val_loss = 292.30793395996096 | val acc = 5.918476581573486
val_error = -316.19343757629395 | val_abs_error = 316.19343757629395
Time execution (tranning): 52.882745 seconds 
Time execution (load saved model): 0.001530 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

292.3615313720703

num_try : 375 | val_loss = 292.3615313720703 | val acc = 5.987499237060547
val_error = -211.1919641494751 | val_abs_error = 211.1919641494751
Time execution (tranning): 100.947114 seconds 
Time execution (load saved model): 0.001586 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

292.61374755859373

num_try : 275 | val_loss = 292.61374755859373 | val acc = 5.961269378662109
val_error = -474.8405456542969 | val_abs_error = 474.8405456542969
Time execution (tranning): 53.191302 seconds 
Time execution (load saved model): 0.001543 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

293.36922546386717

num_try : 27 | val_loss = 293.36922546386717 | val acc = 5.948995113372803
val_error = -266.3929224014282 | val_abs_error = 266.3929224014282
Time execution (tranning): 50.795069 seconds 
Time execution (load saved model): 0.001486 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

293.43514343261717

num_try : 103 | val_loss = 293.43514343261717 | val acc = 5.97208833694458
val_error = -403.0076026916504 | val_abs_error = 403.0076026916504
Time execution (tranning): 49.108490 seconds 
Time execution (load saved model): 0.001939 seconds 
Time execution (use saved model): 0.000198 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

293.4462634277344

num_try : 171 | val_loss = 293.4462634277344 | val acc = 5.830902099609375
val_error = -225.50573348999023 | val_abs_error = 225.50573348999023
Time execution (tranning): 60.850253 seconds 
Time execution (load saved model): 0.001487 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

294.5874755859375

num_try : 127 | val_loss = 294.5874755859375 | val acc = 5.921728610992432
val_error = -393.88697147369385 | val_abs_error = 393.88697147369385
Time execution (tranning): 68.486146 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

294.6281591796875

num_try : 51 | val_loss = 294.6281591796875 | val acc = 5.979012489318848
val_error = -319.77453231811523 | val_abs_error = 319.77453231811523
Time execution (tranning): 48.154769 seconds 
Time execution (load saved model): 0.001473 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

295.7253192138672

num_try : 3 | val_loss = 295.7253192138672 | val acc = 6.011539936065674
val_error = -237.2241735458374 | val_abs_error = 237.2241735458374
Time execution (tranning): 55.519319 seconds 
Time execution (load saved model): 0.001471 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

296.71478393554685

num_try : 99 | val_loss = 296.71478393554685 | val acc = 5.939600467681885
val_error = -221.55001163482666 | val_abs_error = 221.55001163482666
Time execution (tranning): 44.639071 seconds 
Time execution (load saved model): 0.001506 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

297.34015075683595

num_try : 307 | val_loss = 297.34015075683595 | val acc = 6.0187788009643555
val_error = -187.1142864227295 | val_abs_error = 187.1142864227295
Time execution (tranning): 95.866340 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 407
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

297.77154296875

num_try : 55 | val_loss = 297.77154296875 | val acc = 6.045341491699219
val_error = -459.82632637023926 | val_abs_error = 459.82632637023926
Time execution (tranning): 80.660646 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

298.98847045898435

num_try : 203 | val_loss = 298.98847045898435 | val acc = 6.046027183532715
val_error = -459.50989723205566 | val_abs_error = 459.50989723205566
Time execution (tranning): 52.572147 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

299.70625

num_try : 175 | val_loss = 299.70625 | val acc = 6.062023162841797
val_error = -405.1875591278076 | val_abs_error = 405.1875591278076
Time execution (tranning): 47.998886 seconds 
Time execution (load saved model): 0.001488 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

300.79445495605466

num_try : 179 | val_loss = 300.79445495605466 | val acc = 6.067000865936279
val_error = -500.11348724365234 | val_abs_error = 500.11348724365234
Time execution (tranning): 67.061004 seconds 
Time execution (load saved model): 0.001481 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

301.1869775390625

num_try : 7 | val_loss = 301.1869775390625 | val acc = 6.026424884796143
val_error = -441.02768898010254 | val_abs_error = 441.02768898010254
Time execution (tranning): 55.249230 seconds 
Time execution (load saved model): 0.001462 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

301.20117126464845

num_try : 31 | val_loss = 301.20117126464845 | val acc = 5.999518394470215
val_error = -363.0016803741455 | val_abs_error = 363.0016803741455
Time execution (tranning): 66.630575 seconds 
Time execution (load saved model): 0.001527 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

302.4662243652344

num_try : 107 | val_loss = 302.4662243652344 | val acc = 6.067938327789307
val_error = -476.2187957763672 | val_abs_error = 476.2187957763672
Time execution (tranning): 50.676634 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

302.49442504882813

num_try : 79 | val_loss = 302.49442504882813 | val acc = 6.009293556213379
val_error = -396.64530754089355 | val_abs_error = 396.64530754089355
Time execution (tranning): 46.375136 seconds 
Time execution (load saved model): 0.001467 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

302.7008172607422

num_try : 331 | val_loss = 302.7008172607422 | val acc = 6.053131580352783
val_error = -203.73995304107666 | val_abs_error = 203.73995304107666
Time execution (tranning): 82.512012 seconds 
Time execution (load saved model): 0.001526 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

306.381337890625

num_try : 355 | val_loss = 306.381337890625 | val acc = 6.051034450531006
val_error = -176.91528797149658 | val_abs_error = 176.91528797149658
Time execution (tranning): 79.702866 seconds 
Time execution (load saved model): 0.001512 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

309.9171240234375

num_try : 155 | val_loss = 309.9171240234375 | val acc = 6.130929946899414
val_error = -451.5263080596924 | val_abs_error = 451.5263080596924
Time execution (tranning): 54.189783 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

310.9517425537109

num_try : 471 | val_loss = 310.9517425537109 | val acc = 6.184253692626953
val_error = -222.23238945007324 | val_abs_error = 222.23238945007324
Time execution (tranning): 73.401605 seconds 
Time execution (load saved model): 0.001551 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

313.9332562255859

num_try : 407 | val_loss = 313.9332562255859 | val acc = 6.185471057891846
val_error = -211.9445562362671 | val_abs_error = 211.9445562362671
Time execution (tranning): 99.577686 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 400
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

314.2568103027344

num_try : 131 | val_loss = 314.2568103027344 | val acc = 6.160727024078369
val_error = -432.3744773864746 | val_abs_error = 432.3744773864746
Time execution (tranning): 58.858341 seconds 
Time execution (load saved model): 0.001509 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

316.14672302246095

num_try : 379 | val_loss = 316.14672302246095 | val acc = 6.240781784057617
val_error = -213.08629512786865 | val_abs_error = 213.08629512786865
Time execution (tranning): 61.297745 seconds 
Time execution (load saved model): 0.001521 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

316.58333251953127

num_try : 327 | val_loss = 316.58333251953127 | val acc = 6.216609477996826
val_error = -253.08496952056885 | val_abs_error = 253.08496952056885
Time execution (tranning): 53.917202 seconds 
Time execution (load saved model): 0.001522 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

319.5211181640625

num_try : 311 | val_loss = 319.5211181640625 | val acc = 6.157631874084473
val_error = -223.4290599822998 | val_abs_error = 223.4290599822998
Time execution (tranning): 84.616933 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 364
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

323.68633728027345

num_try : 263 | val_loss = 323.68633728027345 | val acc = 6.22873067855835
val_error = -299.01912212371826 | val_abs_error = 299.01912212371826
Time execution (tranning): 80.654899 seconds 
Time execution (load saved model): 0.001523 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

323.8128997802734

num_try : 447 | val_loss = 323.8128997802734 | val acc = 6.23419713973999
val_error = -288.165283203125 | val_abs_error = 288.165283203125
Time execution (tranning): 59.347471 seconds 
Time execution (load saved model): 0.001627 seconds 
Time execution (use saved model): 0.000175 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

324.6374243164062

num_try : 279 | val_loss = 324.6374243164062 | val acc = 6.2802863121032715
val_error = -58.69895815849304 | val_abs_error = 58.69895815849304
Time execution (tranning): 54.615985 seconds 
Time execution (load saved model): 0.001540 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

325.8433917236328

num_try : 35 | val_loss = 325.8433917236328 | val acc = 6.356348514556885
val_error = -477.84857749938965 | val_abs_error = 477.84857749938965
Time execution (tranning): 66.671578 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 296
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

326.52171630859374

num_try : 63 | val_loss = 326.52171630859374 | val acc = 6.320798397064209
val_error = -92.95845627784729 | val_abs_error = 92.95845627784729
Time execution (tranning): 87.130542 seconds 
Time execution (load saved model): 0.001567 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

327.1904693603516

num_try : 115 | val_loss = 327.1904693603516 | val acc = 6.251944065093994
val_error = -344.9363946914673 | val_abs_error = 344.9363946914673
Time execution (tranning): 86.401747 seconds 
Time execution (load saved model): 0.001515 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 384
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

327.1949475097656

num_try : 135 | val_loss = 327.1949475097656 | val acc = 6.34352970123291
val_error = -205.0546407699585 | val_abs_error = 205.0546407699585
Time execution (tranning): 61.895209 seconds 
Time execution (load saved model): 0.001497 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

329.79631958007815

num_try : 59 | val_loss = 329.79631958007815 | val acc = 6.390884876251221
val_error = -481.6985607147217 | val_abs_error = 481.6985607147217
Time execution (tranning): 64.630785 seconds 
Time execution (load saved model): 0.001550 seconds 
Time execution (use saved model): 0.000171 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

329.8924621582031

num_try : 351 | val_loss = 329.8924621582031 | val acc = 6.354499816894531
val_error = -193.92998218536377 | val_abs_error = 193.92998218536377
Time execution (tranning): 44.283094 seconds 
Time execution (load saved model): 0.001529 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

330.71558837890626

num_try : 211 | val_loss = 330.71558837890626 | val acc = 6.337681293487549
val_error = -234.46671962738037 | val_abs_error = 234.46671962738037
Time execution (tranning): 64.312569 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

331.4848748779297

num_try : 359 | val_loss = 331.4848748779297 | val acc = 6.305436134338379
val_error = -233.82985591888428 | val_abs_error = 233.82985591888428
Time execution (tranning): 74.512587 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

332.21538635253904

num_try : 303 | val_loss = 332.21538635253904 | val acc = 6.363458156585693
val_error = -181.90022706985474 | val_abs_error = 181.90022706985474
Time execution (tranning): 55.076941 seconds 
Time execution (load saved model): 0.001547 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

332.45980163574217

num_try : 111 | val_loss = 332.45980163574217 | val acc = 6.3780388832092285
val_error = -151.81775093078613 | val_abs_error = 151.81775093078613
Time execution (tranning): 61.370759 seconds 
Time execution (load saved model): 0.001485 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

332.6661566162109

num_try : 83 | val_loss = 332.6661566162109 | val acc = 6.397406101226807
val_error = -466.06554985046387 | val_abs_error = 466.06554985046387
Time execution (tranning): 65.916534 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

333.0833660888672

num_try : 283 | val_loss = 333.0833660888672 | val acc = 6.383535385131836
val_error = -245.41313648223877 | val_abs_error = 245.41313648223877
Time execution (tranning): 47.573065 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

333.88414489746094

num_try : 207 | val_loss = 333.88414489746094 | val acc = 6.32111120223999
val_error = -165.3459072113037 | val_abs_error = 165.3459072113037
Time execution (tranning): 52.170532 seconds 
Time execution (load saved model): 0.001533 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

335.3847320556641

num_try : 67 | val_loss = 335.3847320556641 | val acc = 6.360194206237793
val_error = -389.9264335632324 | val_abs_error = 389.9264335632324
Time execution (tranning): 98.387490 seconds 
Time execution (load saved model): 0.001538 seconds 
Time execution (use saved model): 0.000170 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 436
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

337.2972692871094

num_try : 259 | val_loss = 337.2972692871094 | val acc = 6.4438934326171875
val_error = -227.64129638671875 | val_abs_error = 227.64129638671875
Time execution (tranning): 45.625740 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

337.30530700683596

num_try : 39 | val_loss = 337.30530700683596 | val acc = 6.392172336578369
val_error = -284.6667766571045 | val_abs_error = 284.6667766571045
Time execution (tranning): 80.136189 seconds 
Time execution (load saved model): 0.001470 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 368
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

337.7019519042969

num_try : 139 | val_loss = 337.7019519042969 | val acc = 6.403194427490234
val_error = -300.4364252090454 | val_abs_error = 300.4364252090454
Time execution (tranning): 78.430817 seconds 
Time execution (load saved model): 0.001483 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

339.54552001953124

num_try : 239 | val_loss = 339.54552001953124 | val acc = 6.414046287536621
val_error = -325.8516550064087 | val_abs_error = 325.8516550064087
Time execution (tranning): 86.908981 seconds 
Time execution (load saved model): 0.001500 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 382
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

339.75239501953126

num_try : 163 | val_loss = 339.75239501953126 | val acc = 6.429821014404297
val_error = -259.31570529937744 | val_abs_error = 259.31570529937744
Time execution (tranning): 65.092164 seconds 
Time execution (load saved model): 0.001527 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 282
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

341.0426544189453

num_try : 231 | val_loss = 341.0426544189453 | val acc = 6.4535722732543945
val_error = -175.10818243026733 | val_abs_error = 175.10818243026733
Time execution (tranning): 37.622371 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 167
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

341.29099365234373

num_try : 187 | val_loss = 341.29099365234373 | val acc = 6.464099407196045
val_error = -290.85021018981934 | val_abs_error = 290.85021018981934
Time execution (tranning): 50.473359 seconds 
Time execution (load saved model): 0.001497 seconds 
Time execution (use saved model): 0.000164 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

342.22254760742186

num_try : 87 | val_loss = 342.22254760742186 | val acc = 6.391274452209473
val_error = -193.0066704750061 | val_abs_error = 193.0066704750061
Time execution (tranning): 77.470303 seconds 
Time execution (load saved model): 0.001476 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 350
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

342.31566650390624

num_try : 335 | val_loss = 342.31566650390624 | val acc = 6.437650680541992
val_error = -261.99097633361816 | val_abs_error = 261.99097633361816
Time execution (tranning): 65.353127 seconds 
Time execution (load saved model): 0.001589 seconds 
Time execution (use saved model): 0.000173 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

342.33361572265625

num_try : 255 | val_loss = 342.33361572265625 | val acc = 6.491088390350342
val_error = -209.82346534729004 | val_abs_error = 209.82346534729004
Time execution (tranning): 40.866669 seconds 
Time execution (load saved model): 0.001504 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 180
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

343.88250427246095

num_try : 11 | val_loss = 343.88250427246095 | val acc = 6.637762069702148
val_error = -473.5176086425781 | val_abs_error = 473.5176086425781
Time execution (tranning): 66.513471 seconds 
Time execution (load saved model): 0.001465 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

345.15678955078124

num_try : 15 | val_loss = 345.15678955078124 | val acc = 6.476624011993408
val_error = -241.939377784729 | val_abs_error = 241.939377784729
Time execution (tranning): 69.480699 seconds 
Time execution (load saved model): 0.001508 seconds 
Time execution (use saved model): 0.000160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 321
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

345.4481390380859

num_try : 235 | val_loss = 345.4481390380859 | val acc = 6.535318851470947
val_error = -240.11168479919434 | val_abs_error = 240.11168479919434
Time execution (tranning): 48.877777 seconds 
Time execution (load saved model): 0.001566 seconds 
Time execution (use saved model): 0.000174 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

345.57526428222656

num_try : 43 | val_loss = 345.57526428222656 | val acc = 6.512588024139404
val_error = -324.74365234375 | val_abs_error = 324.74365234375
Time execution (tranning): 68.360132 seconds 
Time execution (load saved model): 0.001600 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

345.75506103515625

num_try : 159 | val_loss = 345.75506103515625 | val acc = 6.450561046600342
val_error = -222.38216400146484 | val_abs_error = 222.38216400146484
Time execution (tranning): 74.594914 seconds 
Time execution (load saved model): 0.001545 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

346.6746887207031

num_try : 431 | val_loss = 346.6746887207031 | val acc = 6.487184047698975
val_error = -158.45705270767212 | val_abs_error = 158.45705270767212
Time execution (tranning): 68.750365 seconds 
Time execution (load saved model): 0.001553 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[512],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 275
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

347.44636169433596

num_try : 215 | val_loss = 347.44636169433596 | val acc = 6.48560094833374
val_error = -355.92334270477295 | val_abs_error = 355.92334270477295
Time execution (tranning): 55.273106 seconds 
Time execution (load saved model): 0.001482 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

349.4827435302734

num_try : 383 | val_loss = 349.4827435302734 | val acc = 6.522116661071777
val_error = -259.25869941711426 | val_abs_error = 259.25869941711426
Time execution (tranning): 64.566010 seconds 
Time execution (load saved model): 0.001560 seconds 
Time execution (use saved model): 0.000169 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[256],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 275
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

349.9941864013672

num_try : 19 | val_loss = 349.9941864013672 | val acc = 6.512619972229004
val_error = -342.57524013519287 | val_abs_error = 342.57524013519287
Time execution (tranning): 83.753397 seconds 
Time execution (load saved model): 0.001473 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 381
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

350.8910626220703

num_try : 91 | val_loss = 350.8910626220703 | val acc = 6.533307075500488
val_error = -332.7542781829834 | val_abs_error = 332.7542781829834
Time execution (tranning): 72.304771 seconds 
Time execution (load saved model): 0.001518 seconds 
Time execution (use saved model): 0.000167 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

353.01555114746094

num_try : 287 | val_loss = 353.01555114746094 | val acc = 6.556026458740234
val_error = -356.52637481689453 | val_abs_error = 356.52637481689453
Time execution (tranning): 43.961563 seconds 
Time execution (load saved model): 0.001534 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[128],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

354.9442156982422

num_try : 119 | val_loss = 354.9442156982422 | val acc = 6.51804256439209
val_error = -397.08807468414307 | val_abs_error = 397.08807468414307
Time execution (tranning): 79.162104 seconds 
Time execution (load saved model): 0.001482 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 352
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

355.5462078857422

num_try : 191 | val_loss = 355.5462078857422 | val acc = 6.526453495025635
val_error = -403.1221389770508 | val_abs_error = 403.1221389770508
Time execution (tranning): 82.203543 seconds 
Time execution (load saved model): 0.001506 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 362
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

356.2836590576172

num_try : 167 | val_loss = 356.2836590576172 | val acc = 6.549012660980225
val_error = -402.0517826080322 | val_abs_error = 402.0517826080322
Time execution (tranning): 86.033173 seconds 
Time execution (load saved model): 0.001544 seconds 
Time execution (use saved model): 0.000163 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 378
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

360.9211602783203

num_try : 143 | val_loss = 360.9211602783203 | val acc = 6.558941841125488
val_error = -400.9136199951172 | val_abs_error = 400.9136199951172
Time execution (tranning): 51.480914 seconds 
Time execution (load saved model): 0.001513 seconds 
Time execution (use saved model): 0.000166 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

361.99150451660154

num_try : 183 | val_loss = 361.99150451660154 | val acc = 6.64171838760376
val_error = -228.84719371795654 | val_abs_error = 228.84719371795654
Time execution (tranning): 40.806175 seconds 
Time execution (load saved model): 0.001559 seconds 
Time execution (use saved model): 0.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[64],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True 

Num of epoch used : 181
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

379.3870739746094

num_try : 95 | val_loss = 379.3870739746094 | val acc = 6.73043966293335
val_error = -474.2528438568115 | val_abs_error = 474.2528438568115
Time execution (tranning): 69.843699 seconds 
Time execution (load saved model): 0.001490 seconds 
Time execution (use saved model): 0.000165 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

385.8295202636719

num_try : 23 | val_loss = 385.8295202636719 | val acc = 6.75316858291626
val_error = -492.76881217956543 | val_abs_error = 492.76881217956543
Time execution (tranning): 65.629037 seconds 
Time execution (load saved model): 0.001526 seconds 
Time execution (use saved model): 0.000168 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

390.63645751953123

num_try : 71 | val_loss = 390.63645751953123 | val acc = 6.79517126083374
val_error = -507.16209411621094 | val_abs_error = 507.16209411621094
Time execution (tranning): 66.620242 seconds 
Time execution (load saved model): 0.001473 seconds 
Time execution (use saved model): 0.000162 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

427.0853601074219

num_try : 47 | val_loss = 427.0853601074219 | val acc = 7.153035640716553
val_error = -575.2342700958252 | val_abs_error = 575.2342700958252
Time execution (tranning): 29.328684 seconds 
Time execution (load saved model): 0.001468 seconds 
Time execution (use saved model): 0.000161 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- batch_size=64,
- n_nodes=[32],
- activations=[GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.5, 
- use_batch_norm=True 

Num of epoch used : 128
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.5, 'factor': 1.0}
----------

5.736386983699049e-06

num_try : 224 | val_loss = 5.736386983699049e-06 | val acc = 0.0016404730267822742
Time execution (tranning): 134.350151 seconds 
Time execution (load saved model): 0.003291 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.751398211941705e-06

num_try : 168 | val_loss = 5.751398211941705e-06 | val acc = 0.0018160517793148756
Time execution (tranning): 76.446367 seconds 
Time execution (load saved model): 0.002640 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.7820617348625095e-06

num_try : 272 | val_loss = 5.7820617348625095e-06 | val acc = 0.001684724586084485
Time execution (tranning): 128.430033 seconds 
Time execution (load saved model): 0.005850 seconds 
Time execution (use saved model): 0.000442 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.862496282134089e-06

num_try : 194 | val_loss = 5.862496282134089e-06 | val acc = 0.0018617426976561546
Time execution (tranning): 95.194601 seconds 
Time execution (load saved model): 0.003290 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.890250195079716e-06

num_try : 206 | val_loss = 5.890250195079716e-06 | val acc = 0.0018166308291256428
Time execution (tranning): 83.983283 seconds 
Time execution (load saved model): 0.003304 seconds 
Time execution (use saved model): 0.000322 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.07476490586123e-06

num_try : 130 | val_loss = 6.07476490586123e-06 | val acc = 0.0018849578918889165
Time execution (tranning): 111.466210 seconds 
Time execution (load saved model): 0.002444 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 382
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.140064679129864e-06

num_try : 191 | val_loss = 6.140064679129864e-06 | val acc = 0.0018389290198683739
Time execution (tranning): 116.773783 seconds 
Time execution (load saved model): 0.002588 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 370
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.2195648388296834e-06

num_try : 235 | val_loss = 6.2195648388296834e-06 | val acc = 0.001814022776670754
Time execution (tranning): 107.258964 seconds 
Time execution (load saved model): 0.003376 seconds 
Time execution (use saved model): 0.000325 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

6.372008501784876e-06

num_try : 213 | val_loss = 6.372008501784876e-06 | val acc = 0.001767099485732615
Time execution (tranning): 97.603602 seconds 
Time execution (load saved model): 0.003567 seconds 
Time execution (use saved model): 0.000297 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.413278588297544e-06

num_try : 200 | val_loss = 6.413278588297544e-06 | val acc = 0.001868814812041819
Time execution (tranning): 89.754171 seconds 
Time execution (load saved model): 0.003263 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.53675651847152e-06

num_try : 212 | val_loss = 6.53675651847152e-06 | val acc = 0.001819082535803318
Time execution (tranning): 69.472756 seconds 
Time execution (load saved model): 0.003235 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.665736100330832e-06

num_try : 176 | val_loss = 6.665736100330832e-06 | val acc = 0.0019052497809752822
Time execution (tranning): 118.249208 seconds 
Time execution (load saved model): 0.002825 seconds 
Time execution (use saved model): 0.000297 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 368
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.67703075123427e-06

num_try : 236 | val_loss = 6.67703075123427e-06 | val acc = 0.0018844233127310872
Time execution (tranning): 91.598634 seconds 
Time execution (load saved model): 0.003353 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.78646584674425e-06

num_try : 135 | val_loss = 6.78646584674425e-06 | val acc = 0.0019277564715594053
Time execution (tranning): 91.704701 seconds 
Time execution (load saved model): 0.002532 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.797114147047978e-06

num_try : 148 | val_loss = 6.797114147047978e-06 | val acc = 0.0020137426909059286
Time execution (tranning): 76.482486 seconds 
Time execution (load saved model): 0.002635 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.8368151733011475e-06

num_try : 195 | val_loss = 6.8368151733011475e-06 | val acc = 0.001980374101549387
Time execution (tranning): 78.776922 seconds 
Time execution (load saved model): 0.003236 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.839194065832999e-06

num_try : 218 | val_loss = 6.839194065832999e-06 | val acc = 0.0020357391331344843
Time execution (tranning): 107.007627 seconds 
Time execution (load saved model): 0.003265 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.885164120831177e-06

num_try : 190 | val_loss = 6.885164120831177e-06 | val acc = 0.001974987331777811
Time execution (tranning): 88.339258 seconds 
Time execution (load saved model): 0.002581 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.896056211189716e-06

num_try : 99 | val_loss = 6.896056211189716e-06 | val acc = 0.0020488055888563395
Time execution (tranning): 70.560268 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.898792689753464e-06

num_try : 226 | val_loss = 6.898792689753464e-06 | val acc = 0.00193316163495183
Time execution (tranning): 119.371386 seconds 
Time execution (load saved model): 0.003242 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 329
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.922742722963449e-06

num_try : 186 | val_loss = 6.922742722963449e-06 | val acc = 0.001990758115425706
Time execution (tranning): 128.486301 seconds 
Time execution (load saved model): 0.002588 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 421
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.970871181692928e-06

num_try : 154 | val_loss = 6.970871181692928e-06 | val acc = 0.001964232884347439
Time execution (tranning): 74.364293 seconds 
Time execution (load saved model): 0.002637 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.010225717749563e-06

num_try : 221 | val_loss = 7.010225717749563e-06 | val acc = 0.00198094779625535
Time execution (tranning): 94.127794 seconds 
Time execution (load saved model): 0.003455 seconds 
Time execution (use saved model): 0.000329 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.054043235257268e-06

num_try : 266 | val_loss = 7.054043235257268e-06 | val acc = 0.002061906736344099
Time execution (tranning): 162.797936 seconds 
Time execution (load saved model): 0.005890 seconds 
Time execution (use saved model): 0.000449 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.074146706145256e-06

num_try : 127 | val_loss = 7.074146706145256e-06 | val acc = 0.002051279181614518
Time execution (tranning): 96.279791 seconds 
Time execution (load saved model): 0.002390 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 333
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.094297243384062e-06

num_try : 111 | val_loss = 7.094297243384062e-06 | val acc = 0.0020640799775719643
Time execution (tranning): 73.701554 seconds 
Time execution (load saved model): 0.002559 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.094883758327342e-06

num_try : 172 | val_loss = 7.094883758327342e-06 | val acc = 0.0020307982340455055
Time execution (tranning): 64.727907 seconds 
Time execution (load saved model): 0.002947 seconds 
Time execution (use saved model): 0.000300 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.115207608876517e-06

num_try : 210 | val_loss = 7.115207608876517e-06 | val acc = 0.0019494168227538466
Time execution (tranning): 82.270327 seconds 
Time execution (load saved model): 0.003311 seconds 
Time execution (use saved model): 0.000320 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.120795944501879e-06

num_try : 150 | val_loss = 7.120795944501879e-06 | val acc = 0.0019311760552227497
Time execution (tranning): 113.262607 seconds 
Time execution (load saved model): 0.002636 seconds 
Time execution (use saved model): 0.000277 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 371
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.1255508464673765e-06

num_try : 225 | val_loss = 7.1255508464673765e-06 | val acc = 0.0018474576063454151
Time execution (tranning): 118.753204 seconds 
Time execution (load saved model): 0.003352 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 325
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.135487276173081e-06

num_try : 220 | val_loss = 7.135487276173081e-06 | val acc = 0.001881367526948452
Time execution (tranning): 150.952420 seconds 
Time execution (load saved model): 0.003301 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 413
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.1480059250461635e-06

num_try : 153 | val_loss = 7.1480059250461635e-06 | val acc = 0.002042758511379361
Time execution (tranning): 106.369219 seconds 
Time execution (load saved model): 0.002614 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.162189422160736e-06

num_try : 120 | val_loss = 7.162189422160736e-06 | val acc = 0.0020367377437651157
Time execution (tranning): 84.850861 seconds 
Time execution (load saved model): 0.002411 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 296
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.164165563153801e-06

num_try : 182 | val_loss = 7.164165563153801e-06 | val acc = 0.0020759792532771826
Time execution (tranning): 66.496701 seconds 
Time execution (load saved model): 0.002639 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.201889084171853e-06

num_try : 137 | val_loss = 7.201889084171853e-06 | val acc = 0.0020869553554803133
Time execution (tranning): 76.762855 seconds 
Time execution (load saved model): 0.002394 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 263
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.221491050586337e-06

num_try : 185 | val_loss = 7.221491050586337e-06 | val acc = 0.0020748323295265436
Time execution (tranning): 94.358917 seconds 
Time execution (load saved model): 0.002621 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.239420692712884e-06

num_try : 171 | val_loss = 7.239420692712884e-06 | val acc = 0.002148727886378765
Time execution (tranning): 104.486427 seconds 
Time execution (load saved model): 0.002575 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.2651860864425544e-06

num_try : 140 | val_loss = 7.2651860864425544e-06 | val acc = 0.0020892168395221233
Time execution (tranning): 94.397471 seconds 
Time execution (load saved model): 0.002530 seconds 
Time execution (use saved model): 0.000273 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.281629614226403e-06

num_try : 222 | val_loss = 7.281629614226403e-06 | val acc = 0.0019092620350420475
Time execution (tranning): 73.773872 seconds 
Time execution (load saved model): 0.003373 seconds 
Time execution (use saved model): 0.000322 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.30955284780066e-06

num_try : 279 | val_loss = 7.30955284780066e-06 | val acc = 0.002154695335775614
Time execution (tranning): 164.510741 seconds 
Time execution (load saved model): 0.005857 seconds 
Time execution (use saved model): 0.000446 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 322
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.3542703648854515e-06

num_try : 175 | val_loss = 7.3542703648854515e-06 | val acc = 0.0019883173517882824
Time execution (tranning): 76.147058 seconds 
Time execution (load saved model): 0.002699 seconds 
Time execution (use saved model): 0.000282 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.363694458035752e-06

num_try : 160 | val_loss = 7.363694458035752e-06 | val acc = 0.0021055310498923063
Time execution (tranning): 87.084576 seconds 
Time execution (load saved model): 0.002662 seconds 
Time execution (use saved model): 0.000277 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 278
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.368787546511157e-06

num_try : 183 | val_loss = 7.368787546511157e-06 | val acc = 0.0020907914731651545
Time execution (tranning): 70.184194 seconds 
Time execution (load saved model): 0.002652 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.3725787024159215e-06

num_try : 173 | val_loss = 7.3725787024159215e-06 | val acc = 0.0021226319950073957
Time execution (tranning): 69.654607 seconds 
Time execution (load saved model): 0.002683 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.389699612758705e-06

num_try : 157 | val_loss = 7.389699612758705e-06 | val acc = 0.0020908562000840902
Time execution (tranning): 70.632831 seconds 
Time execution (load saved model): 0.002593 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.398277330139536e-06

num_try : 242 | val_loss = 7.398277330139536e-06 | val acc = 0.002062152838334441
Time execution (tranning): 131.476324 seconds 
Time execution (load saved model): 0.007269 seconds 
Time execution (use saved model): 0.000445 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.4260866676922885e-06

num_try : 165 | val_loss = 7.4260866676922885e-06 | val acc = 0.0019262793939560652
Time execution (tranning): 83.452178 seconds 
Time execution (load saved model): 0.002609 seconds 
Time execution (use saved model): 0.000273 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.4648204099503344e-06

num_try : 244 | val_loss = 7.4648204099503344e-06 | val acc = 0.002109339227899909
Time execution (tranning): 119.251298 seconds 
Time execution (load saved model): 0.006255 seconds 
Time execution (use saved model): 0.000460 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.469094662155839e-06

num_try : 178 | val_loss = 7.469094662155839e-06 | val acc = 0.0020469659939408302
Time execution (tranning): 87.632378 seconds 
Time execution (load saved model): 0.002584 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.4729779225890526e-06

num_try : 196 | val_loss = 7.4729779225890526e-06 | val acc = 0.0020581528078764677
Time execution (tranning): 95.651808 seconds 
Time execution (load saved model): 0.003691 seconds 
Time execution (use saved model): 0.000314 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.516214100178331e-06

num_try : 152 | val_loss = 7.516214100178331e-06 | val acc = 0.0019273892976343632
Time execution (tranning): 111.338518 seconds 
Time execution (load saved model): 0.002563 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.548091980424943e-06

num_try : 167 | val_loss = 7.548091980424943e-06 | val acc = 0.0019391742534935474
Time execution (tranning): 101.681018 seconds 
Time execution (load saved model): 0.002621 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.574273477075621e-06

num_try : 162 | val_loss = 7.574273477075621e-06 | val acc = 0.0020126209128648043
Time execution (tranning): 91.400656 seconds 
Time execution (load saved model): 0.002591 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.592183801534702e-06

num_try : 179 | val_loss = 7.592183801534702e-06 | val acc = 0.0021170279942452908
Time execution (tranning): 91.787287 seconds 
Time execution (load saved model): 0.002583 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.6044712386647005e-06

num_try : 139 | val_loss = 7.6044712386647005e-06 | val acc = 0.002157833194360137
Time execution (tranning): 101.964028 seconds 
Time execution (load saved model): 0.002418 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 356
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.645145851711277e-06

num_try : 233 | val_loss = 7.645145851711277e-06 | val acc = 0.0019460542825981975
Time execution (tranning): 143.288737 seconds 
Time execution (load saved model): 0.003250 seconds 
Time execution (use saved model): 0.000292 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 392
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.652675831195666e-06

num_try : 189 | val_loss = 7.652675831195666e-06 | val acc = 0.001977582462131977
Time execution (tranning): 71.348581 seconds 
Time execution (load saved model): 0.002739 seconds 
Time execution (use saved model): 0.000287 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.664391168873409e-06

num_try : 254 | val_loss = 7.664391168873409e-06 | val acc = 0.00213435641489923
Time execution (tranning): 120.983008 seconds 
Time execution (load saved model): 0.005824 seconds 
Time execution (use saved model): 0.000445 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.66782802202215e-06

num_try : 207 | val_loss = 7.66782802202215e-06 | val acc = 0.0022778206039220095
Time execution (tranning): 86.770589 seconds 
Time execution (load saved model): 0.003295 seconds 
Time execution (use saved model): 0.000322 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.697797873333911e-06

num_try : 102 | val_loss = 7.697797873333911e-06 | val acc = 0.002033136785030365
Time execution (tranning): 103.899018 seconds 
Time execution (load saved model): 0.002407 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 363
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.708076836934196e-06

num_try : 243 | val_loss = 7.708076836934196e-06 | val acc = 0.0022308798506855965
Time execution (tranning): 145.833897 seconds 
Time execution (load saved model): 0.006383 seconds 
Time execution (use saved model): 0.000447 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.725300838501425e-06

num_try : 164 | val_loss = 7.725300838501425e-06 | val acc = 0.0020310867112129927
Time execution (tranning): 94.888021 seconds 
Time execution (load saved model): 0.002582 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.831754464859841e-06

num_try : 98 | val_loss = 7.831754464859841e-06 | val acc = 0.002191318664699793
Time execution (tranning): 65.809301 seconds 
Time execution (load saved model): 0.002447 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.832141618564491e-06

num_try : 228 | val_loss = 7.832141618564491e-06 | val acc = 0.002218003151938319
Time execution (tranning): 79.262774 seconds 
Time execution (load saved model): 0.003352 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.838167803129182e-06

num_try : 155 | val_loss = 7.838167803129182e-06 | val acc = 0.0020098909735679626
Time execution (tranning): 99.629686 seconds 
Time execution (load saved model): 0.002891 seconds 
Time execution (use saved model): 0.000286 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.864696399337845e-06

num_try : 114 | val_loss = 7.864696399337845e-06 | val acc = 0.0022168683353811502
Time execution (tranning): 77.974794 seconds 
Time execution (load saved model): 0.002410 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.87603798926284e-06

num_try : 174 | val_loss = 7.87603798926284e-06 | val acc = 0.0020994392689317465
Time execution (tranning): 131.036533 seconds 
Time execution (load saved model): 0.002597 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 426
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.903565783635714e-06

num_try : 147 | val_loss = 7.903565783635714e-06 | val acc = 0.0021214785519987345
Time execution (tranning): 74.732577 seconds 
Time execution (load saved model): 0.002678 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.926247308205348e-06

num_try : 100 | val_loss = 7.926247308205348e-06 | val acc = 0.0022170082665979862
Time execution (tranning): 82.034685 seconds 
Time execution (load saved model): 0.002389 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.959830873005557e-06

num_try : 271 | val_loss = 7.959830873005557e-06 | val acc = 0.0018651426071301103
Time execution (tranning): 201.031587 seconds 
Time execution (load saved model): 0.006003 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 416
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.97332913862192e-06

num_try : 101 | val_loss = 7.97332913862192e-06 | val acc = 0.0022565769031643867
Time execution (tranning): 71.279331 seconds 
Time execution (load saved model): 0.002420 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.98187264081207e-06

num_try : 276 | val_loss = 7.98187264081207e-06 | val acc = 0.0022336365655064583
Time execution (tranning): 97.602234 seconds 
Time execution (load saved model): 0.005989 seconds 
Time execution (use saved model): 0.000446 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 202
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.987370599948917e-06

num_try : 156 | val_loss = 7.987370599948917e-06 | val acc = 0.0020970359910279512
Time execution (tranning): 76.872740 seconds 
Time execution (load saved model): 0.002617 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 249
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.030874505493557e-06

num_try : 170 | val_loss = 8.030874505493557e-06 | val acc = 0.002175259171053767
Time execution (tranning): 76.631361 seconds 
Time execution (load saved model): 0.002579 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.04079907538835e-06

num_try : 124 | val_loss = 8.04079907538835e-06 | val acc = 0.0021734926849603653
Time execution (tranning): 70.243903 seconds 
Time execution (load saved model): 0.002396 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.044362548389472e-06

num_try : 122 | val_loss = 8.044362548389472e-06 | val acc = 0.0022400247398763895
Time execution (tranning): 48.235292 seconds 
Time execution (load saved model): 0.002429 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 164
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.06339464361372e-06

num_try : 169 | val_loss = 8.06339464361372e-06 | val acc = 0.0021708919666707516
Time execution (tranning): 94.399828 seconds 
Time execution (load saved model): 0.002629 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.066364653132041e-06

num_try : 205 | val_loss = 8.066364653132041e-06 | val acc = 0.002247756812721491
Time execution (tranning): 95.642605 seconds 
Time execution (load saved model): 0.003307 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 263
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.082996509983787e-06

num_try : 255 | val_loss = 8.082996509983787e-06 | val acc = 0.002275673672556877
Time execution (tranning): 115.838015 seconds 
Time execution (load saved model): 0.006015 seconds 
Time execution (use saved model): 0.000450 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.10305763479846e-06

num_try : 188 | val_loss = 8.10305763479846e-06 | val acc = 0.0020474924240261316
Time execution (tranning): 68.200111 seconds 
Time execution (load saved model): 0.002593 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.112132318274235e-06

num_try : 177 | val_loss = 8.112132318274235e-06 | val acc = 0.002018256112933159
Time execution (tranning): 102.630913 seconds 
Time execution (load saved model): 0.002569 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 328
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.113808135021828e-06

num_try : 103 | val_loss = 8.113808135021828e-06 | val acc = 0.002126061823219061
Time execution (tranning): 75.532969 seconds 
Time execution (load saved model): 0.002366 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.15582016002736e-06

num_try : 117 | val_loss = 8.15582016002736e-06 | val acc = 0.002149044768884778
Time execution (tranning): 102.002718 seconds 
Time execution (load saved model): 0.002444 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 342
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.21374480437953e-06

num_try : 286 | val_loss = 8.21374480437953e-06 | val acc = 0.001924413605593145
Time execution (tranning): 244.589808 seconds 
Time execution (load saved model): 0.006098 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 497
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.217119257096783e-06

num_try : 187 | val_loss = 8.217119257096783e-06 | val acc = 0.0020377447362989187
Time execution (tranning): 74.158427 seconds 
Time execution (load saved model): 0.002587 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.232773670897587e-06

num_try : 247 | val_loss = 8.232773670897587e-06 | val acc = 0.001954285427927971
Time execution (tranning): 215.934035 seconds 
Time execution (load saved model): 0.006091 seconds 
Time execution (use saved model): 0.000448 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 430
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.242172007157934e-06

num_try : 112 | val_loss = 8.242172007157934e-06 | val acc = 0.0022522176150232553
Time execution (tranning): 75.782699 seconds 
Time execution (load saved model): 0.002385 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.333335727002122e-06

num_try : 275 | val_loss = 8.333335727002122e-06 | val acc = 0.0019441531039774418
Time execution (tranning): 223.791543 seconds 
Time execution (load saved model): 0.005957 seconds 
Time execution (use saved model): 0.000449 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 437
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.363957831534208e-06

num_try : 229 | val_loss = 8.363957831534208e-06 | val acc = 0.0022587210405617952
Time execution (tranning): 83.772206 seconds 
Time execution (load saved model): 0.003264 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.403266110690311e-06

num_try : 138 | val_loss = 8.403266110690311e-06 | val acc = 0.002124886028468609
Time execution (tranning): 76.743577 seconds 
Time execution (load saved model): 0.002449 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.439991979685147e-06

num_try : 151 | val_loss = 8.439991979685147e-06 | val acc = 0.0020378921180963516
Time execution (tranning): 96.348084 seconds 
Time execution (load saved model): 0.002558 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.466863364446909e-06

num_try : 118 | val_loss = 8.466863364446909e-06 | val acc = 0.002210762118920684
Time execution (tranning): 89.284333 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 306
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.483779611196951e-06

num_try : 158 | val_loss = 8.483779611196951e-06 | val acc = 0.0021933806128799915
Time execution (tranning): 69.645938 seconds 
Time execution (load saved model): 0.002617 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.483827023155755e-06

num_try : 134 | val_loss = 8.483827023155755e-06 | val acc = 0.002304496243596077
Time execution (tranning): 90.437490 seconds 
Time execution (load saved model): 0.002440 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.490031095789164e-06

num_try : 149 | val_loss = 8.490031095789164e-06 | val acc = 0.002090464113280177
Time execution (tranning): 83.960732 seconds 
Time execution (load saved model): 0.002680 seconds 
Time execution (use saved model): 0.000278 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.497564849676564e-06

num_try : 278 | val_loss = 8.497564849676564e-06 | val acc = 0.0023427517153322697
Time execution (tranning): 108.472208 seconds 
Time execution (load saved model): 0.005828 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.50874727802875e-06

num_try : 219 | val_loss = 8.50874727802875e-06 | val acc = 0.0022281701676547527
Time execution (tranning): 88.569418 seconds 
Time execution (load saved model): 0.003576 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.524255390511826e-06

num_try : 180 | val_loss = 8.524255390511826e-06 | val acc = 0.002230271929875016
Time execution (tranning): 89.029085 seconds 
Time execution (load saved model): 0.002661 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 288
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.53206195642997e-06

num_try : 231 | val_loss = 8.53206195642997e-06 | val acc = 0.002153606154024601
Time execution (tranning): 67.108834 seconds 
Time execution (load saved model): 0.003303 seconds 
Time execution (use saved model): 0.000314 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.544286256437772e-06

num_try : 145 | val_loss = 8.544286256437772e-06 | val acc = 0.002167582279071212
Time execution (tranning): 74.355650 seconds 
Time execution (load saved model): 0.002607 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.563371866330271e-06

num_try : 142 | val_loss = 8.563371866330271e-06 | val acc = 0.0023000622168183327
Time execution (tranning): 89.099756 seconds 
Time execution (load saved model): 0.002549 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.616716568212724e-06

num_try : 161 | val_loss = 8.616716568212724e-06 | val acc = 0.0022536739706993103
Time execution (tranning): 63.349184 seconds 
Time execution (load saved model): 0.002798 seconds 
Time execution (use saved model): 0.000292 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.618251868028893e-06

num_try : 115 | val_loss = 8.618251868028893e-06 | val acc = 0.0022288791369646788
Time execution (tranning): 78.516713 seconds 
Time execution (load saved model): 0.002387 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.64227606143686e-06

num_try : 285 | val_loss = 8.64227606143686e-06 | val acc = 0.0019750145729631186
Time execution (tranning): 197.839909 seconds 
Time execution (load saved model): 0.007315 seconds 
Time execution (use saved model): 0.000450 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.677606138007831e-06

num_try : 159 | val_loss = 8.677606138007831e-06 | val acc = 0.0021637878380715847
Time execution (tranning): 80.699413 seconds 
Time execution (load saved model): 0.002618 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.726305313757621e-06

num_try : 131 | val_loss = 8.726305313757621e-06 | val acc = 0.002281775465235114
Time execution (tranning): 101.137138 seconds 
Time execution (load saved model): 0.002391 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 338
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.801298536127433e-06

num_try : 144 | val_loss = 8.801298536127433e-06 | val acc = 0.0022338619455695152
Time execution (tranning): 99.185963 seconds 
Time execution (load saved model): 0.002693 seconds 
Time execution (use saved model): 0.000277 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 319
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.832491430439404e-06

num_try : 292 | val_loss = 8.832491430439404e-06 | val acc = 0.0021727513521909714
Time execution (tranning): 591.869522 seconds 
Time execution (load saved model): 0.016739 seconds 
Time execution (use saved model): 0.001060 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.864479132171255e-06

num_try : 123 | val_loss = 8.864479132171255e-06 | val acc = 0.0023513175547122955
Time execution (tranning): 65.255657 seconds 
Time execution (load saved model): 0.002433 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.87483702172176e-06

num_try : 126 | val_loss = 8.87483702172176e-06 | val acc = 0.002417056355625391
Time execution (tranning): 86.365378 seconds 
Time execution (load saved model): 0.002421 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.928986198952771e-06

num_try : 184 | val_loss = 8.928986198952771e-06 | val acc = 0.002343780593946576
Time execution (tranning): 91.405107 seconds 
Time execution (load saved model): 0.002577 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.947918795456644e-06

num_try : 108 | val_loss = 8.947918795456644e-06 | val acc = 0.0023020696826279163
Time execution (tranning): 53.372665 seconds 
Time execution (load saved model): 0.002412 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.98661865903705e-06

num_try : 146 | val_loss = 8.98661865903705e-06 | val acc = 0.0021463443990796804
Time execution (tranning): 65.656763 seconds 
Time execution (load saved model): 0.002653 seconds 
Time execution (use saved model): 0.000273 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.030045966937904e-06

num_try : 181 | val_loss = 9.030045966937904e-06 | val acc = 0.0022455777507275343
Time execution (tranning): 72.394184 seconds 
Time execution (load saved model): 0.002652 seconds 
Time execution (use saved model): 0.000277 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 236
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.083599525183673e-06

num_try : 106 | val_loss = 9.083599525183673e-06 | val acc = 0.0023370631970465183
Time execution (tranning): 84.676134 seconds 
Time execution (load saved model): 0.002471 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.137280330833165e-06

num_try : 249 | val_loss = 9.137280330833165e-06 | val acc = 0.002212332095950842
Time execution (tranning): 190.742480 seconds 
Time execution (load saved model): 0.005856 seconds 
Time execution (use saved model): 0.000446 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 389
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.20308411878068e-06

num_try : 110 | val_loss = 9.20308411878068e-06 | val acc = 0.002342688385397196
Time execution (tranning): 62.453276 seconds 
Time execution (load saved model): 0.002391 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.28579744140734e-06

num_try : 315 | val_loss = 9.28579744140734e-06 | val acc = 0.0023434082977473736
Time execution (tranning): 464.410899 seconds 
Time execution (load saved model): 0.016650 seconds 
Time execution (use saved model): 0.001088 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.313585069321562e-06

num_try : 128 | val_loss = 9.313585069321562e-06 | val acc = 0.0023665702901780605
Time execution (tranning): 84.583367 seconds 
Time execution (load saved model): 0.002412 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 290
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.323077283625026e-06

num_try : 116 | val_loss = 9.323077283625026e-06 | val acc = 0.0023024315014481544
Time execution (tranning): 67.650779 seconds 
Time execution (load saved model): 0.002398 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.344405998490402e-06

num_try : 97 | val_loss = 9.344405998490402e-06 | val acc = 0.0023741351906210184
Time execution (tranning): 61.797437 seconds 
Time execution (load saved model): 0.002403 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 217
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.350298469144037e-06

num_try : 141 | val_loss = 9.350298469144037e-06 | val acc = 0.002443356905132532
Time execution (tranning): 92.658428 seconds 
Time execution (load saved model): 0.002452 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.356083664897596e-06

num_try : 269 | val_loss = 9.356083664897596e-06 | val acc = 0.0021945000626146793
Time execution (tranning): 146.862601 seconds 
Time execution (load saved model): 0.005863 seconds 
Time execution (use saved model): 0.000438 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.388477828906615e-06

num_try : 133 | val_loss = 9.388477828906615e-06 | val acc = 0.0024170204997062683
Time execution (tranning): 74.226616 seconds 
Time execution (load saved model): 0.002477 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.407785728399177e-06

num_try : 232 | val_loss = 9.407785728399177e-06 | val acc = 0.0021344332490116358
Time execution (tranning): 124.877224 seconds 
Time execution (load saved model): 0.003289 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.425635307707125e-06

num_try : 125 | val_loss = 9.425635307707125e-06 | val acc = 0.0022547610569745302
Time execution (tranning): 73.208665 seconds 
Time execution (load saved model): 0.002402 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.448089995203191e-06

num_try : 261 | val_loss = 9.448089995203191e-06 | val acc = 0.002130009001120925
Time execution (tranning): 202.051778 seconds 
Time execution (load saved model): 0.005986 seconds 
Time execution (use saved model): 0.000446 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 407
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.455560857531963e-06

num_try : 88 | val_loss = 9.455560857531963e-06 | val acc = 0.002554102800786495
Time execution (tranning): 77.557241 seconds 
Time execution (load saved model): 0.002384 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.473775535298045e-06

num_try : 86 | val_loss = 9.473775535298045e-06 | val acc = 0.0025233507622033358
Time execution (tranning): 76.660667 seconds 
Time execution (load saved model): 0.002342 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.562610102875624e-06

num_try : 105 | val_loss = 9.562610102875624e-06 | val acc = 0.002265018178150058
Time execution (tranning): 84.686879 seconds 
Time execution (load saved model): 0.002511 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.60137205765932e-06

num_try : 241 | val_loss = 9.60137205765932e-06 | val acc = 0.00248659192584455
Time execution (tranning): 133.333262 seconds 
Time execution (load saved model): 0.005911 seconds 
Time execution (use saved model): 0.000449 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.611386958567892e-06

num_try : 296 | val_loss = 9.611386958567892e-06 | val acc = 0.0020720786415040493
Time execution (tranning): 519.313857 seconds 
Time execution (load saved model): 0.017275 seconds 
Time execution (use saved model): 0.001088 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.619607480999547e-06

num_try : 96 | val_loss = 9.619607480999547e-06 | val acc = 0.002381553640589118
Time execution (tranning): 61.593222 seconds 
Time execution (load saved model): 0.002468 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 214
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.62223803071538e-06

num_try : 129 | val_loss = 9.62223803071538e-06 | val acc = 0.0023295439314097166
Time execution (tranning): 102.874311 seconds 
Time execution (load saved model): 0.002398 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 353
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.629865280658123e-06

num_try : 234 | val_loss = 9.629865280658123e-06 | val acc = 0.0021397313103079796
Time execution (tranning): 150.125937 seconds 
Time execution (load saved model): 0.003267 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 420
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.68427109910408e-06

num_try : 51 | val_loss = 9.68427109910408e-06 | val acc = 0.0024768745061010122
Time execution (tranning): 83.164153 seconds 
Time execution (load saved model): 0.002457 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 289
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.739113884279505e-06

num_try : 121 | val_loss = 9.739113884279505e-06 | val acc = 0.0024331805761903524
Time execution (tranning): 70.411297 seconds 
Time execution (load saved model): 0.002700 seconds 
Time execution (use saved model): 0.000282 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.78216248768149e-06

num_try : 94 | val_loss = 9.78216248768149e-06 | val acc = 0.002523259725421667
Time execution (tranning): 85.883999 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.784000576473773e-06

num_try : 143 | val_loss = 9.784000576473773e-06 | val acc = 0.002386946463957429
Time execution (tranning): 61.233955 seconds 
Time execution (load saved model): 0.002379 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.796541908144718e-06

num_try : 268 | val_loss = 9.796541908144718e-06 | val acc = 0.0023753277491778135
Time execution (tranning): 157.357042 seconds 
Time execution (load saved model): 0.005845 seconds 
Time execution (use saved model): 0.000444 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.85523640338215e-06

num_try : 76 | val_loss = 9.85523640338215e-06 | val acc = 0.0025087175890803337
Time execution (tranning): 94.405027 seconds 
Time execution (load saved model): 0.002335 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 334
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.911572742566932e-06

num_try : 62 | val_loss = 9.911572742566932e-06 | val acc = 0.0026153242215514183
Time execution (tranning): 56.223897 seconds 
Time execution (load saved model): 0.002456 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.960073148249649e-06

num_try : 230 | val_loss = 9.960073148249649e-06 | val acc = 0.0022379783913493156
Time execution (tranning): 86.886537 seconds 
Time execution (load saved model): 0.003298 seconds 
Time execution (use saved model): 0.000314 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0023551012636745e-05

num_try : 333 | val_loss = 1.0023551012636745e-05 | val acc = 0.0020582289434969425
Time execution (tranning): 497.553187 seconds 
Time execution (load saved model): 0.022193 seconds 
Time execution (use saved model): 0.001091 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0030438606918325e-05

num_try : 214 | val_loss = 1.0030438606918325e-05 | val acc = 0.0022828220389783382
Time execution (tranning): 127.640595 seconds 
Time execution (load saved model): 0.003636 seconds 
Time execution (use saved model): 0.000314 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 351
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0140461918126674e-05

num_try : 107 | val_loss = 1.0140461918126674e-05 | val acc = 0.0023716003634035587
Time execution (tranning): 70.887279 seconds 
Time execution (load saved model): 0.002403 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0157343449463952e-05

num_try : 166 | val_loss = 1.0157343449463952e-05 | val acc = 0.00223723566159606
Time execution (tranning): 69.337952 seconds 
Time execution (load saved model): 0.002677 seconds 
Time execution (use saved model): 0.000278 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0200589040323393e-05

num_try : 73 | val_loss = 1.0200589040323393e-05 | val acc = 0.0026699965819716454
Time execution (tranning): 66.291924 seconds 
Time execution (load saved model): 0.002412 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0204396457993426e-05

num_try : 267 | val_loss = 1.0204396457993426e-05 | val acc = 0.0024131108075380325
Time execution (tranning): 125.926678 seconds 
Time execution (load saved model): 0.007233 seconds 
Time execution (use saved model): 0.000442 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0218143925158075e-05

num_try : 113 | val_loss = 1.0218143925158075e-05 | val acc = 0.0026402967050671577
Time execution (tranning): 111.178755 seconds 
Time execution (load saved model): 0.002445 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 384
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0284289237461052e-05

num_try : 109 | val_loss = 1.0284289237461052e-05 | val acc = 0.0024253532756119967
Time execution (tranning): 73.667165 seconds 
Time execution (load saved model): 0.002412 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 258
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0303964127160724e-05

num_try : 238 | val_loss = 1.0303964127160724e-05 | val acc = 0.002131350804120302
Time execution (tranning): 142.730512 seconds 
Time execution (load saved model): 0.003420 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 393
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0363552009948762e-05

num_try : 59 | val_loss = 1.0363552009948762e-05 | val acc = 0.0026102312840521336
Time execution (tranning): 107.326765 seconds 
Time execution (load saved model): 0.002405 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 380
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0389714034317877e-05

num_try : 313 | val_loss = 1.0389714034317877e-05 | val acc = 0.0023996734526008368
Time execution (tranning): 944.863096 seconds 
Time execution (load saved model): 0.016849 seconds 
Time execution (use saved model): 0.001124 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 572
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0395048120699357e-05

num_try : 71 | val_loss = 1.0395048120699357e-05 | val acc = 0.0026004782412201166
Time execution (tranning): 98.025044 seconds 
Time execution (load saved model): 0.002386 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 340
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0492795663594734e-05

num_try : 209 | val_loss = 1.0492795663594734e-05 | val acc = 0.0024126367643475533
Time execution (tranning): 76.701805 seconds 
Time execution (load saved model): 0.003310 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.050445456712623e-05

num_try : 65 | val_loss = 1.050445456712623e-05 | val acc = 0.002610734896734357
Time execution (tranning): 89.972655 seconds 
Time execution (load saved model): 0.002341 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0509448902666918e-05

num_try : 251 | val_loss = 1.0509448902666918e-05 | val acc = 0.0020464411936700344
Time execution (tranning): 161.559039 seconds 
Time execution (load saved model): 0.005951 seconds 
Time execution (use saved model): 0.000442 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0591976624709788e-05

num_try : 58 | val_loss = 1.0591976624709788e-05 | val acc = 0.002586057875305414
Time execution (tranning): 82.348779 seconds 
Time execution (load saved model): 0.002350 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 290
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.067409915776807e-05

num_try : 284 | val_loss = 1.067409915776807e-05 | val acc = 0.002280009910464287
Time execution (tranning): 117.078554 seconds 
Time execution (load saved model): 0.007152 seconds 
Time execution (use saved model): 0.000476 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0713424599089194e-05

num_try : 304 | val_loss = 1.0713424599089194e-05 | val acc = 0.00250179972499609
Time execution (tranning): 542.455275 seconds 
Time execution (load saved model): 0.022814 seconds 
Time execution (use saved model): 0.001073 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0730396352300887e-05

num_try : 303 | val_loss = 1.0730396352300887e-05 | val acc = 0.0025843442417681217
Time execution (tranning): 359.325162 seconds 
Time execution (load saved model): 0.023516 seconds 
Time execution (use saved model): 0.001118 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0734628776845057e-05

num_try : 52 | val_loss = 1.0734628776845057e-05 | val acc = 0.002589908894151449
Time execution (tranning): 99.656837 seconds 
Time execution (load saved model): 0.002350 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 349
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0750060191639932e-05

num_try : 132 | val_loss = 1.0750060191639932e-05 | val acc = 0.0024659563787281513
Time execution (tranning): 70.965702 seconds 
Time execution (load saved model): 0.002417 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 250
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0784546393551864e-05

num_try : 289 | val_loss = 1.0784546393551864e-05 | val acc = 0.002409696811810136
Time execution (tranning): 500.577744 seconds 
Time execution (load saved model): 0.016813 seconds 
Time execution (use saved model): 0.001061 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0803215900523355e-05

num_try : 314 | val_loss = 1.0803215900523355e-05 | val acc = 0.002762646647170186
Time execution (tranning): 354.375633 seconds 
Time execution (load saved model): 0.020666 seconds 
Time execution (use saved model): 0.001105 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.082359705833369e-05

num_try : 48 | val_loss = 1.082359705833369e-05 | val acc = 0.002681455807760358
Time execution (tranning): 79.982568 seconds 
Time execution (load saved model): 0.002349 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 290
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0843756153917639e-05

num_try : 66 | val_loss = 1.0843756153917639e-05 | val acc = 0.0026135998778045177
Time execution (tranning): 86.164809 seconds 
Time execution (load saved model): 0.002441 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.088283497665543e-05

num_try : 93 | val_loss = 1.088283497665543e-05 | val acc = 0.0026161433197557926
Time execution (tranning): 80.126539 seconds 
Time execution (load saved model): 0.002390 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0896874873651542e-05

num_try : 201 | val_loss = 1.0896874873651542e-05 | val acc = 0.002163581782951951
Time execution (tranning): 138.587961 seconds 
Time execution (load saved model): 0.003254 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 377
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0910165674431482e-05

num_try : 82 | val_loss = 1.0910165674431482e-05 | val acc = 0.002691476373001933
Time execution (tranning): 81.539819 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0910613382293376e-05

num_try : 198 | val_loss = 1.0910613382293376e-05 | val acc = 0.0022160056978464127
Time execution (tranning): 132.427797 seconds 
Time execution (load saved model): 0.003221 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 367
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0917853669525357e-05

num_try : 84 | val_loss = 1.0917853669525357e-05 | val acc = 0.002630893373861909
Time execution (tranning): 66.160103 seconds 
Time execution (load saved model): 0.002344 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.098431092032115e-05

num_try : 197 | val_loss = 1.098431092032115e-05 | val acc = 0.002473231637850404
Time execution (tranning): 106.987391 seconds 
Time execution (load saved model): 0.003468 seconds 
Time execution (use saved model): 0.000335 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1034395556634991e-05

num_try : 91 | val_loss = 1.1034395556634991e-05 | val acc = 0.0026251717936247587
Time execution (tranning): 94.229804 seconds 
Time execution (load saved model): 0.002355 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 339
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1074468657170656e-05

num_try : 74 | val_loss = 1.1074468657170656e-05 | val acc = 0.0026797084137797356
Time execution (tranning): 58.470489 seconds 
Time execution (load saved model): 0.002365 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1127241295980638e-05

num_try : 273 | val_loss = 1.1127241295980638e-05 | val acc = 0.002255769446492195
Time execution (tranning): 98.358074 seconds 
Time execution (load saved model): 0.007731 seconds 
Time execution (use saved model): 0.000460 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.1151501985295908e-05

num_try : 54 | val_loss = 1.1151501985295908e-05 | val acc = 0.002689049579203129
Time execution (tranning): 80.484313 seconds 
Time execution (load saved model): 0.002536 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.1155495303682984e-05

num_try : 248 | val_loss = 1.1155495303682984e-05 | val acc = 0.0023119552060961723
Time execution (tranning): 92.369980 seconds 
Time execution (load saved model): 0.006262 seconds 
Time execution (use saved model): 0.000470 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.125184139709745e-05

num_try : 283 | val_loss = 1.125184139709745e-05 | val acc = 0.002249333309009671
Time execution (tranning): 171.185198 seconds 
Time execution (load saved model): 0.007507 seconds 
Time execution (use saved model): 0.000450 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 350
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1275866800133372e-05

num_try : 320 | val_loss = 1.1275866800133372e-05 | val acc = 0.0023579508997499943
Time execution (tranning): 432.012672 seconds 
Time execution (load saved model): 0.017955 seconds 
Time execution (use saved model): 0.001110 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1295312888250919e-05

num_try : 239 | val_loss = 1.1295312888250919e-05 | val acc = 0.0023061640094965696
Time execution (tranning): 128.404558 seconds 
Time execution (load saved model): 0.003297 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.13539117774053e-05

num_try : 90 | val_loss = 1.13539117774053e-05 | val acc = 0.0026798259932547808
Time execution (tranning): 82.799297 seconds 
Time execution (load saved model): 0.002390 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 299
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.141342359915143e-05

num_try : 321 | val_loss = 1.141342359915143e-05 | val acc = 0.002303910208866
Time execution (tranning): 515.045964 seconds 
Time execution (load saved model): 0.016600 seconds 
Time execution (use saved model): 0.001056 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.1438273013482103e-05

num_try : 324 | val_loss = 1.1438273013482103e-05 | val acc = 0.0025983131490647793
Time execution (tranning): 378.378348 seconds 
Time execution (load saved model): 0.023318 seconds 
Time execution (use saved model): 0.001120 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.145696805906482e-05

num_try : 119 | val_loss = 1.145696805906482e-05 | val acc = 0.0024407918099313974
Time execution (tranning): 72.578905 seconds 
Time execution (load saved model): 0.002500 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1514805373735726e-05

num_try : 64 | val_loss = 1.1514805373735726e-05 | val acc = 0.002774818567559123
Time execution (tranning): 57.848131 seconds 
Time execution (load saved model): 0.002378 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1593267245189054e-05

num_try : 87 | val_loss = 1.1593267245189054e-05 | val acc = 0.00274973688647151
Time execution (tranning): 69.712293 seconds 
Time execution (load saved model): 0.002362 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.163923014246393e-05

num_try : 89 | val_loss = 1.163923014246393e-05 | val acc = 0.0027716667391359806
Time execution (tranning): 76.376730 seconds 
Time execution (load saved model): 0.002352 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.172340773337055e-05

num_try : 49 | val_loss = 1.172340773337055e-05 | val acc = 0.0026832758449018
Time execution (tranning): 52.810866 seconds 
Time execution (load saved model): 0.002331 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1730993664968991e-05

num_try : 77 | val_loss = 1.1730993664968991e-05 | val acc = 0.0027138725854456425
Time execution (tranning): 57.956776 seconds 
Time execution (load saved model): 0.002394 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1754898114304524e-05

num_try : 68 | val_loss = 1.1754898114304524e-05 | val acc = 0.002748232800513506
Time execution (tranning): 86.984763 seconds 
Time execution (load saved model): 0.002402 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 306
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1782454384956509e-05

num_try : 92 | val_loss = 1.1782454384956509e-05 | val acc = 0.002708916552364826
Time execution (tranning): 87.624654 seconds 
Time execution (load saved model): 0.002360 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1831673746200976e-05

num_try : 67 | val_loss = 1.1831673746200976e-05 | val acc = 0.002627395326271653
Time execution (tranning): 103.396104 seconds 
Time execution (load saved model): 0.002446 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 365
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.185956014523981e-05

num_try : 326 | val_loss = 1.185956014523981e-05 | val acc = 0.0026630929205566645
Time execution (tranning): 375.534058 seconds 
Time execution (load saved model): 0.016988 seconds 
Time execution (use saved model): 0.001110 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1860669874295126e-05

num_try : 211 | val_loss = 1.1860669874295126e-05 | val acc = 0.0023817934561520815
Time execution (tranning): 99.239605 seconds 
Time execution (load saved model): 0.003302 seconds 
Time execution (use saved model): 0.000320 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.186619614600204e-05

num_try : 199 | val_loss = 1.186619614600204e-05 | val acc = 0.002416146919131279
Time execution (tranning): 132.507779 seconds 
Time execution (load saved model): 0.003248 seconds 
Time execution (use saved model): 0.000304 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 371
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1895515199285e-05

num_try : 79 | val_loss = 1.1895515199285e-05 | val acc = 0.002791120670735836
Time execution (tranning): 79.059299 seconds 
Time execution (load saved model): 0.002353 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.194976008264348e-05

num_try : 69 | val_loss = 1.194976008264348e-05 | val acc = 0.0027866344898939133
Time execution (tranning): 71.176922 seconds 
Time execution (load saved model): 0.002383 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2011671033178573e-05

num_try : 237 | val_loss = 1.2011671033178573e-05 | val acc = 0.002370142377912998
Time execution (tranning): 116.059507 seconds 
Time execution (load saved model): 0.003573 seconds 
Time execution (use saved model): 0.000307 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2104741308576195e-05

num_try : 227 | val_loss = 1.2104741308576195e-05 | val acc = 0.0022795621771365404
Time execution (tranning): 154.624682 seconds 
Time execution (load saved model): 0.003352 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 417
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2123588257964002e-05

num_try : 104 | val_loss = 1.2123588257964002e-05 | val acc = 0.002546243602409959
Time execution (tranning): 68.773936 seconds 
Time execution (load saved model): 0.002405 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.2200045930512715e-05

num_try : 78 | val_loss = 1.2200045930512715e-05 | val acc = 0.0027932808734476566
Time execution (tranning): 83.155954 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2201466070109746e-05

num_try : 308 | val_loss = 1.2201466070109746e-05 | val acc = 0.002391277579590678
Time execution (tranning): 499.628698 seconds 
Time execution (load saved model): 0.022939 seconds 
Time execution (use saved model): 0.001128 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.2204209251649445e-05

num_try : 250 | val_loss = 1.2204209251649445e-05 | val acc = 0.0023564877919852734
Time execution (tranning): 114.895528 seconds 
Time execution (load saved model): 0.005816 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.2219531345181168e-05

num_try : 282 | val_loss = 1.2219531345181168e-05 | val acc = 0.002332710660994053
Time execution (tranning): 133.386306 seconds 
Time execution (load saved model): 0.007306 seconds 
Time execution (use saved model): 0.000437 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 274
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2226318722241558e-05

num_try : 246 | val_loss = 1.2226318722241558e-05 | val acc = 0.00239730766043067
Time execution (tranning): 98.547111 seconds 
Time execution (load saved model): 0.006497 seconds 
Time execution (use saved model): 0.000466 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2258040769665967e-05

num_try : 72 | val_loss = 1.2258040769665967e-05 | val acc = 0.002764378674328327
Time execution (tranning): 61.976001 seconds 
Time execution (load saved model): 0.002323 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.227916867719614e-05

num_try : 57 | val_loss = 1.227916867719614e-05 | val acc = 0.0027695188764482737
Time execution (tranning): 128.799146 seconds 
Time execution (load saved model): 0.002479 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 451
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2306594053370645e-05

num_try : 56 | val_loss = 1.2306594053370645e-05 | val acc = 0.0026910221204161644
Time execution (tranning): 70.128197 seconds 
Time execution (load saved model): 0.002340 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.2314591567701427e-05

num_try : 85 | val_loss = 1.2314591567701427e-05 | val acc = 0.0027957847341895103
Time execution (tranning): 41.257762 seconds 
Time execution (load saved model): 0.002344 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 149
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.2415137007337762e-05

num_try : 95 | val_loss = 1.2415137007337762e-05 | val acc = 0.0027371409814804792
Time execution (tranning): 92.654479 seconds 
Time execution (load saved model): 0.002354 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 326
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.250158853508765e-05

num_try : 75 | val_loss = 1.250158853508765e-05 | val acc = 0.002863676054403186
Time execution (tranning): 75.862240 seconds 
Time execution (load saved model): 0.002411 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2529259693110362e-05

num_try : 274 | val_loss = 1.2529259693110362e-05 | val acc = 0.0025181376840919256
Time execution (tranning): 187.419890 seconds 
Time execution (load saved model): 0.007287 seconds 
Time execution (use saved model): 0.000440 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.2532428436315967e-05

num_try : 309 | val_loss = 1.2532428436315967e-05 | val acc = 0.0023355213925242424
Time execution (tranning): 366.800150 seconds 
Time execution (load saved model): 0.016669 seconds 
Time execution (use saved model): 0.001076 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2629293523787055e-05

num_try : 136 | val_loss = 1.2629293523787055e-05 | val acc = 0.002619729144498706
Time execution (tranning): 78.550423 seconds 
Time execution (load saved model): 0.002457 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.269971573492512e-05

num_try : 334 | val_loss = 1.269971573492512e-05 | val acc = 0.0023517163936048746
Time execution (tranning): 589.848632 seconds 
Time execution (load saved model): 0.022343 seconds 
Time execution (use saved model): 0.001107 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 358
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.271023595109e-05

num_try : 203 | val_loss = 1.271023595109e-05 | val acc = 0.002469325438141823
Time execution (tranning): 109.641946 seconds 
Time execution (load saved model): 0.003879 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2715013681372512e-05

num_try : 259 | val_loss = 1.2715013681372512e-05 | val acc = 0.0023523622658103704
Time execution (tranning): 152.554429 seconds 
Time execution (load saved model): 0.005883 seconds 
Time execution (use saved model): 0.000447 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 301
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.2775010109180585e-05

num_try : 70 | val_loss = 1.2775010109180585e-05 | val acc = 0.0028296036180108786
Time execution (tranning): 102.136400 seconds 
Time execution (load saved model): 0.002349 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.2793324694939656e-05

num_try : 192 | val_loss = 1.2793324694939656e-05 | val acc = 0.0027669852133840322
Time execution (tranning): 71.109496 seconds 
Time execution (load saved model): 0.003245 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2829899969801772e-05

num_try : 60 | val_loss = 1.2829899969801772e-05 | val acc = 0.002800896530970931
Time execution (tranning): 69.469109 seconds 
Time execution (load saved model): 0.002351 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 250
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3120557605361683e-05

num_try : 294 | val_loss = 1.3120557605361683e-05 | val acc = 0.0024144297931343317
Time execution (tranning): 575.623960 seconds 
Time execution (load saved model): 0.016998 seconds 
Time execution (use saved model): 0.001139 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 346
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3129770977684529e-05

num_try : 61 | val_loss = 1.3129770977684529e-05 | val acc = 0.0028616758063435555
Time execution (tranning): 66.544477 seconds 
Time execution (load saved model): 0.002419 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3149055630492513e-05

num_try : 297 | val_loss = 1.3149055630492513e-05 | val acc = 0.0024490433279424906
Time execution (tranning): 346.886086 seconds 
Time execution (load saved model): 0.017660 seconds 
Time execution (use saved model): 0.001062 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.3151137263776036e-05

num_try : 301 | val_loss = 1.3151137263776036e-05 | val acc = 0.002947926754131913
Time execution (tranning): 478.979155 seconds 
Time execution (load saved model): 0.016749 seconds 
Time execution (use saved model): 0.001064 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 287
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3190348236093996e-05

num_try : 83 | val_loss = 1.3190348236093996e-05 | val acc = 0.002794031985104084
Time execution (tranning): 67.563286 seconds 
Time execution (load saved model): 0.002392 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.3196458221500506e-05

num_try : 53 | val_loss = 1.3196458221500506e-05 | val acc = 0.002873119432479143
Time execution (tranning): 67.464748 seconds 
Time execution (load saved model): 0.002334 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.3202035406720824e-05

num_try : 332 | val_loss = 1.3202035406720824e-05 | val acc = 0.0024624725338071585
Time execution (tranning): 254.325249 seconds 
Time execution (load saved model): 0.018688 seconds 
Time execution (use saved model): 0.001078 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 153
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3304674994287779e-05

num_try : 50 | val_loss = 1.3304674994287779e-05 | val acc = 0.0028454225976020098
Time execution (tranning): 64.951655 seconds 
Time execution (load saved model): 0.002381 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3418922262644629e-05

num_try : 311 | val_loss = 1.3418922262644629e-05 | val acc = 0.00243675266392529
Time execution (tranning): 404.470960 seconds 
Time execution (load saved model): 0.016652 seconds 
Time execution (use saved model): 0.001132 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.3476028343575308e-05

num_try : 319 | val_loss = 1.3476028343575308e-05 | val acc = 0.0024565388448536396
Time execution (tranning): 583.085332 seconds 
Time execution (load saved model): 0.016794 seconds 
Time execution (use saved model): 0.001093 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 350
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3498810276360018e-05

num_try : 252 | val_loss = 1.3498810276360018e-05 | val acc = 0.0024934196844697
Time execution (tranning): 172.370731 seconds 
Time execution (load saved model): 0.006567 seconds 
Time execution (use saved model): 0.000463 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 348
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3574940367107046e-05

num_try : 258 | val_loss = 1.3574940367107046e-05 | val acc = 0.002432991052046418
Time execution (tranning): 171.469954 seconds 
Time execution (load saved model): 0.005812 seconds 
Time execution (use saved model): 0.000440 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 340
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3622344104078366e-05

num_try : 300 | val_loss = 1.3622344104078366e-05 | val acc = 0.002949916757643223
Time execution (tranning): 440.364404 seconds 
Time execution (load saved model): 0.017366 seconds 
Time execution (use saved model): 0.001069 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3852043266524561e-05

num_try : 81 | val_loss = 1.3852043266524561e-05 | val acc = 0.002896730788052082
Time execution (tranning): 80.781273 seconds 
Time execution (load saved model): 0.002350 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.3932978508819361e-05

num_try : 287 | val_loss = 1.3932978508819361e-05 | val acc = 0.002541877329349518
Time execution (tranning): 107.532475 seconds 
Time execution (load saved model): 0.005922 seconds 
Time execution (use saved model): 0.000452 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.3961247241240926e-05

num_try : 215 | val_loss = 1.3961247241240926e-05 | val acc = 0.002519255504012108
Time execution (tranning): 64.672073 seconds 
Time execution (load saved model): 0.003272 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4041927588550607e-05

num_try : 55 | val_loss = 1.4041927588550607e-05 | val acc = 0.002975692041218281
Time execution (tranning): 70.001529 seconds 
Time execution (load saved model): 0.002328 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 252
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4077475170779508e-05

num_try : 302 | val_loss = 1.4077475170779508e-05 | val acc = 0.003213324351236224
Time execution (tranning): 373.861247 seconds 
Time execution (load saved model): 0.016649 seconds 
Time execution (use saved model): 0.001059 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.419910675394931e-05

num_try : 299 | val_loss = 1.419910675394931e-05 | val acc = 0.0024647852405905724
Time execution (tranning): 623.777857 seconds 
Time execution (load saved model): 0.017046 seconds 
Time execution (use saved model): 0.001131 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 370
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4226220246200683e-05

num_try : 63 | val_loss = 1.4226220246200683e-05 | val acc = 0.003039723727852106
Time execution (tranning): 56.422853 seconds 
Time execution (load saved model): 0.002464 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.4270609917730325e-05

num_try : 310 | val_loss = 1.4270609917730325e-05 | val acc = 0.002569804433733225
Time execution (tranning): 483.224652 seconds 
Time execution (load saved model): 0.016707 seconds 
Time execution (use saved model): 0.001102 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4278169492172311e-05

num_try : 217 | val_loss = 1.4278169492172311e-05 | val acc = 0.002765545155853033
Time execution (tranning): 114.346652 seconds 
Time execution (load saved model): 0.003359 seconds 
Time execution (use saved model): 0.000323 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 315
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4323410250653978e-05

num_try : 216 | val_loss = 1.4323410250653978e-05 | val acc = 0.0028978351037949324
Time execution (tranning): 79.768622 seconds 
Time execution (load saved model): 0.003338 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4440212125919061e-05

num_try : 80 | val_loss = 1.4440212125919061e-05 | val acc = 0.0029625750612467527
Time execution (tranning): 58.141266 seconds 
Time execution (load saved model): 0.002389 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4508171552733984e-05

num_try : 288 | val_loss = 1.4508171552733984e-05 | val acc = 0.0026408142875880003
Time execution (tranning): 366.895566 seconds 
Time execution (load saved model): 0.017187 seconds 
Time execution (use saved model): 0.001059 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 202
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4526133963954634e-05

num_try : 270 | val_loss = 1.4526133963954634e-05 | val acc = 0.0025106901302933693
Time execution (tranning): 91.204866 seconds 
Time execution (load saved model): 0.007332 seconds 
Time execution (use saved model): 0.000442 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 187
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4529319469147594e-05

num_try : 331 | val_loss = 1.4529319469147594e-05 | val acc = 0.002610713941976428
Time execution (tranning): 338.654623 seconds 
Time execution (load saved model): 0.017475 seconds 
Time execution (use saved model): 0.001090 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4562665492121595e-05

num_try : 330 | val_loss = 1.4562665492121595e-05 | val acc = 0.0025609852746129036
Time execution (tranning): 336.621980 seconds 
Time execution (load saved model): 0.016688 seconds 
Time execution (use saved model): 0.001085 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 207
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4580485531041632e-05

num_try : 264 | val_loss = 1.4580485531041632e-05 | val acc = 0.002850427059456706
Time execution (tranning): 127.913341 seconds 
Time execution (load saved model): 0.006247 seconds 
Time execution (use saved model): 0.000452 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 262
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4581773648387752e-05

num_try : 298 | val_loss = 1.4581773648387752e-05 | val acc = 0.0025435059797018766
Time execution (tranning): 389.431817 seconds 
Time execution (load saved model): 0.016843 seconds 
Time execution (use saved model): 0.001072 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4678923489555018e-05

num_try : 307 | val_loss = 1.4678923489555018e-05 | val acc = 0.002593569690361619
Time execution (tranning): 342.907822 seconds 
Time execution (load saved model): 0.022783 seconds 
Time execution (use saved model): 0.001109 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4813616253377404e-05

num_try : 335 | val_loss = 1.4813616253377404e-05 | val acc = 0.0026122834533452988
Time execution (tranning): 399.258859 seconds 
Time execution (load saved model): 0.016885 seconds 
Time execution (use saved model): 0.001105 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.485261571360752e-05

num_try : 262 | val_loss = 1.485261571360752e-05 | val acc = 0.0026348400861024857
Time execution (tranning): 89.515934 seconds 
Time execution (load saved model): 0.005917 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 175
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4925962950655958e-05

num_try : 208 | val_loss = 1.4925962950655958e-05 | val acc = 0.002820153720676899
Time execution (tranning): 78.487879 seconds 
Time execution (load saved model): 0.003312 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4963355661166133e-05

num_try : 163 | val_loss = 1.4963355661166133e-05 | val acc = 0.0027429896872490644
Time execution (tranning): 140.486130 seconds 
Time execution (load saved model): 0.002723 seconds 
Time execution (use saved model): 0.000280 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 455
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4983680739533155e-05

num_try : 322 | val_loss = 1.4983680739533155e-05 | val acc = 0.0025456685107201338
Time execution (tranning): 301.649838 seconds 
Time execution (load saved model): 0.016742 seconds 
Time execution (use saved model): 0.001119 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.5279274248314322e-05

num_try : 306 | val_loss = 1.5279274248314322e-05 | val acc = 0.00258128740824759
Time execution (tranning): 429.936409 seconds 
Time execution (load saved model): 0.016811 seconds 
Time execution (use saved model): 0.001114 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.5514293754677054e-05

num_try : 295 | val_loss = 1.5514293754677054e-05 | val acc = 0.002572183031588793
Time execution (tranning): 473.064008 seconds 
Time execution (load saved model): 0.016937 seconds 
Time execution (use saved model): 0.001102 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 276
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.558833708259044e-05

num_try : 245 | val_loss = 1.558833708259044e-05 | val acc = 0.002876793034374714
Time execution (tranning): 168.744603 seconds 
Time execution (load saved model): 0.005984 seconds 
Time execution (use saved model): 0.000445 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.5749407630210044e-05

num_try : 318 | val_loss = 1.5749407630210044e-05 | val acc = 0.002646665321663022
Time execution (tranning): 435.261913 seconds 
Time execution (load saved model): 0.016778 seconds 
Time execution (use saved model): 0.001085 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 254
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.591566040588077e-05

num_try : 260 | val_loss = 1.591566040588077e-05 | val acc = 0.00276789884082973
Time execution (tranning): 109.244286 seconds 
Time execution (load saved model): 0.006093 seconds 
Time execution (use saved model): 0.000453 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.599991042894544e-05

num_try : 202 | val_loss = 1.599991042894544e-05 | val acc = 0.0027509648352861404
Time execution (tranning): 78.610339 seconds 
Time execution (load saved model): 0.003270 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.6131385091284756e-05

num_try : 323 | val_loss = 1.6131385091284756e-05 | val acc = 0.002714366652071476
Time execution (tranning): 417.400413 seconds 
Time execution (load saved model): 0.019741 seconds 
Time execution (use saved model): 0.001133 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 249
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.6148524700838607e-05

num_try : 26 | val_loss = 1.6148524700838607e-05 | val acc = 0.0033271771389991045
Time execution (tranning): 78.314484 seconds 
Time execution (load saved model): 0.002374 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.6154921249835753e-05

num_try : 33 | val_loss = 1.6154921249835753e-05 | val acc = 0.0034245275892317295
Time execution (tranning): 86.239774 seconds 
Time execution (load saved model): 0.002320 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 310
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.6237140825978714e-05

num_try : 316 | val_loss = 1.6237140825978714e-05 | val acc = 0.002929411828517914
Time execution (tranning): 535.990600 seconds 
Time execution (load saved model): 0.016919 seconds 
Time execution (use saved model): 0.001105 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.6281823372992222e-05

num_try : 265 | val_loss = 1.6281823372992222e-05 | val acc = 0.002928024623543024
Time execution (tranning): 113.535331 seconds 
Time execution (load saved model): 0.006713 seconds 
Time execution (use saved model): 0.000478 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6284757057292153e-05

num_try : 293 | val_loss = 1.6284757057292153e-05 | val acc = 0.003233974799513817
Time execution (tranning): 551.068513 seconds 
Time execution (load saved model): 0.017648 seconds 
Time execution (use saved model): 0.001116 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.6336255175701808e-05

num_try : 30 | val_loss = 1.6336255175701808e-05 | val acc = 0.0033424377907067537
Time execution (tranning): 107.643510 seconds 
Time execution (load saved model): 0.002427 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 396
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.6336994249286363e-05

num_try : 223 | val_loss = 1.6336994249286363e-05 | val acc = 0.00283921230584383
Time execution (tranning): 84.226481 seconds 
Time execution (load saved model): 0.003284 seconds 
Time execution (use saved model): 0.000307 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6428984508820577e-05

num_try : 46 | val_loss = 1.6428984508820577e-05 | val acc = 0.0033152680844068527
Time execution (tranning): 95.872504 seconds 
Time execution (load saved model): 0.002314 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 346
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.6445860255771548e-05

num_try : 1 | val_loss = 1.6445860255771548e-05 | val acc = 0.0034817128907889128
Time execution (tranning): 71.519553 seconds 
Time execution (load saved model): 0.002292 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 261
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6519577511644455e-05

num_try : 263 | val_loss = 1.6519577511644455e-05 | val acc = 0.0027144267223775387
Time execution (tranning): 102.188444 seconds 
Time execution (load saved model): 0.007546 seconds 
Time execution (use saved model): 0.000465 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.6527122043044073e-05

num_try : 38 | val_loss = 1.6527122043044073e-05 | val acc = 0.0033955322578549385
Time execution (tranning): 63.220888 seconds 
Time execution (load saved model): 0.002309 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.658018616581103e-05

num_try : 25 | val_loss = 1.658018616581103e-05 | val acc = 0.0032899314537644386
Time execution (tranning): 68.202853 seconds 
Time execution (load saved model): 0.002434 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6698917825124227e-05

num_try : 253 | val_loss = 1.6698917825124227e-05 | val acc = 0.002789528574794531
Time execution (tranning): 200.111723 seconds 
Time execution (load saved model): 0.008268 seconds 
Time execution (use saved model): 0.000447 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 409
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.672090027568629e-05

num_try : 4 | val_loss = 1.672090027568629e-05 | val acc = 0.0034367823973298073
Time execution (tranning): 64.503933 seconds 
Time execution (load saved model): 0.002324 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.673551128988038e-05

num_try : 277 | val_loss = 1.673551128988038e-05 | val acc = 0.002965710824355483
Time execution (tranning): 96.425062 seconds 
Time execution (load saved model): 0.006300 seconds 
Time execution (use saved model): 0.000473 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.68388170277467e-05

num_try : 31 | val_loss = 1.68388170277467e-05 | val acc = 0.003412796650081873
Time execution (tranning): 82.600785 seconds 
Time execution (load saved model): 0.002337 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6914661591727055e-05

num_try : 6 | val_loss = 1.6914661591727055e-05 | val acc = 0.003362000221386552
Time execution (tranning): 84.798340 seconds 
Time execution (load saved model): 0.002340 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 313
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.692463887593476e-05

num_try : 0 | val_loss = 1.692463887593476e-05 | val acc = 0.003453285666182637
Time execution (tranning): 66.000320 seconds 
Time execution (load saved model): 0.002356 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.6954512502707076e-05

num_try : 17 | val_loss = 1.6954512502707076e-05 | val acc = 0.003488388145342469
Time execution (tranning): 65.769147 seconds 
Time execution (load saved model): 0.002372 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.69610066950554e-05

num_try : 12 | val_loss = 1.69610066950554e-05 | val acc = 0.003393125021830201
Time execution (tranning): 67.540141 seconds 
Time execution (load saved model): 0.002317 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 249
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.7037734269251815e-05

num_try : 204 | val_loss = 1.7037734269251815e-05 | val acc = 0.002985869301483035
Time execution (tranning): 86.640485 seconds 
Time execution (load saved model): 0.003312 seconds 
Time execution (use saved model): 0.000322 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.7123689503932836e-05

num_try : 24 | val_loss = 1.7123689503932836e-05 | val acc = 0.0034559571649879217
Time execution (tranning): 54.021741 seconds 
Time execution (load saved model): 0.002380 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 199
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.718033141514752e-05

num_try : 41 | val_loss = 1.718033141514752e-05 | val acc = 0.0035404134541749954
Time execution (tranning): 80.842139 seconds 
Time execution (load saved model): 0.002438 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.7222403403138743e-05

num_try : 39 | val_loss = 1.7222403403138743e-05 | val acc = 0.003475968027487397
Time execution (tranning): 80.755563 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.732315602566814e-05

num_try : 8 | val_loss = 1.732315602566814e-05 | val acc = 0.0035833728034049273
Time execution (tranning): 101.553547 seconds 
Time execution (load saved model): 0.002322 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 354
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.742025964631466e-05

num_try : 19 | val_loss = 1.742025964631466e-05 | val acc = 0.0034643078688532114
Time execution (tranning): 75.691691 seconds 
Time execution (load saved model): 0.002308 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.754052769683767e-05

num_try : 37 | val_loss = 1.754052769683767e-05 | val acc = 0.003533818991854787
Time execution (tranning): 80.441857 seconds 
Time execution (load saved model): 0.002330 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.7549315616633974e-05

num_try : 5 | val_loss = 1.7549315616633974e-05 | val acc = 0.0033447681926190853
Time execution (tranning): 81.640415 seconds 
Time execution (load saved model): 0.002320 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.7884235130622983e-05

num_try : 328 | val_loss = 1.7884235130622983e-05 | val acc = 0.0033136021811515093
Time execution (tranning): 345.893233 seconds 
Time execution (load saved model): 0.017910 seconds 
Time execution (use saved model): 0.001143 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.791586295439629e-05

num_try : 16 | val_loss = 1.791586295439629e-05 | val acc = 0.00350560387596488
Time execution (tranning): 58.100975 seconds 
Time execution (load saved model): 0.002425 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.800545971491374e-05

num_try : 14 | val_loss = 1.800545971491374e-05 | val acc = 0.0034327295143157244
Time execution (tranning): 57.986525 seconds 
Time execution (load saved model): 0.002319 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.8152477787225506e-05

num_try : 35 | val_loss = 1.8152477787225506e-05 | val acc = 0.0035955491475760937
Time execution (tranning): 75.886703 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 276
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.8165630935982337e-05

num_try : 329 | val_loss = 1.8165630935982337e-05 | val acc = 0.0032966043800115585
Time execution (tranning): 436.133635 seconds 
Time execution (load saved model): 0.016740 seconds 
Time execution (use saved model): 0.001076 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.8223612460133155e-05

num_try : 193 | val_loss = 1.8223612460133155e-05 | val acc = 0.002961256541311741
Time execution (tranning): 64.881569 seconds 
Time execution (load saved model): 0.003275 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 172
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.8335698350711026e-05

num_try : 3 | val_loss = 1.8335698350711026e-05 | val acc = 0.0035379084292799234
Time execution (tranning): 69.477547 seconds 
Time execution (load saved model): 0.002353 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.8563516568974592e-05

num_try : 40 | val_loss = 1.8563516568974592e-05 | val acc = 0.003570577595382929
Time execution (tranning): 57.291360 seconds 
Time execution (load saved model): 0.002328 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.8596443587739487e-05

num_try : 2 | val_loss = 1.8596443587739487e-05 | val acc = 0.0034322841092944145
Time execution (tranning): 55.575605 seconds 
Time execution (load saved model): 0.002340 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.86288350232644e-05

num_try : 36 | val_loss = 1.86288350232644e-05 | val acc = 0.0034818812273442745
Time execution (tranning): 56.397912 seconds 
Time execution (load saved model): 0.002389 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.869370349595556e-05

num_try : 44 | val_loss = 1.869370349595556e-05 | val acc = 0.0034845226909965277
Time execution (tranning): 65.483219 seconds 
Time execution (load saved model): 0.002330 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.891390416858485e-05

num_try : 29 | val_loss = 1.891390416858485e-05 | val acc = 0.003574141301214695
Time execution (tranning): 62.907142 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.8995688296854496e-05

num_try : 45 | val_loss = 1.8995688296854496e-05 | val acc = 0.0035387063398957253
Time execution (tranning): 67.990102 seconds 
Time execution (load saved model): 0.002362 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.9024063367396592e-05

num_try : 11 | val_loss = 1.9024063367396592e-05 | val acc = 0.003494753036648035
Time execution (tranning): 81.531360 seconds 
Time execution (load saved model): 0.002324 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.924992124259006e-05

num_try : 42 | val_loss = 1.924992124259006e-05 | val acc = 0.003504781750962138
Time execution (tranning): 82.944425 seconds 
Time execution (load saved model): 0.002311 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 302
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.9327268782944886e-05

num_try : 43 | val_loss = 1.9327268782944886e-05 | val acc = 0.0035667014308273792
Time execution (tranning): 105.457242 seconds 
Time execution (load saved model): 0.002317 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 384
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.937751156219747e-05

num_try : 18 | val_loss = 1.937751156219747e-05 | val acc = 0.003546361345797777
Time execution (tranning): 92.718955 seconds 
Time execution (load saved model): 0.002427 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 326
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.9421956785663497e-05

num_try : 9 | val_loss = 1.9421956785663497e-05 | val acc = 0.0036274066660553217
Time execution (tranning): 104.137041 seconds 
Time execution (load saved model): 0.002328 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 373
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.949795536347665e-05

num_try : 7 | val_loss = 1.949795536347665e-05 | val acc = 0.003483410459011793
Time execution (tranning): 113.882738 seconds 
Time execution (load saved model): 0.002418 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 419
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.9618556179921143e-05

num_try : 47 | val_loss = 1.9618556179921143e-05 | val acc = 0.0036003433633595705
Time execution (tranning): 88.871702 seconds 
Time execution (load saved model): 0.002331 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 320
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.9777397992584155e-05

num_try : 13 | val_loss = 1.9777397992584155e-05 | val acc = 0.0034268172457814217
Time execution (tranning): 65.600635 seconds 
Time execution (load saved model): 0.002364 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 242
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.9914573240384925e-05

num_try : 28 | val_loss = 1.9914573240384925e-05 | val acc = 0.0036184873897582293
Time execution (tranning): 68.456815 seconds 
Time execution (load saved model): 0.002413 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.993469923036173e-05

num_try : 20 | val_loss = 1.993469923036173e-05 | val acc = 0.0036464815493673086
Time execution (tranning): 52.204068 seconds 
Time execution (load saved model): 0.002311 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.007256585784489e-05

num_try : 290 | val_loss = 2.007256585784489e-05 | val acc = 0.003483609529212117
Time execution (tranning): 420.378116 seconds 
Time execution (load saved model): 0.017845 seconds 
Time execution (use saved model): 0.001102 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.013334677030798e-05

num_try : 34 | val_loss = 2.013334677030798e-05 | val acc = 0.0035743401385843754
Time execution (tranning): 87.298040 seconds 
Time execution (load saved model): 0.002365 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.034858709521359e-05

num_try : 327 | val_loss = 2.034858709521359e-05 | val acc = 0.0035844433587044477
Time execution (tranning): 332.797303 seconds 
Time execution (load saved model): 0.016671 seconds 
Time execution (use saved model): 0.001088 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.0376530883368105e-05

num_try : 27 | val_loss = 2.0376530883368105e-05 | val acc = 0.0036070120986551046
Time execution (tranning): 62.253583 seconds 
Time execution (load saved model): 0.002425 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.040003389993217e-05

num_try : 15 | val_loss = 2.040003389993217e-05 | val acc = 0.0036049126647412777
Time execution (tranning): 52.495739 seconds 
Time execution (load saved model): 0.002423 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.059417311102152e-05

num_try : 22 | val_loss = 2.059417311102152e-05 | val acc = 0.003575769253075123
Time execution (tranning): 68.026176 seconds 
Time execution (load saved model): 0.002359 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.0608517588698304e-05

num_try : 281 | val_loss = 2.0608517588698304e-05 | val acc = 0.0032053866889327765
Time execution (tranning): 122.215978 seconds 
Time execution (load saved model): 0.005930 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.0705341157736256e-05

num_try : 240 | val_loss = 2.0705341157736256e-05 | val acc = 0.003084243508055806
Time execution (tranning): 117.337455 seconds 
Time execution (load saved model): 0.005879 seconds 
Time execution (use saved model): 0.000443 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 217
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.1115944364282768e-05

num_try : 32 | val_loss = 2.1115944364282768e-05 | val acc = 0.0036801209207624197
Time execution (tranning): 75.704614 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.1163203673495445e-05

num_try : 23 | val_loss = 2.1163203673495445e-05 | val acc = 0.003593344008550048
Time execution (tranning): 83.608476 seconds 
Time execution (load saved model): 0.002458 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 300
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.2236036020331085e-05

num_try : 21 | val_loss = 2.2236036020331085e-05 | val acc = 0.003558172844350338
Time execution (tranning): 78.495977 seconds 
Time execution (load saved model): 0.002305 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.2309211781248452e-05

num_try : 10 | val_loss = 2.2309211781248452e-05 | val acc = 0.0037248593289405107
Time execution (tranning): 60.880149 seconds 
Time execution (load saved model): 0.002532 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.2621156203967986e-05

num_try : 280 | val_loss = 2.2621156203967986e-05 | val acc = 0.0032987508457154036
Time execution (tranning): 109.261586 seconds 
Time execution (load saved model): 0.005871 seconds 
Time execution (use saved model): 0.000442 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.443538233113941e-05

num_try : 256 | val_loss = 3.443538233113941e-05 | val acc = 0.004880470689386129
Time execution (tranning): 57.237922 seconds 
Time execution (load saved model): 0.007159 seconds 
Time execution (use saved model): 0.000483 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 114
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.606321974075399e-05

num_try : 257 | val_loss = 3.606321974075399e-05 | val acc = 0.004884887486696243
Time execution (tranning): 59.785305 seconds 
Time execution (load saved model): 0.006271 seconds 
Time execution (use saved model): 0.000465 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 114
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

3.704885813931469e-05

num_try : 291 | val_loss = 3.704885813931469e-05 | val acc = 0.004382145591080189
Time execution (tranning): 512.426767 seconds 
Time execution (load saved model): 0.017969 seconds 
Time execution (use saved model): 0.001118 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.38881042302819e-05

num_try : 312 | val_loss = 5.38881042302819e-05 | val acc = 0.0054643345065414906
Time execution (tranning): 182.161237 seconds 
Time execution (load saved model): 0.017824 seconds 
Time execution (use saved model): 0.001085 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 110
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.745300753915217e-05

num_try : 317 | val_loss = 5.745300753915217e-05 | val acc = 0.006102061830461025
Time execution (tranning): 185.738280 seconds 
Time execution (load saved model): 0.022099 seconds 
Time execution (use saved model): 0.001076 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 108
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.675680371699855e-05

num_try : 325 | val_loss = 6.675680371699855e-05 | val acc = 0.006471848580986261
Time execution (tranning): 188.980068 seconds 
Time execution (load saved model): 0.016771 seconds 
Time execution (use saved model): 0.001082 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 112
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.962433712440543e-05

num_try : 305 | val_loss = 8.962433712440543e-05 | val acc = 0.007505685091018677
Time execution (tranning): 119.052348 seconds 
Time execution (load saved model): 0.016486 seconds 
Time execution (use saved model): 0.001106 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=64,
- n_nodes=[2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 71
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.5073649096488952

num_try : 3 | val_loss = 1.5073649096488952 | val acc = 1.5952439308166504
Time execution: 147.929160 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.TORQUE,
- batch_size=64,
- n_nodes=[1024, 1024, 1024],
- activations=[GELU(approximate='none'), GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.6857920432090758

num_try : 4 | val_loss = 1.6857920432090758 | val acc = 1.6409509181976318
Time execution: 625.000172 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.TORQUE,
- batch_size=64,
- n_nodes=[2048, 2048, 2048],
- activations=[GELU(approximate='none'), GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.0601087188720704

num_try : 2 | val_loss = 2.0601087188720704 | val acc = 1.9514480829238892
Time execution: 96.344057 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.TORQUE,
- batch_size=64,
- n_nodes=[512, 512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.3977840757369995

num_try : 1 | val_loss = 2.3977840757369995 | val acc = 1.9822293519973755
Time execution: 97.191770 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.TORQUE,
- batch_size=64,
- n_nodes=[256, 256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.2598812055587767

num_try : 0 | val_loss = 3.2598812055587767 | val acc = 2.3881006240844727
Time execution: 93.934672 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.TORQUE,
- batch_size=64,
- n_nodes=[128, 128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

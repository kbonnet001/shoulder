3.835079367036087e-06

num_try : 350 | val_loss = 3.835079367036087e-06 | val acc = 0.0015740575036033988
Time execution (tranning): 138.071304 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.862690477944852e-06

num_try : 325 | val_loss = 3.862690477944852e-06 | val acc = 0.001630414859391749
Time execution (tranning): 113.797738 seconds 
Time execution (load saved model): 0.002333 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.909500019290136e-06

num_try : 349 | val_loss = 3.909500019290136e-06 | val acc = 0.0016022727359086275
Time execution (tranning): 186.944479 seconds 
Time execution (load saved model): 0.002419 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 434
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.120433879961638e-06

num_try : 401 | val_loss = 4.120433879961638e-06 | val acc = 0.0015252686571329832
Time execution (tranning): 146.917318 seconds 
Time execution (load saved model): 0.002577 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 312
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.128245977881306e-06

num_try : 375 | val_loss = 4.128245977881306e-06 | val acc = 0.0016411442775279284
Time execution (tranning): 136.145476 seconds 
Time execution (load saved model): 0.002393 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 309
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.138034103107202e-06

num_try : 400 | val_loss = 4.138034103107202e-06 | val acc = 0.0017062317347154021
Time execution (tranning): 96.409720 seconds 
Time execution (load saved model): 0.002535 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.145342709307442e-06

num_try : 470 | val_loss = 4.145342709307442e-06 | val acc = 0.0016425343928858638
Time execution (tranning): 121.434309 seconds 
Time execution (load saved model): 0.002520 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.148573896145535e-06

num_try : 398 | val_loss = 4.148573896145535e-06 | val acc = 0.001599484938196838
Time execution (tranning): 139.682527 seconds 
Time execution (load saved model): 0.002533 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.170982765572262e-06

num_try : 327 | val_loss = 4.170982765572262e-06 | val acc = 0.0017133934888988733
Time execution (tranning): 124.305687 seconds 
Time execution (load saved model): 0.002356 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.171435218722763e-06

num_try : 373 | val_loss = 4.171435218722763e-06 | val acc = 0.0017360943602398038
Time execution (tranning): 120.986388 seconds 
Time execution (load saved model): 0.002408 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.326872608544363e-06

num_try : 496 | val_loss = 4.326872608544363e-06 | val acc = 0.0017410580767318606
Time execution (tranning): 134.206238 seconds 
Time execution (load saved model): 0.003256 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.381114192710811e-06

num_try : 445 | val_loss = 4.381114192710811e-06 | val acc = 0.0016455375589430332
Time execution (tranning): 149.151768 seconds 
Time execution (load saved model): 0.002508 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 322
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.414554448430863e-06

num_try : 493 | val_loss = 4.414554448430863e-06 | val acc = 0.0016273658256977797
Time execution (tranning): 167.788280 seconds 
Time execution (load saved model): 0.003255 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 318
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.424190037752851e-06

num_try : 364 | val_loss = 4.424190037752851e-06 | val acc = 0.0017768056131899357
Time execution (tranning): 82.192858 seconds 
Time execution (load saved model): 0.002462 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.4244707692087105e-06

num_try : 517 | val_loss = 4.4244707692087105e-06 | val acc = 0.0017289342358708382
Time execution (tranning): 123.107924 seconds 
Time execution (load saved model): 0.003483 seconds 
Time execution (use saved model): 0.000330 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.451777986105299e-06

num_try : 449 | val_loss = 4.451777986105299e-06 | val acc = 0.0017003732500597835
Time execution (tranning): 116.890563 seconds 
Time execution (load saved model): 0.002519 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.5027951114207095e-06

num_try : 469 | val_loss = 4.5027951114207095e-06 | val acc = 0.0016119671054184437
Time execution (tranning): 128.760346 seconds 
Time execution (load saved model): 0.002513 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.503358647980349e-06

num_try : 540 | val_loss = 4.503358647980349e-06 | val acc = 0.0017078256933018565
Time execution (tranning): 161.492926 seconds 
Time execution (load saved model): 0.003223 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.516428275564977e-06

num_try : 566 | val_loss = 4.516428275564977e-06 | val acc = 0.0017027008580043912
Time execution (tranning): 154.487630 seconds 
Time execution (load saved model): 0.003198 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 284
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.52600391326996e-06

num_try : 278 | val_loss = 4.52600391326996e-06 | val acc = 0.001856967923231423
Time execution (tranning): 129.023354 seconds 
Time execution (load saved model): 0.002313 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.541014325241122e-06

num_try : 328 | val_loss = 4.541014325241122e-06 | val acc = 0.0017545658629387617
Time execution (tranning): 96.431421 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.572293410092243e-06

num_try : 423 | val_loss = 4.572293410092243e-06 | val acc = 0.0016885839868336916
Time execution (tranning): 150.011672 seconds 
Time execution (load saved model): 0.002531 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 318
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.594489059854822e-06

num_try : 568 | val_loss = 4.594489059854822e-06 | val acc = 0.0017221719026565552
Time execution (tranning): 128.551376 seconds 
Time execution (load saved model): 0.003250 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.615466307313909e-06

num_try : 541 | val_loss = 4.615466307313909e-06 | val acc = 0.0016892004059627652
Time execution (tranning): 168.105546 seconds 
Time execution (load saved model): 0.003296 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 318
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.647000585009664e-06

num_try : 521 | val_loss = 4.647000585009664e-06 | val acc = 0.0017312170239165425
Time execution (tranning): 183.070392 seconds 
Time execution (load saved model): 0.003260 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 339
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.661711734570418e-06

num_try : 567 | val_loss = 4.661711734570418e-06 | val acc = 0.0017538234824314713
Time execution (tranning): 115.216719 seconds 
Time execution (load saved model): 0.003280 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.72512207352338e-06

num_try : 376 | val_loss = 4.72512207352338e-06 | val acc = 0.0017909632297232747
Time execution (tranning): 96.549263 seconds 
Time execution (load saved model): 0.002458 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.7493821057287274e-06

num_try : 408 | val_loss = 4.7493821057287274e-06 | val acc = 0.0018076386768370867
Time execution (tranning): 106.315391 seconds 
Time execution (load saved model): 0.002534 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.7709269756524005e-06

num_try : 337 | val_loss = 4.7709269756524005e-06 | val acc = 0.0018134413985535502
Time execution (tranning): 99.397597 seconds 
Time execution (load saved model): 0.002373 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.795489467142033e-06

num_try : 329 | val_loss = 4.795489467142033e-06 | val acc = 0.0017795407911762595
Time execution (tranning): 134.382745 seconds 
Time execution (load saved model): 0.002341 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 307
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.806572303550638e-06

num_try : 348 | val_loss = 4.806572303550638e-06 | val acc = 0.0017940832767635584
Time execution (tranning): 124.380627 seconds 
Time execution (load saved model): 0.002470 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 289
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.822751438950945e-06

num_try : 372 | val_loss = 4.822751438950945e-06 | val acc = 0.0018170969560742378
Time execution (tranning): 91.329786 seconds 
Time execution (load saved model): 0.002352 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.834303151710628e-06

num_try : 444 | val_loss = 4.834303151710628e-06 | val acc = 0.0018658183980733156
Time execution (tranning): 101.792393 seconds 
Time execution (load saved model): 0.002688 seconds 
Time execution (use saved model): 0.000279 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.846375236411404e-06

num_try : 565 | val_loss = 4.846375236411404e-06 | val acc = 0.001806508400477469
Time execution (tranning): 95.813739 seconds 
Time execution (load saved model): 0.003298 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 178
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.853012649164157e-06

num_try : 352 | val_loss = 4.853012649164157e-06 | val acc = 0.0017846986884251237
Time execution (tranning): 117.022868 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.8786063825900786e-06

num_try : 244 | val_loss = 4.8786063825900786e-06 | val acc = 0.0018900330178439617
Time execution (tranning): 90.235669 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.895345209661173e-06

num_try : 434 | val_loss = 4.895345209661173e-06 | val acc = 0.0018010742496699095
Time execution (tranning): 83.447750 seconds 
Time execution (load saved model): 0.002586 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 177
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.903864096377219e-06

num_try : 542 | val_loss = 4.903864096377219e-06 | val acc = 0.0018089457880705595
Time execution (tranning): 114.609785 seconds 
Time execution (load saved model): 0.003251 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.920508856685046e-06

num_try : 422 | val_loss = 4.920508856685046e-06 | val acc = 0.0018629499245435
Time execution (tranning): 105.150296 seconds 
Time execution (load saved model): 0.002623 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

4.921995125641842e-06

num_try : 289 | val_loss = 4.921995125641842e-06 | val acc = 0.0017963281134143472
Time execution (tranning): 129.007053 seconds 
Time execution (load saved model): 0.002374 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.928037437821331e-06

num_try : 317 | val_loss = 4.928037437821331e-06 | val acc = 0.0018905684119090438
Time execution (tranning): 111.729722 seconds 
Time execution (load saved model): 0.002332 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.943036506119825e-06

num_try : 340 | val_loss = 4.943036506119825e-06 | val acc = 0.0017687577055767179
Time execution (tranning): 156.886371 seconds 
Time execution (load saved model): 0.002615 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 355
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.9494678637529435e-06

num_try : 468 | val_loss = 4.9494678637529435e-06 | val acc = 0.001775357872247696
Time execution (tranning): 105.026009 seconds 
Time execution (load saved model): 0.002565 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.96569898814414e-06

num_try : 300 | val_loss = 4.96569898814414e-06 | val acc = 0.0018023905577138066
Time execution (tranning): 111.024695 seconds 
Time execution (load saved model): 0.002392 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

4.967212139490584e-06

num_try : 495 | val_loss = 4.967212139490584e-06 | val acc = 0.0016498980112373829
Time execution (tranning): 186.787149 seconds 
Time execution (load saved model): 0.003278 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 350
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.974200328433653e-06

num_try : 387 | val_loss = 4.974200328433653e-06 | val acc = 0.0017088123131543398
Time execution (tranning): 96.843014 seconds 
Time execution (load saved model): 0.002541 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.987794627595577e-06

num_try : 252 | val_loss = 4.987794627595577e-06 | val acc = 0.0019440214382484555
Time execution (tranning): 94.607717 seconds 
Time execution (load saved model): 0.002296 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.060837879682367e-06

num_try : 420 | val_loss = 5.060837879682367e-06 | val acc = 0.001814872957766056
Time execution (tranning): 107.183000 seconds 
Time execution (load saved model): 0.002666 seconds 
Time execution (use saved model): 0.000280 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.0800516510207675e-06

num_try : 302 | val_loss = 5.0800516510207675e-06 | val acc = 0.0017124307341873646
Time execution (tranning): 128.207467 seconds 
Time execution (load saved model): 0.002362 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.105847096729122e-06

num_try : 564 | val_loss = 5.105847096729122e-06 | val acc = 0.0018270304426550865
Time execution (tranning): 131.070786 seconds 
Time execution (load saved model): 0.003260 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.10842297671843e-06

num_try : 292 | val_loss = 5.10842297671843e-06 | val acc = 0.0018375589279457927
Time execution (tranning): 96.631722 seconds 
Time execution (load saved model): 0.002355 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 219
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.116808390539518e-06

num_try : 233 | val_loss = 5.116808390539518e-06 | val acc = 0.0018716208869591355
Time execution (tranning): 111.612977 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.120921891830221e-06

num_try : 519 | val_loss = 5.120921891830221e-06 | val acc = 0.001860199379734695
Time execution (tranning): 129.513101 seconds 
Time execution (load saved model): 0.003187 seconds 
Time execution (use saved model): 0.000303 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.129217918238282e-06

num_try : 315 | val_loss = 5.129217918238282e-06 | val acc = 0.0018359628738835454
Time execution (tranning): 79.655732 seconds 
Time execution (load saved model): 0.002324 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 180
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.167326462469646e-06

num_try : 516 | val_loss = 5.167326462469646e-06 | val acc = 0.0017420261865481734
Time execution (tranning): 161.464435 seconds 
Time execution (load saved model): 0.003182 seconds 
Time execution (use saved model): 0.000302 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 306
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.171467457785184e-06

num_try : 388 | val_loss = 5.171467457785184e-06 | val acc = 0.001791501883417368
Time execution (tranning): 139.295941 seconds 
Time execution (load saved model): 0.002531 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.174873990654305e-06

num_try : 421 | val_loss = 5.174873990654305e-06 | val acc = 0.001814182847738266
Time execution (tranning): 123.786734 seconds 
Time execution (load saved model): 0.002543 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.184487897622603e-06

num_try : 432 | val_loss = 5.184487897622603e-06 | val acc = 0.0018493885872885585
Time execution (tranning): 79.124369 seconds 
Time execution (load saved model): 0.002581 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 171
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.2348937788337935e-06

num_try : 301 | val_loss = 5.2348937788337935e-06 | val acc = 0.0019246158190071583
Time execution (tranning): 97.638288 seconds 
Time execution (load saved model): 0.002354 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.242915153758076e-06

num_try : 374 | val_loss = 5.242915153758076e-06 | val acc = 0.0018324799602851272
Time execution (tranning): 117.749198 seconds 
Time execution (load saved model): 0.002430 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.251547809166368e-06

num_try : 385 | val_loss = 5.251547809166368e-06 | val acc = 0.0018343371339142323
Time execution (tranning): 117.452752 seconds 
Time execution (load saved model): 0.002489 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.258677056190209e-06

num_try : 277 | val_loss = 5.258677056190209e-06 | val acc = 0.001969832694157958
Time execution (tranning): 117.924737 seconds 
Time execution (load saved model): 0.002410 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.259900451619614e-06

num_try : 425 | val_loss = 5.259900451619614e-06 | val acc = 0.0017712864791974425
Time execution (tranning): 123.590676 seconds 
Time execution (load saved model): 0.002566 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.269324060463987e-06

num_try : 471 | val_loss = 5.269324060463987e-06 | val acc = 0.00180247041862458
Time execution (tranning): 93.470024 seconds 
Time execution (load saved model): 0.002563 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.273166889310232e-06

num_try : 410 | val_loss = 5.273166889310232e-06 | val acc = 0.0019247597083449364
Time execution (tranning): 108.673748 seconds 
Time execution (load saved model): 0.002627 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.277811196719995e-06

num_try : 353 | val_loss = 5.277811196719995e-06 | val acc = 0.0018419013358652592
Time execution (tranning): 119.529887 seconds 
Time execution (load saved model): 0.002403 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.292029829888633e-06

num_try : 472 | val_loss = 5.292029829888633e-06 | val acc = 0.0018228708067908883
Time execution (tranning): 101.075822 seconds 
Time execution (load saved model): 0.002533 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.307027286107768e-06

num_try : 264 | val_loss = 5.307027286107768e-06 | val acc = 0.0019290377385914326
Time execution (tranning): 77.976243 seconds 
Time execution (load saved model): 0.002425 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.308691779646324e-06

num_try : 290 | val_loss = 5.308691779646324e-06 | val acc = 0.001844843034632504
Time execution (tranning): 79.915451 seconds 
Time execution (load saved model): 0.002431 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 181
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.332142923180072e-06

num_try : 494 | val_loss = 5.332142923180072e-06 | val acc = 0.001870256382972002
Time execution (tranning): 112.591082 seconds 
Time execution (load saved model): 0.003306 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.373740368668222e-06

num_try : 265 | val_loss = 5.373740368668222e-06 | val acc = 0.0019660291727632284
Time execution (tranning): 87.629528 seconds 
Time execution (load saved model): 0.002276 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.374982088142133e-06

num_try : 411 | val_loss = 5.374982088142133e-06 | val acc = 0.0018711916636675596
Time execution (tranning): 91.023150 seconds 
Time execution (load saved model): 0.002495 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.3752622829961186e-06

num_try : 313 | val_loss = 5.3752622829961186e-06 | val acc = 0.0018181377090513706
Time execution (tranning): 95.165138 seconds 
Time execution (load saved model): 0.002357 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.381672513067315e-06

num_try : 433 | val_loss = 5.381672513067315e-06 | val acc = 0.0018773183692246675
Time execution (tranning): 103.210228 seconds 
Time execution (load saved model): 0.002577 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.40135576557077e-06

num_try : 520 | val_loss = 5.40135576557077e-06 | val acc = 0.001922526629641652
Time execution (tranning): 115.470143 seconds 
Time execution (load saved model): 0.003291 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.4014495390219965e-06

num_try : 229 | val_loss = 5.4014495390219965e-06 | val acc = 0.0020314808934926987
Time execution (tranning): 112.462960 seconds 
Time execution (load saved model): 0.002289 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.416753137978958e-06

num_try : 365 | val_loss = 5.416753137978958e-06 | val acc = 0.001931858016178012
Time execution (tranning): 115.715661 seconds 
Time execution (load saved model): 0.002419 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.417799111455679e-06

num_try : 409 | val_loss = 5.417799111455679e-06 | val acc = 0.0018351544858887792
Time execution (tranning): 110.258196 seconds 
Time execution (load saved model): 0.002635 seconds 
Time execution (use saved model): 0.000274 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.428862325516093e-06

num_try : 552 | val_loss = 5.428862325516093e-06 | val acc = 0.0019372712122276425
Time execution (tranning): 123.127861 seconds 
Time execution (load saved model): 0.003229 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 226
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.431399438293738e-06

num_try : 424 | val_loss = 5.431399438293738e-06 | val acc = 0.001820841571316123
Time execution (tranning): 120.223511 seconds 
Time execution (load saved model): 0.002580 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.435511516225233e-06

num_try : 492 | val_loss = 5.435511516225233e-06 | val acc = 0.001960453577339649
Time execution (tranning): 112.810231 seconds 
Time execution (load saved model): 0.003226 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.439387191472633e-06

num_try : 389 | val_loss = 5.439387191472633e-06 | val acc = 0.0018798393430188298
Time execution (tranning): 116.199848 seconds 
Time execution (load saved model): 0.002604 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.449790353395656e-06

num_try : 362 | val_loss = 5.449790353395656e-06 | val acc = 0.0019440080504864454
Time execution (tranning): 83.695249 seconds 
Time execution (load saved model): 0.002462 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.457360771288222e-06

num_try : 457 | val_loss = 5.457360771288222e-06 | val acc = 0.0018857619725167751
Time execution (tranning): 115.109411 seconds 
Time execution (load saved model): 0.002559 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.472661048315785e-06

num_try : 228 | val_loss = 5.472661048315785e-06 | val acc = 0.0019463743083178997
Time execution (tranning): 116.477880 seconds 
Time execution (load saved model): 0.002301 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 283
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.4835020637256096e-06

num_try : 220 | val_loss = 5.4835020637256096e-06 | val acc = 0.0020546363666653633
Time execution (tranning): 84.572580 seconds 
Time execution (load saved model): 0.002426 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 196
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.530585224278184e-06

num_try : 293 | val_loss = 5.530585224278184e-06 | val acc = 0.001847766456194222
Time execution (tranning): 100.929690 seconds 
Time execution (load saved model): 0.002351 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.530838775484881e-06

num_try : 435 | val_loss = 5.530838775484881e-06 | val acc = 0.001975675579160452
Time execution (tranning): 103.987663 seconds 
Time execution (load saved model): 0.002511 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.540351151012146e-06

num_try : 339 | val_loss = 5.540351151012146e-06 | val acc = 0.0018661774229258299
Time execution (tranning): 91.201039 seconds 
Time execution (load saved model): 0.002461 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.554108956857817e-06

num_try : 458 | val_loss = 5.554108956857817e-06 | val acc = 0.0020327838137745857
Time execution (tranning): 75.485653 seconds 
Time execution (load saved model): 0.003069 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 161
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.586123388638953e-06

num_try : 245 | val_loss = 5.586123388638953e-06 | val acc = 0.002048504538834095
Time execution (tranning): 101.932611 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.588490462287155e-06

num_try : 192 | val_loss = 5.588490462287155e-06 | val acc = 0.0019649448804557323
Time execution (tranning): 137.732798 seconds 
Time execution (load saved model): 0.002372 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 330
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.614066240013927e-06

num_try : 554 | val_loss = 5.614066240013927e-06 | val acc = 0.0019279413390904665
Time execution (tranning): 120.646935 seconds 
Time execution (load saved model): 0.003229 seconds 
Time execution (use saved model): 0.000303 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.619797984763864e-06

num_try : 456 | val_loss = 5.619797984763864e-06 | val acc = 0.0019439278403297067
Time execution (tranning): 107.188862 seconds 
Time execution (load saved model): 0.002559 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.620665365313471e-06

num_try : 257 | val_loss = 5.620665365313471e-06 | val acc = 0.001993146724998951
Time execution (tranning): 107.147607 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.638253558117867e-06

num_try : 312 | val_loss = 5.638253558117867e-06 | val acc = 0.0018460056744515896
Time execution (tranning): 115.462071 seconds 
Time execution (load saved model): 0.002462 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.660431038450042e-06

num_try : 448 | val_loss = 5.660431038450042e-06 | val acc = 0.0019089615670964122
Time execution (tranning): 150.306278 seconds 
Time execution (load saved model): 0.002586 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 315
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.666179185936926e-06

num_try : 254 | val_loss = 5.666179185936926e-06 | val acc = 0.0021078293211758137
Time execution (tranning): 150.705039 seconds 
Time execution (load saved model): 0.002411 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 349
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.668288622473483e-06

num_try : 206 | val_loss = 5.668288622473483e-06 | val acc = 0.0019473161082714796
Time execution (tranning): 145.809057 seconds 
Time execution (load saved model): 0.002312 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.680299068444583e-06

num_try : 336 | val_loss = 5.680299068444583e-06 | val acc = 0.0019111799774691463
Time execution (tranning): 121.790808 seconds 
Time execution (load saved model): 0.002460 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.685997839464108e-06

num_try : 557 | val_loss = 5.685997839464108e-06 | val acc = 0.0019071729620918632
Time execution (tranning): 196.199633 seconds 
Time execution (load saved model): 0.003401 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 364
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.724482639379857e-06

num_try : 543 | val_loss = 5.724482639379857e-06 | val acc = 0.0020405722316354513
Time execution (tranning): 145.604343 seconds 
Time execution (load saved model): 0.003241 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 270
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.790888685623941e-06

num_try : 361 | val_loss = 5.790888685623941e-06 | val acc = 0.0018934911349788308
Time execution (tranning): 126.749100 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.800459016427339e-06

num_try : 314 | val_loss = 5.800459016427339e-06 | val acc = 0.0019232422346249223
Time execution (tranning): 72.742790 seconds 
Time execution (load saved model): 0.002383 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 164
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.805059458907635e-06

num_try : 360 | val_loss = 5.805059458907635e-06 | val acc = 0.0018555020214989781
Time execution (tranning): 117.812603 seconds 
Time execution (load saved model): 0.002329 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 274
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.808765763504198e-06

num_try : 205 | val_loss = 5.808765763504198e-06 | val acc = 0.002122230129316449
Time execution (tranning): 101.738814 seconds 
Time execution (load saved model): 0.002345 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.818435706714808e-06

num_try : 531 | val_loss = 5.818435706714808e-06 | val acc = 0.0021052693482488394
Time execution (tranning): 108.336377 seconds 
Time execution (load saved model): 0.003237 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.828759335599898e-06

num_try : 316 | val_loss = 5.828759335599898e-06 | val acc = 0.0019462251802906394
Time execution (tranning): 77.648344 seconds 
Time execution (load saved model): 0.002392 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.831676112393325e-06

num_try : 436 | val_loss = 5.831676112393325e-06 | val acc = 0.0017908531008288264
Time execution (tranning): 93.368160 seconds 
Time execution (load saved model): 0.002514 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 195
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.847196953254752e-06

num_try : 460 | val_loss = 5.847196953254752e-06 | val acc = 0.0018099227454513311
Time execution (tranning): 100.736681 seconds 
Time execution (load saved model): 0.002641 seconds 
Time execution (use saved model): 0.000279 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.867120196398901e-06

num_try : 396 | val_loss = 5.867120196398901e-06 | val acc = 0.0019255026709288359
Time execution (tranning): 93.929815 seconds 
Time execution (load saved model): 0.002515 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.881208558093931e-06

num_try : 555 | val_loss = 5.881208558093931e-06 | val acc = 0.0020060832612216473
Time execution (tranning): 131.189950 seconds 
Time execution (load saved model): 0.003397 seconds 
Time execution (use saved model): 0.000327 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.94383027873846e-06

num_try : 269 | val_loss = 5.94383027873846e-06 | val acc = 0.002085981657728553
Time execution (tranning): 103.791159 seconds 
Time execution (load saved model): 0.002302 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.951057869424403e-06

num_try : 281 | val_loss = 5.951057869424403e-06 | val acc = 0.0020331174600869417
Time execution (tranning): 129.380304 seconds 
Time execution (load saved model): 0.002339 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

5.959796740171442e-06

num_try : 532 | val_loss = 5.959796740171442e-06 | val acc = 0.002133874921128154
Time execution (tranning): 127.998258 seconds 
Time execution (load saved model): 0.003282 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.9621742911986075e-06

num_try : 279 | val_loss = 5.9621742911986075e-06 | val acc = 0.0020409277640283108
Time execution (tranning): 129.185149 seconds 
Time execution (load saved model): 0.002316 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.962591526440519e-06

num_try : 208 | val_loss = 5.962591526440519e-06 | val acc = 0.0020914629567414522
Time execution (tranning): 107.968426 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

5.981693916510266e-06

num_try : 446 | val_loss = 5.981693916510266e-06 | val acc = 0.0018055784748867154
Time execution (tranning): 110.268074 seconds 
Time execution (load saved model): 0.002596 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.007670622238948e-06

num_try : 253 | val_loss = 6.007670622238948e-06 | val acc = 0.0020569143816828728
Time execution (tranning): 123.975889 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 300
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

6.009128956065979e-06

num_try : 207 | val_loss = 6.009128956065979e-06 | val acc = 0.002006779657676816
Time execution (tranning): 147.775998 seconds 
Time execution (load saved model): 0.002310 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 344
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.090504184612655e-06

num_try : 194 | val_loss = 6.090504184612655e-06 | val acc = 0.002135674702003598
Time execution (tranning): 108.375791 seconds 
Time execution (load saved model): 0.002341 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.111869333835785e-06

num_try : 351 | val_loss = 6.111869333835785e-06 | val acc = 0.0019424468046054244
Time execution (tranning): 99.273244 seconds 
Time execution (load saved model): 0.002344 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.131425652711186e-06

num_try : 196 | val_loss = 6.131425652711186e-06 | val acc = 0.0020422341767698526
Time execution (tranning): 125.753537 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 290
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.172028724904521e-06

num_try : 276 | val_loss = 6.172028724904521e-06 | val acc = 0.0020831916481256485
Time execution (tranning): 75.960648 seconds 
Time execution (load saved model): 0.002339 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 183
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.1813409774913455e-06

num_try : 399 | val_loss = 6.1813409774913455e-06 | val acc = 0.002010077005252242
Time execution (tranning): 131.315771 seconds 
Time execution (load saved model): 0.002544 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.219904294084699e-06

num_try : 240 | val_loss = 6.219904294084699e-06 | val acc = 0.001976878149434924
Time execution (tranning): 86.619623 seconds 
Time execution (load saved model): 0.002393 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.222288157005096e-06

num_try : 324 | val_loss = 6.222288157005096e-06 | val acc = 0.0020508284214884043
Time execution (tranning): 97.392299 seconds 
Time execution (load saved model): 0.002398 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.276282069848094e-06

num_try : 569 | val_loss = 6.276282069848094e-06 | val acc = 0.001997523708269
Time execution (tranning): 104.934230 seconds 
Time execution (load saved model): 0.003181 seconds 
Time execution (use saved model): 0.000299 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.347460212055011e-06

num_try : 268 | val_loss = 6.347460212055011e-06 | val acc = 0.002106317086145282
Time execution (tranning): 83.990492 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.4006668799265755e-06

num_try : 291 | val_loss = 6.4006668799265755e-06 | val acc = 0.001907369471155107
Time execution (tranning): 94.552811 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.407386845239671e-06

num_try : 447 | val_loss = 6.407386845239671e-06 | val acc = 0.0018418062245473266
Time execution (tranning): 149.660423 seconds 
Time execution (load saved model): 0.002597 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.470449166045e-06

num_try : 255 | val_loss = 6.470449166045e-06 | val acc = 0.0021168955136090517
Time execution (tranning): 121.083562 seconds 
Time execution (load saved model): 0.002268 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.484349435140757e-06

num_try : 341 | val_loss = 6.484349435140757e-06 | val acc = 0.00200810469686985
Time execution (tranning): 111.796995 seconds 
Time execution (load saved model): 0.002364 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.4865907097555465e-06

num_try : 173 | val_loss = 6.4865907097555465e-06 | val acc = 0.0022600588854402304
Time execution (tranning): 81.543043 seconds 
Time execution (load saved model): 0.002324 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.5079517798949385e-06

num_try : 326 | val_loss = 6.5079517798949385e-06 | val acc = 0.0020566678140312433
Time execution (tranning): 100.197219 seconds 
Time execution (load saved model): 0.002339 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.542448668369616e-06

num_try : 459 | val_loss = 6.542448668369616e-06 | val acc = 0.0019595192279666662
Time execution (tranning): 104.964855 seconds 
Time execution (load saved model): 0.002566 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.550700427396805e-06

num_try : 384 | val_loss = 6.550700427396805e-06 | val acc = 0.0019203216070309281
Time execution (tranning): 127.700589 seconds 
Time execution (load saved model): 0.002541 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 276
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.579096029781795e-06

num_try : 417 | val_loss = 6.579096029781795e-06 | val acc = 0.0022624852135777473
Time execution (tranning): 142.496325 seconds 
Time execution (load saved model): 0.002661 seconds 
Time execution (use saved model): 0.000281 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 294
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.582102787433541e-06

num_try : 548 | val_loss = 6.582102787433541e-06 | val acc = 0.0021817467641085386
Time execution (tranning): 127.966151 seconds 
Time execution (load saved model): 0.003324 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.58881816889334e-06

num_try : 219 | val_loss = 6.58881816889334e-06 | val acc = 0.0021591249387711287
Time execution (tranning): 57.704314 seconds 
Time execution (load saved model): 0.002393 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 134
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.599861194445111e-06

num_try : 505 | val_loss = 6.599861194445111e-06 | val acc = 0.0021427366882562637
Time execution (tranning): 139.433697 seconds 
Time execution (load saved model): 0.003360 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

6.674517444480443e-06

num_try : 518 | val_loss = 6.674517444480443e-06 | val acc = 0.0019554393365979195
Time execution (tranning): 180.395292 seconds 
Time execution (load saved model): 0.003234 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.689526117042988e-06

num_try : 242 | val_loss = 6.689526117042988e-06 | val acc = 0.0022654689382761717
Time execution (tranning): 117.436946 seconds 
Time execution (load saved model): 0.002365 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.71402850002778e-06

num_try : 217 | val_loss = 6.71402850002778e-06 | val acc = 0.002144415397197008
Time execution (tranning): 85.681834 seconds 
Time execution (load saved model): 0.002371 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

6.73700792958698e-06

num_try : 525 | val_loss = 6.73700792958698e-06 | val acc = 0.002137088682502508
Time execution (tranning): 179.716101 seconds 
Time execution (load saved model): 0.003340 seconds 
Time execution (use saved model): 0.000287 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.738024585501989e-06

num_try : 544 | val_loss = 6.738024585501989e-06 | val acc = 0.0020114812068641186
Time execution (tranning): 100.011404 seconds 
Time execution (load saved model): 0.003318 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

6.810493682678498e-06

num_try : 437 | val_loss = 6.810493682678498e-06 | val acc = 0.0020180351566523314
Time execution (tranning): 90.836662 seconds 
Time execution (load saved model): 0.002593 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 190
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.861371930426685e-06

num_try : 120 | val_loss = 6.861371930426685e-06 | val acc = 0.0022091325372457504
Time execution (tranning): 109.692003 seconds 
Time execution (load saved model): 0.002367 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.861483393549861e-06

num_try : 243 | val_loss = 6.861483393549861e-06 | val acc = 0.002064705593511462
Time execution (tranning): 111.968794 seconds 
Time execution (load saved model): 0.002445 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.868891891826934e-06

num_try : 545 | val_loss = 6.868891891826934e-06 | val acc = 0.0020704413764178753
Time execution (tranning): 121.749539 seconds 
Time execution (load saved model): 0.003263 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

6.870050042380172e-06

num_try : 195 | val_loss = 6.870050042380172e-06 | val acc = 0.0022103609517216682
Time execution (tranning): 69.138813 seconds 
Time execution (load saved model): 0.002430 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 162
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

6.891879497743502e-06

num_try : 530 | val_loss = 6.891879497743502e-06 | val acc = 0.002130787819623947
Time execution (tranning): 133.713698 seconds 
Time execution (load saved model): 0.003450 seconds 
Time execution (use saved model): 0.000335 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.907331585352949e-06

num_try : 266 | val_loss = 6.907331585352949e-06 | val acc = 0.0021253088489174843
Time execution (tranning): 72.453418 seconds 
Time execution (load saved model): 0.002311 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 169
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

6.910045476615778e-06

num_try : 157 | val_loss = 6.910045476615778e-06 | val acc = 0.002323641674593091
Time execution (tranning): 181.119508 seconds 
Time execution (load saved model): 0.002391 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 440
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

6.948189811737393e-06

num_try : 216 | val_loss = 6.948189811737393e-06 | val acc = 0.0021882287692278624
Time execution (tranning): 57.006888 seconds 
Time execution (load saved model): 0.002304 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 137
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

6.952290214030654e-06

num_try : 193 | val_loss = 6.952290214030654e-06 | val acc = 0.002116302028298378
Time execution (tranning): 82.248635 seconds 
Time execution (load saved model): 0.002419 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 195
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.001226495049196e-06

num_try : 181 | val_loss = 7.001226495049196e-06 | val acc = 0.0022968838457018137
Time execution (tranning): 113.554223 seconds 
Time execution (load saved model): 0.002291 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 276
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.038974558781774e-06

num_try : 256 | val_loss = 7.038974558781774e-06 | val acc = 0.002214607782661915
Time execution (tranning): 104.163813 seconds 
Time execution (load saved model): 0.002289 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.1151405472846815e-06

num_try : 406 | val_loss = 7.1151405472846815e-06 | val acc = 0.0022795351687818766
Time execution (tranning): 146.524521 seconds 
Time execution (load saved model): 0.002512 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.116116003089701e-06

num_try : 232 | val_loss = 7.116116003089701e-06 | val acc = 0.0021820045076310635
Time execution (tranning): 89.191161 seconds 
Time execution (load saved model): 0.002283 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.135413252399303e-06

num_try : 463 | val_loss = 7.135413252399303e-06 | val acc = 0.002341883722692728
Time execution (tranning): 110.241513 seconds 
Time execution (load saved model): 0.002533 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.144011069613043e-06

num_try : 221 | val_loss = 7.144011069613043e-06 | val acc = 0.002093423390761018
Time execution (tranning): 96.317051 seconds 
Time execution (load saved model): 0.002294 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.155892944865627e-06

num_try : 145 | val_loss = 7.155892944865627e-06 | val acc = 0.00235870573669672
Time execution (tranning): 94.466865 seconds 
Time execution (load saved model): 0.002410 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.164881290009362e-06

num_try : 501 | val_loss = 7.164881290009362e-06 | val acc = 0.0021290855947881937
Time execution (tranning): 137.153251 seconds 
Time execution (load saved model): 0.003253 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.188644990492321e-06

num_try : 575 | val_loss = 7.188644990492321e-06 | val acc = 0.0021328942384570837
Time execution (tranning): 167.502064 seconds 
Time execution (load saved model): 0.003287 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 301
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.1942752083486995e-06

num_try : 526 | val_loss = 7.1942752083486995e-06 | val acc = 0.0022767826449126005
Time execution (tranning): 137.084434 seconds 
Time execution (load saved model): 0.003389 seconds 
Time execution (use saved model): 0.000333 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.2304460309169375e-06

num_try : 156 | val_loss = 7.2304460309169375e-06 | val acc = 0.0023181515280157328
Time execution (tranning): 121.574152 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 296
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.304881173695321e-06

num_try : 267 | val_loss = 7.304881173695321e-06 | val acc = 0.0022407732903957367
Time execution (tranning): 97.755764 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.326145369006553e-06

num_try : 412 | val_loss = 7.326145369006553e-06 | val acc = 0.002284278627485037
Time execution (tranning): 174.702642 seconds 
Time execution (load saved model): 0.002596 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 370
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.326896238737391e-06

num_try : 509 | val_loss = 7.326896238737391e-06 | val acc = 0.002203415846452117
Time execution (tranning): 149.235702 seconds 
Time execution (load saved model): 0.003237 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.343439647229389e-06

num_try : 482 | val_loss = 7.343439647229389e-06 | val acc = 0.002381478436291218
Time execution (tranning): 149.679396 seconds 
Time execution (load saved model): 0.003211 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.386325046354614e-06

num_try : 159 | val_loss = 7.386325046354614e-06 | val acc = 0.002329261042177677
Time execution (tranning): 98.394902 seconds 
Time execution (load saved model): 0.002395 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.38745743092295e-06

num_try : 111 | val_loss = 7.38745743092295e-06 | val acc = 0.0023241955786943436
Time execution (tranning): 134.223702 seconds 
Time execution (load saved model): 0.002343 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 319
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

7.39418769171607e-06

num_try : 112 | val_loss = 7.39418769171607e-06 | val acc = 0.0024090257938951254
Time execution (tranning): 100.989936 seconds 
Time execution (load saved model): 0.002276 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.4180432466164345e-06

num_try : 558 | val_loss = 7.4180432466164345e-06 | val acc = 0.0023350866977125406
Time execution (tranning): 155.486060 seconds 
Time execution (load saved model): 0.003242 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 283
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.421197706207749e-06

num_try : 146 | val_loss = 7.421197706207749e-06 | val acc = 0.0022907303646206856
Time execution (tranning): 80.064221 seconds 
Time execution (load saved model): 0.002319 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.439760152010422e-06

num_try : 168 | val_loss = 7.439760152010422e-06 | val acc = 0.0024340886157006025
Time execution (tranning): 62.107734 seconds 
Time execution (load saved model): 0.002251 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 153
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.464152954526071e-06

num_try : 144 | val_loss = 7.464152954526071e-06 | val acc = 0.002344701439142227
Time execution (tranning): 84.763564 seconds 
Time execution (load saved model): 0.002361 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.471930216524925e-06

num_try : 386 | val_loss = 7.471930216524925e-06 | val acc = 0.002153314184397459
Time execution (tranning): 75.051083 seconds 
Time execution (load saved model): 0.002597 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 160
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.473605392078753e-06

num_try : 503 | val_loss = 7.473605392078753e-06 | val acc = 0.002204630058258772
Time execution (tranning): 109.265050 seconds 
Time execution (load saved model): 0.003442 seconds 
Time execution (use saved model): 0.000330 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 195
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.474995063603274e-06

num_try : 467 | val_loss = 7.474995063603274e-06 | val acc = 0.002320033498108387
Time execution (tranning): 143.328836 seconds 
Time execution (load saved model): 0.002520 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.496917301068606e-06

num_try : 490 | val_loss = 7.496917301068606e-06 | val acc = 0.0024324541445821524
Time execution (tranning): 109.576572 seconds 
Time execution (load saved model): 0.003289 seconds 
Time execution (use saved model): 0.000313 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.502028552153206e-06

num_try : 550 | val_loss = 7.502028552153206e-06 | val acc = 0.002195595297962427
Time execution (tranning): 156.003886 seconds 
Time execution (load saved model): 0.003341 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 283
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.525499095208943e-06

num_try : 158 | val_loss = 7.525499095208943e-06 | val acc = 0.0024695182219147682
Time execution (tranning): 168.016998 seconds 
Time execution (load saved model): 0.002275 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 398
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.549370134256606e-06

num_try : 110 | val_loss = 7.549370134256606e-06 | val acc = 0.002386623527854681
Time execution (tranning): 137.854557 seconds 
Time execution (load saved model): 0.002267 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 330
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.552110751021246e-06

num_try : 529 | val_loss = 7.552110751021246e-06 | val acc = 0.002344913315027952
Time execution (tranning): 136.152914 seconds 
Time execution (load saved model): 0.003234 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 260
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.559602599940263e-06

num_try : 497 | val_loss = 7.559602599940263e-06 | val acc = 0.002057277364656329
Time execution (tranning): 119.539711 seconds 
Time execution (load saved model): 0.003258 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.562428686469503e-06

num_try : 160 | val_loss = 7.562428686469503e-06 | val acc = 0.0023538321256637573
Time execution (tranning): 140.213214 seconds 
Time execution (load saved model): 0.002312 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 331
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.564703864773037e-06

num_try : 419 | val_loss = 7.564703864773037e-06 | val acc = 0.002478719921782613
Time execution (tranning): 145.097034 seconds 
Time execution (load saved model): 0.002679 seconds 
Time execution (use saved model): 0.000284 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.565100836472993e-06

num_try : 506 | val_loss = 7.565100836472993e-06 | val acc = 0.0022236171644181013
Time execution (tranning): 126.832972 seconds 
Time execution (load saved model): 0.003331 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.603412027492595e-06

num_try : 305 | val_loss = 7.603412027492595e-06 | val acc = 0.002116732532158494
Time execution (tranning): 124.698543 seconds 
Time execution (load saved model): 0.002364 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.649408767065324e-06

num_try : 402 | val_loss = 7.649408767065324e-06 | val acc = 0.0022544660605490208
Time execution (tranning): 104.590394 seconds 
Time execution (load saved model): 0.002536 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.721422914528375e-06

num_try : 461 | val_loss = 7.721422914528375e-06 | val acc = 0.0021016516257077456
Time execution (tranning): 139.803456 seconds 
Time execution (load saved model): 0.002650 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.731450700703135e-06

num_try : 572 | val_loss = 7.731450700703135e-06 | val acc = 0.0022860723547637463
Time execution (tranning): 155.864680 seconds 
Time execution (load saved model): 0.003226 seconds 
Time execution (use saved model): 0.000302 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.737583559901396e-06

num_try : 553 | val_loss = 7.737583559901396e-06 | val acc = 0.0022887829691171646
Time execution (tranning): 195.440024 seconds 
Time execution (load saved model): 0.003219 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 372
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.7523897834908e-06

num_try : 413 | val_loss = 7.7523897834908e-06 | val acc = 0.002257168060168624
Time execution (tranning): 118.809127 seconds 
Time execution (load saved model): 0.002633 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.767988345221965e-06

num_try : 502 | val_loss = 7.767988345221965e-06 | val acc = 0.0022244465071707964
Time execution (tranning): 149.543418 seconds 
Time execution (load saved model): 0.003312 seconds 
Time execution (use saved model): 0.000321 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

7.808527125234831e-06

num_try : 149 | val_loss = 7.808527125234831e-06 | val acc = 0.002446091501042247
Time execution (tranning): 91.755674 seconds 
Time execution (load saved model): 0.002380 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.831291936781781e-06

num_try : 498 | val_loss = 7.831291936781781e-06 | val acc = 0.002276124432682991
Time execution (tranning): 108.999542 seconds 
Time execution (load saved model): 0.003263 seconds 
Time execution (use saved model): 0.000322 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 196
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.841357146389782e-06

num_try : 218 | val_loss = 7.841357146389782e-06 | val acc = 0.0023305637296289206
Time execution (tranning): 93.730387 seconds 
Time execution (load saved model): 0.002410 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.848657633076073e-06

num_try : 133 | val_loss = 7.848657633076073e-06 | val acc = 0.002400030381977558
Time execution (tranning): 118.189399 seconds 
Time execution (load saved model): 0.002305 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

7.851116693018412e-06

num_try : 182 | val_loss = 7.851116693018412e-06 | val acc = 0.002373072085902095
Time execution (tranning): 155.614288 seconds 
Time execution (load saved model): 0.002309 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 369
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.875099072407465e-06

num_try : 101 | val_loss = 7.875099072407465e-06 | val acc = 0.002367273671552539
Time execution (tranning): 111.262315 seconds 
Time execution (load saved model): 0.002308 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.922094068817387e-06

num_try : 527 | val_loss = 7.922094068817387e-06 | val acc = 0.0022055599838495255
Time execution (tranning): 128.059330 seconds 
Time execution (load saved model): 0.003712 seconds 
Time execution (use saved model): 0.000340 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.945912466311711e-06

num_try : 288 | val_loss = 7.945912466311711e-06 | val acc = 0.002100858138874173
Time execution (tranning): 94.762404 seconds 
Time execution (load saved model): 0.002422 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

7.946762589199351e-06

num_try : 377 | val_loss = 7.946762589199351e-06 | val acc = 0.002283236477524042
Time execution (tranning): 77.159638 seconds 
Time execution (load saved model): 0.002335 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 176
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.977160771588388e-06

num_try : 230 | val_loss = 7.977160771588388e-06 | val acc = 0.0022799468133598566
Time execution (tranning): 90.522338 seconds 
Time execution (load saved model): 0.002314 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

7.992123237272608e-06

num_try : 407 | val_loss = 7.992123237272608e-06 | val acc = 0.0023474502377212048
Time execution (tranning): 139.070476 seconds 
Time execution (load saved model): 0.002557 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

7.999782928891363e-06

num_try : 546 | val_loss = 7.999782928891363e-06 | val acc = 0.0021983771584928036
Time execution (tranning): 142.878387 seconds 
Time execution (load saved model): 0.003211 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 263
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.003299753909233e-06

num_try : 171 | val_loss = 8.003299753909233e-06 | val acc = 0.0024489753413945436
Time execution (tranning): 87.157391 seconds 
Time execution (load saved model): 0.002294 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.061558100962429e-06

num_try : 136 | val_loss = 8.061558100962429e-06 | val acc = 0.002447046572342515
Time execution (tranning): 140.890055 seconds 
Time execution (load saved model): 0.002292 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 336
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.065756974247051e-06

num_try : 134 | val_loss = 8.065756974247051e-06 | val acc = 0.002387942047789693
Time execution (tranning): 129.719900 seconds 
Time execution (load saved model): 0.002326 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 306
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.078868909251468e-06

num_try : 478 | val_loss = 8.078868909251468e-06 | val acc = 0.00227902689948678
Time execution (tranning): 94.986401 seconds 
Time execution (load saved model): 0.002584 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.085871331786621e-06

num_try : 184 | val_loss = 8.085871331786621e-06 | val acc = 0.0024365573190152645
Time execution (tranning): 78.976170 seconds 
Time execution (load saved model): 0.002383 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.08979948033084e-06

num_try : 109 | val_loss = 8.08979948033084e-06 | val acc = 0.0024782526306807995
Time execution (tranning): 83.452896 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.100702116280445e-06

num_try : 524 | val_loss = 8.100702116280445e-06 | val acc = 0.0023172448854893446
Time execution (tranning): 153.530108 seconds 
Time execution (load saved model): 0.003258 seconds 
Time execution (use saved model): 0.000304 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.105773626994051e-06

num_try : 363 | val_loss = 8.105773626994051e-06 | val acc = 0.0021548450458794832
Time execution (tranning): 86.035518 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 195
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.116519638861064e-06

num_try : 522 | val_loss = 8.116519638861064e-06 | val acc = 0.0022600910160690546
Time execution (tranning): 132.644347 seconds 
Time execution (load saved model): 0.003300 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.140277432175935e-06

num_try : 404 | val_loss = 8.140277432175935e-06 | val acc = 0.0024180104956030846
Time execution (tranning): 102.083839 seconds 
Time execution (load saved model): 0.002583 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.16285497876379e-06

num_try : 571 | val_loss = 8.16285497876379e-06 | val acc = 0.0023340003099292517
Time execution (tranning): 170.240543 seconds 
Time execution (load saved model): 0.003255 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 312
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.164174728335638e-06

num_try : 148 | val_loss = 8.164174728335638e-06 | val acc = 0.002333523705601692
Time execution (tranning): 91.988713 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.203381880775851e-06

num_try : 450 | val_loss = 8.203381880775851e-06 | val acc = 0.0024249651469290257
Time execution (tranning): 120.822314 seconds 
Time execution (load saved model): 0.002784 seconds 
Time execution (use saved model): 0.000290 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.213006199184746e-06

num_try : 415 | val_loss = 8.213006199184746e-06 | val acc = 0.002266848925501108
Time execution (tranning): 113.816708 seconds 
Time execution (load saved model): 0.002522 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.22005822101346e-06

num_try : 204 | val_loss = 8.22005822101346e-06 | val acc = 0.0022602383978664875
Time execution (tranning): 101.079436 seconds 
Time execution (load saved model): 0.002301 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.240568654400704e-06

num_try : 132 | val_loss = 8.240568654400704e-06 | val acc = 0.0024145671632140875
Time execution (tranning): 118.800269 seconds 
Time execution (load saved model): 0.002433 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 292
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.24191871288349e-06

num_try : 241 | val_loss = 8.24191871288349e-06 | val acc = 0.002152297180145979
Time execution (tranning): 79.889547 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.292270317724615e-06

num_try : 147 | val_loss = 8.292270317724615e-06 | val acc = 0.002431520726531744
Time execution (tranning): 74.170954 seconds 
Time execution (load saved model): 0.002276 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 177
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.295877169075539e-06

num_try : 466 | val_loss = 8.295877169075539e-06 | val acc = 0.002531777136027813
Time execution (tranning): 137.622029 seconds 
Time execution (load saved model): 0.002567 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.30092112209968e-06

num_try : 99 | val_loss = 8.30092112209968e-06 | val acc = 0.0024481136351823807
Time execution (tranning): 91.104640 seconds 
Time execution (load saved model): 0.002312 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.306741306114417e-06

num_try : 431 | val_loss = 8.306741306114417e-06 | val acc = 0.0023082613479346037
Time execution (tranning): 124.363451 seconds 
Time execution (load saved model): 0.002553 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.311963456435479e-06

num_try : 100 | val_loss = 8.311963456435479e-06 | val acc = 0.002375326817855239
Time execution (tranning): 86.397789 seconds 
Time execution (load saved model): 0.002373 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.36544771118497e-06

num_try : 124 | val_loss = 8.36544771118497e-06 | val acc = 0.0025061655323952436
Time execution (tranning): 105.703681 seconds 
Time execution (load saved model): 0.002344 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.393268162762979e-06

num_try : 370 | val_loss = 8.393268162762979e-06 | val acc = 0.0024456907995045185
Time execution (tranning): 120.539886 seconds 
Time execution (load saved model): 0.002337 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.402292437494907e-06

num_try : 135 | val_loss = 8.402292437494907e-06 | val acc = 0.0024156670551747084
Time execution (tranning): 123.965545 seconds 
Time execution (load saved model): 0.002323 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.427290417785116e-06

num_try : 452 | val_loss = 8.427290417785116e-06 | val acc = 0.002436311449855566
Time execution (tranning): 109.137194 seconds 
Time execution (load saved model): 0.002628 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.434760534328234e-06

num_try : 123 | val_loss = 8.434760534328234e-06 | val acc = 0.002581206150352955
Time execution (tranning): 84.078928 seconds 
Time execution (load saved model): 0.002266 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.458615216113685e-06

num_try : 137 | val_loss = 8.458615216113685e-06 | val acc = 0.002495192689821124
Time execution (tranning): 108.118100 seconds 
Time execution (load saved model): 0.002307 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 258
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

8.488434964419867e-06

num_try : 108 | val_loss = 8.488434964419867e-06 | val acc = 0.0025137162301689386
Time execution (tranning): 120.937766 seconds 
Time execution (load saved model): 0.002366 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.523458641320758e-06

num_try : 429 | val_loss = 8.523458641320758e-06 | val acc = 0.002373014111071825
Time execution (tranning): 116.976361 seconds 
Time execution (load saved model): 0.002599 seconds 
Time execution (use saved model): 0.000276 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.529963988621603e-06

num_try : 97 | val_loss = 8.529963988621603e-06 | val acc = 0.0025753630325198174
Time execution (tranning): 65.897585 seconds 
Time execution (load saved model): 0.002259 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 160
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.533900172551512e-06

num_try : 426 | val_loss = 8.533900172551512e-06 | val acc = 0.002401175443083048
Time execution (tranning): 127.051573 seconds 
Time execution (load saved model): 0.002648 seconds 
Time execution (use saved model): 0.000281 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.544531383449793e-06

num_try : 303 | val_loss = 8.544531383449793e-06 | val acc = 0.002233457285910845
Time execution (tranning): 94.732540 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.550842158001615e-06

num_try : 390 | val_loss = 8.550842158001615e-06 | val acc = 0.0023682089522480965
Time execution (tranning): 113.057151 seconds 
Time execution (load saved model): 0.002506 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.588305749981373e-06

num_try : 309 | val_loss = 8.588305749981373e-06 | val acc = 0.0024513949174433947
Time execution (tranning): 120.365829 seconds 
Time execution (load saved model): 0.002362 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.594174837526224e-06

num_try : 500 | val_loss = 8.594174837526224e-06 | val acc = 0.002357682678848505
Time execution (tranning): 113.418632 seconds 
Time execution (load saved model): 0.003340 seconds 
Time execution (use saved model): 0.000325 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.595546833021217e-06

num_try : 488 | val_loss = 8.595546833021217e-06 | val acc = 0.0024997834116220474
Time execution (tranning): 117.496875 seconds 
Time execution (load saved model): 0.003323 seconds 
Time execution (use saved model): 0.000305 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.597137994001968e-06

num_try : 570 | val_loss = 8.597137994001968e-06 | val acc = 0.0023055649362504482
Time execution (tranning): 101.947736 seconds 
Time execution (load saved model): 0.003214 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.624476922705071e-06

num_try : 369 | val_loss = 8.624476922705071e-06 | val acc = 0.002491476945579052
Time execution (tranning): 141.969725 seconds 
Time execution (load saved model): 0.002358 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 316
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.632107351331796e-06

num_try : 440 | val_loss = 8.632107351331796e-06 | val acc = 0.002398974960669875
Time execution (tranning): 88.944648 seconds 
Time execution (load saved model): 0.002565 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.679377615408156e-06

num_try : 508 | val_loss = 8.679377615408156e-06 | val acc = 0.0024719536304473877
Time execution (tranning): 143.148621 seconds 
Time execution (load saved model): 0.003278 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

8.69453177529067e-06

num_try : 486 | val_loss = 8.69453177529067e-06 | val acc = 0.0025081445928663015
Time execution (tranning): 180.882211 seconds 
Time execution (load saved model): 0.003188 seconds 
Time execution (use saved model): 0.000296 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 332
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.696213371877093e-06

num_try : 561 | val_loss = 8.696213371877093e-06 | val acc = 0.0025651538744568825
Time execution (tranning): 138.230339 seconds 
Time execution (load saved model): 0.003300 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.764340773268486e-06

num_try : 98 | val_loss = 8.764340773268486e-06 | val acc = 0.0024297458585351706
Time execution (tranning): 69.797086 seconds 
Time execution (load saved model): 0.002349 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 166
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.771121902100276e-06

num_try : 357 | val_loss = 8.771121902100276e-06 | val acc = 0.0024345130659639835
Time execution (tranning): 125.795389 seconds 
Time execution (load saved model): 0.002461 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.77935710377642e-06

num_try : 464 | val_loss = 8.77935710377642e-06 | val acc = 0.0024991612881422043
Time execution (tranning): 106.883893 seconds 
Time execution (load saved model): 0.002607 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

8.804808940112708e-06

num_try : 180 | val_loss = 8.804808940112708e-06 | val acc = 0.002637891098856926
Time execution (tranning): 110.769433 seconds 
Time execution (load saved model): 0.002397 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.839654660732777e-06

num_try : 96 | val_loss = 8.839654660732777e-06 | val acc = 0.00251994701102376
Time execution (tranning): 71.490613 seconds 
Time execution (load saved model): 0.002312 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 173
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.875632552189927e-06

num_try : 441 | val_loss = 8.875632552189927e-06 | val acc = 0.0025264581199735403
Time execution (tranning): 107.284072 seconds 
Time execution (load saved model): 0.002674 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.878853273017739e-06

num_try : 510 | val_loss = 8.878853273017739e-06 | val acc = 0.0025082528591156006
Time execution (tranning): 190.220749 seconds 
Time execution (load saved model): 0.003212 seconds 
Time execution (use saved model): 0.000301 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 346
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.925911288315547e-06

num_try : 169 | val_loss = 8.925911288315547e-06 | val acc = 0.002503305906429887
Time execution (tranning): 91.603167 seconds 
Time execution (load saved model): 0.002288 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

8.948635199885757e-06

num_try : 528 | val_loss = 8.948635199885757e-06 | val acc = 0.0023417267948389053
Time execution (tranning): 172.233553 seconds 
Time execution (load saved model): 0.003205 seconds 
Time execution (use saved model): 0.000304 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 326
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

8.963651098383706e-06

num_try : 549 | val_loss = 8.963651098383706e-06 | val acc = 0.0023911469615995884
Time execution (tranning): 138.604738 seconds 
Time execution (load saved model): 0.003304 seconds 
Time execution (use saved model): 0.000320 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

8.998188682198816e-06

num_try : 125 | val_loss = 8.998188682198816e-06 | val acc = 0.0025418242439627647
Time execution (tranning): 112.561642 seconds 
Time execution (load saved model): 0.002383 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.001091088975954e-06

num_try : 280 | val_loss = 9.001091088975954e-06 | val acc = 0.002283152425661683
Time execution (tranning): 110.481981 seconds 
Time execution (load saved model): 0.002317 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.013563708322181e-06

num_try : 538 | val_loss = 9.013563708322181e-06 | val acc = 0.002459856914356351
Time execution (tranning): 147.405786 seconds 
Time execution (load saved model): 0.003386 seconds 
Time execution (use saved model): 0.000323 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.024107557706884e-06

num_try : 474 | val_loss = 9.024107557706884e-06 | val acc = 0.0024420281406491995
Time execution (tranning): 140.250019 seconds 
Time execution (load saved model): 0.002527 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 294
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.042152196343523e-06

num_try : 209 | val_loss = 9.042152196343523e-06 | val acc = 0.0023737025912851095
Time execution (tranning): 103.233135 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 242
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.045936708389491e-06

num_try : 393 | val_loss = 9.045936708389491e-06 | val acc = 0.002612758195027709
Time execution (tranning): 88.111880 seconds 
Time execution (load saved model): 0.002584 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.057683446371811e-06

num_try : 344 | val_loss = 9.057683446371811e-06 | val acc = 0.0025119001511484385
Time execution (tranning): 168.393141 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 375
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.080282979994082e-06

num_try : 397 | val_loss = 9.080282979994082e-06 | val acc = 0.00221348088234663
Time execution (tranning): 86.611263 seconds 
Time execution (load saved model): 0.002545 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 190
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.152835627901367e-06

num_try : 573 | val_loss = 9.152835627901367e-06 | val acc = 0.002628239104524255
Time execution (tranning): 99.349070 seconds 
Time execution (load saved model): 0.003350 seconds 
Time execution (use saved model): 0.000320 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 176
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.160591221188951e-06

num_try : 343 | val_loss = 9.160591221188951e-06 | val acc = 0.002533441176638007
Time execution (tranning): 120.060682 seconds 
Time execution (load saved model): 0.002375 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 274
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.179168191622011e-06

num_try : 403 | val_loss = 9.179168191622011e-06 | val acc = 0.002666718326508999
Time execution (tranning): 145.590788 seconds 
Time execution (load saved model): 0.002539 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.211484189108887e-06

num_try : 483 | val_loss = 9.211484189108887e-06 | val acc = 0.002347588771954179
Time execution (tranning): 104.925030 seconds 
Time execution (load saved model): 0.003216 seconds 
Time execution (use saved model): 0.000307 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.247807470273984e-06

num_try : 395 | val_loss = 9.247807470273984e-06 | val acc = 0.0024454561062157154
Time execution (tranning): 89.479172 seconds 
Time execution (load saved model): 0.002514 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.285136875405443e-06

num_try : 556 | val_loss = 9.285136875405443e-06 | val acc = 0.002592073054984212
Time execution (tranning): 130.364267 seconds 
Time execution (load saved model): 0.003283 seconds 
Time execution (use saved model): 0.000303 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.289900544899865e-06

num_try : 295 | val_loss = 9.289900544899865e-06 | val acc = 0.0025540634524077177
Time execution (tranning): 83.175069 seconds 
Time execution (load saved model): 0.002456 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.291175920225215e-06

num_try : 299 | val_loss = 9.291175920225215e-06 | val acc = 0.0026051837485283613
Time execution (tranning): 102.386528 seconds 
Time execution (load saved model): 0.002408 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.306817087235686e-06

num_try : 507 | val_loss = 9.306817087235686e-06 | val acc = 0.0023953758645802736
Time execution (tranning): 97.554789 seconds 
Time execution (load saved model): 0.003246 seconds 
Time execution (use saved model): 0.000307 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.308597354902303e-06

num_try : 515 | val_loss = 9.308597354902303e-06 | val acc = 0.0025334046222269535
Time execution (tranning): 113.031578 seconds 
Time execution (load saved model): 0.003206 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.30962696656934e-06

num_try : 416 | val_loss = 9.30962696656934e-06 | val acc = 0.002555271377786994
Time execution (tranning): 105.951674 seconds 
Time execution (load saved model): 0.002657 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 217
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.320417379967694e-06

num_try : 414 | val_loss = 9.320417379967694e-06 | val acc = 0.002639040118083358
Time execution (tranning): 101.039332 seconds 
Time execution (load saved model): 0.002714 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.362930404677172e-06

num_try : 50 | val_loss = 9.362930404677172e-06 | val acc = 0.0028607177082449198
Time execution (tranning): 128.958962 seconds 
Time execution (load saved model): 0.002327 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 311
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.369614081151668e-06

num_try : 371 | val_loss = 9.369614081151668e-06 | val acc = 0.0025426491629332304
Time execution (tranning): 169.632476 seconds 
Time execution (load saved model): 0.002351 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 379
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.408016558154486e-06

num_try : 346 | val_loss = 9.408016558154486e-06 | val acc = 0.0026969811879098415
Time execution (tranning): 123.104561 seconds 
Time execution (load saved model): 0.002339 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 272
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.46820067383669e-06

num_try : 443 | val_loss = 9.46820067383669e-06 | val acc = 0.0025805162731558084
Time execution (tranning): 153.965899 seconds 
Time execution (load saved model): 0.002536 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.477671574131818e-06

num_try : 366 | val_loss = 9.477671574131818e-06 | val acc = 0.002618777798488736
Time execution (tranning): 119.100693 seconds 
Time execution (load saved model): 0.002435 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.492923049947422e-06

num_try : 504 | val_loss = 9.492923049947422e-06 | val acc = 0.002453565364703536
Time execution (tranning): 143.376659 seconds 
Time execution (load saved model): 0.003232 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

9.513495174360286e-06

num_try : 321 | val_loss = 9.513495174360286e-06 | val acc = 0.0027054930105805397
Time execution (tranning): 129.876800 seconds 
Time execution (load saved model): 0.002421 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 291
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.513936747680418e-06

num_try : 451 | val_loss = 9.513936747680418e-06 | val acc = 0.0024610606487840414
Time execution (tranning): 149.933018 seconds 
Time execution (load saved model): 0.002757 seconds 
Time execution (use saved model): 0.000289 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 312
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.532161784591154e-06

num_try : 172 | val_loss = 9.532161784591154e-06 | val acc = 0.0025992945302277803
Time execution (tranning): 123.091550 seconds 
Time execution (load saved model): 0.002279 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 292
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.537077353343193e-06

num_try : 405 | val_loss = 9.537077353343193e-06 | val acc = 0.0025085348170250654
Time execution (tranning): 126.247993 seconds 
Time execution (load saved model): 0.002528 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 259
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.540469909552484e-06

num_try : 185 | val_loss = 9.540469909552484e-06 | val acc = 0.002648816676810384
Time execution (tranning): 124.376815 seconds 
Time execution (load saved model): 0.002272 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.541374938635271e-06

num_try : 499 | val_loss = 9.541374938635271e-06 | val acc = 0.0024828899186104536
Time execution (tranning): 177.453912 seconds 
Time execution (load saved model): 0.003470 seconds 
Time execution (use saved model): 0.000340 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 316
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.65111293226073e-06

num_try : 475 | val_loss = 9.65111293226073e-06 | val acc = 0.002590086543932557
Time execution (tranning): 144.268025 seconds 
Time execution (load saved model): 0.002525 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 303
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.726159923957311e-06

num_try : 304 | val_loss = 9.726159923957311e-06 | val acc = 0.002249983139336109
Time execution (tranning): 88.863252 seconds 
Time execution (load saved model): 0.002393 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 202
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.742665461089929e-06

num_try : 333 | val_loss = 9.742665461089929e-06 | val acc = 0.0025883771013468504
Time execution (tranning): 91.085553 seconds 
Time execution (load saved model): 0.002378 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.772085832082666e-06

num_try : 161 | val_loss = 9.772085832082666e-06 | val acc = 0.0027076241094619036
Time execution (tranning): 107.757926 seconds 
Time execution (load saved model): 0.002433 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.801230607990874e-06

num_try : 481 | val_loss = 9.801230607990874e-06 | val acc = 0.0025028937961906195
Time execution (tranning): 102.223741 seconds 
Time execution (load saved model): 0.003248 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.839098747761455e-06

num_try : 513 | val_loss = 9.839098747761455e-06 | val acc = 0.002525585237890482
Time execution (tranning): 164.874971 seconds 
Time execution (load saved model): 0.003227 seconds 
Time execution (use saved model): 0.000306 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.869827663351315e-06

num_try : 380 | val_loss = 9.869827663351315e-06 | val acc = 0.0025043224450200796
Time execution (tranning): 90.674151 seconds 
Time execution (load saved model): 0.002343 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

9.889506618492305e-06

num_try : 319 | val_loss = 9.889506618492305e-06 | val acc = 0.0027543031610548496
Time execution (tranning): 69.118105 seconds 
Time execution (load saved model): 0.002361 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 157
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

9.900304175971542e-06

num_try : 537 | val_loss = 9.900304175971542e-06 | val acc = 0.002681402489542961
Time execution (tranning): 166.189475 seconds 
Time execution (load saved model): 0.003273 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

9.900654836201284e-06

num_try : 479 | val_loss = 9.900654836201284e-06 | val acc = 0.0024382262490689754
Time execution (tranning): 113.661255 seconds 
Time execution (load saved model): 0.002544 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

9.937140330293914e-06

num_try : 334 | val_loss = 9.937140330293914e-06 | val acc = 0.002608486684039235
Time execution (tranning): 82.291089 seconds 
Time execution (load saved model): 0.002384 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

9.967785617845947e-06

num_try : 121 | val_loss = 9.967785617845947e-06 | val acc = 0.002529562683776021
Time execution (tranning): 92.654216 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 227
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0003562560996216e-05

num_try : 462 | val_loss = 1.0003562560996216e-05 | val acc = 0.002596092876046896
Time execution (tranning): 93.230450 seconds 
Time execution (load saved model): 0.002555 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0031940178123477e-05

num_try : 338 | val_loss = 1.0031940178123477e-05 | val acc = 0.0024738474749028683
Time execution (tranning): 101.445734 seconds 
Time execution (load saved model): 0.002426 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0119691032741685e-05

num_try : 72 | val_loss = 1.0119691032741685e-05 | val acc = 0.0029379096813499928
Time execution (tranning): 102.728471 seconds 
Time execution (load saved model): 0.002288 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0155196778214303e-05

num_try : 24 | val_loss = 1.0155196778214303e-05 | val acc = 0.0028999780770391226
Time execution (tranning): 98.190392 seconds 
Time execution (load saved model): 0.002309 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0186742447331198e-05

num_try : 323 | val_loss = 1.0186742447331198e-05 | val acc = 0.002658063778653741
Time execution (tranning): 97.586813 seconds 
Time execution (load saved model): 0.002388 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0196644420830126e-05

num_try : 563 | val_loss = 1.0196644420830126e-05 | val acc = 0.0026919981464743614
Time execution (tranning): 134.117893 seconds 
Time execution (load saved model): 0.003407 seconds 
Time execution (use saved model): 0.000320 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0219662908639292e-05

num_try : 5 | val_loss = 1.0219662908639292e-05 | val acc = 0.0028956327587366104
Time execution (tranning): 103.329687 seconds 
Time execution (load saved model): 0.002259 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 252
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.022247677155974e-05

num_try : 294 | val_loss = 1.022247677155974e-05 | val acc = 0.002656753873452544
Time execution (tranning): 106.538428 seconds 
Time execution (load saved model): 0.002399 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0260214930895017e-05

num_try : 307 | val_loss = 1.0260214930895017e-05 | val acc = 0.0026980768889188766
Time execution (tranning): 110.643092 seconds 
Time execution (load saved model): 0.002401 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0271381420352554e-05

num_try : 427 | val_loss = 1.0271381420352554e-05 | val acc = 0.002511259401217103
Time execution (tranning): 102.094033 seconds 
Time execution (load saved model): 0.002536 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 216
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0273396464981487e-05

num_try : 551 | val_loss = 1.0273396464981487e-05 | val acc = 0.0023380578495562077
Time execution (tranning): 104.596627 seconds 
Time execution (load saved model): 0.003256 seconds 
Time execution (use saved model): 0.000316 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 186
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0303753078915179e-05

num_try : 454 | val_loss = 1.0303753078915179e-05 | val acc = 0.0026445023249834776
Time execution (tranning): 106.938869 seconds 
Time execution (load saved model): 0.002610 seconds 
Time execution (use saved model): 0.000270 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 218
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0357556830058456e-05

num_try : 391 | val_loss = 1.0357556830058456e-05 | val acc = 0.0026821973733603954
Time execution (tranning): 106.619560 seconds 
Time execution (load saved model): 0.002519 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0386446101620095e-05

num_try : 455 | val_loss = 1.0386446101620095e-05 | val acc = 0.0026144853327423334
Time execution (tranning): 108.433778 seconds 
Time execution (load saved model): 0.002580 seconds 
Time execution (use saved model): 0.000273 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.038938023157243e-05

num_try : 2 | val_loss = 1.038938023157243e-05 | val acc = 0.0030121379531919956
Time execution (tranning): 139.567369 seconds 
Time execution (load saved model): 0.002284 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 341
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0426100125187077e-05

num_try : 170 | val_loss = 1.0426100125187077e-05 | val acc = 0.002763218479231
Time execution (tranning): 72.536502 seconds 
Time execution (load saved model): 0.002276 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 171
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.045937282469822e-05

num_try : 183 | val_loss = 1.045937282469822e-05 | val acc = 0.0026072771288454533
Time execution (tranning): 133.847669 seconds 
Time execution (load saved model): 0.002305 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 317
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0492897449694284e-05

num_try : 477 | val_loss = 1.0492897449694284e-05 | val acc = 0.00249420921318233
Time execution (tranning): 92.664152 seconds 
Time execution (load saved model): 0.002491 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0517168079786644e-05

num_try : 345 | val_loss = 1.0517168079786644e-05 | val acc = 0.002720558550208807
Time execution (tranning): 163.368059 seconds 
Time execution (load saved model): 0.002334 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 363
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0537893244872975e-05

num_try : 428 | val_loss = 1.0537893244872975e-05 | val acc = 0.002509565092623234
Time execution (tranning): 83.568382 seconds 
Time execution (load saved model): 0.002667 seconds 
Time execution (use saved model): 0.000282 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 171
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0542119807723794e-05

num_try : 308 | val_loss = 1.0542119807723794e-05 | val acc = 0.0027272782754153013
Time execution (tranning): 98.538364 seconds 
Time execution (load saved model): 0.002357 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 216
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.054650179867167e-05

num_try : 27 | val_loss = 1.054650179867167e-05 | val acc = 0.00295834057033062
Time execution (tranning): 94.453210 seconds 
Time execution (load saved model): 0.002269 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0559384340922407e-05

num_try : 231 | val_loss = 1.0559384340922407e-05 | val acc = 0.0024583449121564627
Time execution (tranning): 100.875833 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0578073570286506e-05

num_try : 465 | val_loss = 1.0578073570286506e-05 | val acc = 0.002889103488996625
Time execution (tranning): 111.192859 seconds 
Time execution (load saved model): 0.002564 seconds 
Time execution (use saved model): 0.000272 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0581369579085731e-05

num_try : 347 | val_loss = 1.0581369579085731e-05 | val acc = 0.0026808909606188536
Time execution (tranning): 136.947585 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0601428348309128e-05

num_try : 3 | val_loss = 1.0601428348309128e-05 | val acc = 0.00301792798563838
Time execution (tranning): 88.717519 seconds 
Time execution (load saved model): 0.002264 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0656037275111885e-05

num_try : 484 | val_loss = 1.0656037275111885e-05 | val acc = 0.0028240543324500322
Time execution (tranning): 129.874411 seconds 
Time execution (load saved model): 0.003326 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.066309598627413e-05

num_try : 476 | val_loss = 1.066309598627413e-05 | val acc = 0.002515987725928426
Time execution (tranning): 136.405554 seconds 
Time execution (load saved model): 0.002502 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0689040827855933e-05

num_try : 355 | val_loss = 1.0689040827855933e-05 | val acc = 0.0027196835726499557
Time execution (tranning): 81.936025 seconds 
Time execution (load saved model): 0.002382 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.069522764737485e-05

num_try : 331 | val_loss = 1.069522764737485e-05 | val acc = 0.002608364447951317
Time execution (tranning): 81.411478 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.070883122338273e-05

num_try : 335 | val_loss = 1.070883122338273e-05 | val acc = 0.002667592139914632
Time execution (tranning): 105.057971 seconds 
Time execution (load saved model): 0.002329 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.0710252504395611e-05

num_try : 322 | val_loss = 1.0710252504395611e-05 | val acc = 0.0027004205621778965
Time execution (tranning): 85.601873 seconds 
Time execution (load saved model): 0.002359 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0759238762148016e-05

num_try : 392 | val_loss = 1.0759238762148016e-05 | val acc = 0.002750409534201026
Time execution (tranning): 115.043480 seconds 
Time execution (load saved model): 0.002535 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0772866471597808e-05

num_try : 356 | val_loss = 1.0772866471597808e-05 | val acc = 0.002656495664268732
Time execution (tranning): 102.240463 seconds 
Time execution (load saved model): 0.002342 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0875402667807065e-05

num_try : 514 | val_loss = 1.0875402667807065e-05 | val acc = 0.0026968815363943577
Time execution (tranning): 120.305243 seconds 
Time execution (load saved model): 0.003304 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.0907864771070308e-05

num_try : 536 | val_loss = 1.0907864771070308e-05 | val acc = 0.0027770567685365677
Time execution (tranning): 111.377791 seconds 
Time execution (load saved model): 0.003481 seconds 
Time execution (use saved model): 0.000339 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.0908167892011989e-05

num_try : 378 | val_loss = 1.0908167892011989e-05 | val acc = 0.0026347371749579906
Time execution (tranning): 127.804677 seconds 
Time execution (load saved model): 0.002310 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 291
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0928808114840649e-05

num_try : 51 | val_loss = 1.0928808114840649e-05 | val acc = 0.0030599164310842752
Time execution (tranning): 84.413010 seconds 
Time execution (load saved model): 0.002265 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 203
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.0956991100101731e-05

num_try : 379 | val_loss = 1.0956991100101731e-05 | val acc = 0.002814880106598139
Time execution (tranning): 77.760407 seconds 
Time execution (load saved model): 0.002345 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 177
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.0960363206322653e-05

num_try : 438 | val_loss = 1.0960363206322653e-05 | val acc = 0.0027570598758757114
Time execution (tranning): 127.160953 seconds 
Time execution (load saved model): 0.002548 seconds 
Time execution (use saved model): 0.000271 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0972532463711104e-05

num_try : 318 | val_loss = 1.0972532463711104e-05 | val acc = 0.0029605699237436056
Time execution (tranning): 100.933656 seconds 
Time execution (load saved model): 0.002331 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.0982257281284547e-05

num_try : 559 | val_loss = 1.0982257281284547e-05 | val acc = 0.0027563348412513733
Time execution (tranning): 100.131414 seconds 
Time execution (load saved model): 0.003276 seconds 
Time execution (use saved model): 0.000315 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 184
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1042316336897785e-05

num_try : 16 | val_loss = 1.1042316336897785e-05 | val acc = 0.002973707625642419
Time execution (tranning): 126.303512 seconds 
Time execution (load saved model): 0.002233 seconds 
Time execution (use saved model): 0.000245 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.106118653297017e-05

num_try : 442 | val_loss = 1.106118653297017e-05 | val acc = 0.0027849941980093718
Time execution (tranning): 100.131538 seconds 
Time execution (load saved model): 0.002696 seconds 
Time execution (use saved model): 0.000279 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.114170602249942e-05

num_try : 562 | val_loss = 1.114170602249942e-05 | val acc = 0.002693969290703535
Time execution (tranning): 181.881474 seconds 
Time execution (load saved model): 0.003260 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 323
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1242737646171008e-05

num_try : 574 | val_loss = 1.1242737646171008e-05 | val acc = 0.0027232205029577017
Time execution (tranning): 89.133512 seconds 
Time execution (load saved model): 0.003338 seconds 
Time execution (use saved model): 0.000317 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 159
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1270038594375365e-05

num_try : 246 | val_loss = 1.1270038594375365e-05 | val acc = 0.0029288399964571
Time execution (tranning): 118.394279 seconds 
Time execution (load saved model): 0.002315 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 275
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.127578800151241e-05

num_try : 298 | val_loss = 1.127578800151241e-05 | val acc = 0.002768676495179534
Time execution (tranning): 96.279822 seconds 
Time execution (load saved model): 0.002335 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1276133100182052e-05

num_try : 383 | val_loss = 1.1276133100182052e-05 | val acc = 0.0028239237144589424
Time execution (tranning): 101.635033 seconds 
Time execution (load saved model): 0.002469 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 224
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1293891157038161e-05

num_try : 535 | val_loss = 1.1293891157038161e-05 | val acc = 0.0028724486473947763
Time execution (tranning): 159.474660 seconds 
Time execution (load saved model): 0.003209 seconds 
Time execution (use saved model): 0.000311 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.13105048876605e-05

num_try : 52 | val_loss = 1.13105048876605e-05 | val acc = 0.0030522355809807777
Time execution (tranning): 85.403630 seconds 
Time execution (load saved model): 0.002264 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1329765875416342e-05

num_try : 523 | val_loss = 1.1329765875416342e-05 | val acc = 0.0025191314052790403
Time execution (tranning): 155.256860 seconds 
Time execution (load saved model): 0.003234 seconds 
Time execution (use saved model): 0.000303 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1406677158447565e-05

num_try : 367 | val_loss = 1.1406677158447565e-05 | val acc = 0.002965119667351246
Time execution (tranning): 115.762613 seconds 
Time execution (load saved model): 0.002329 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 261
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1477287771413102e-05

num_try : 491 | val_loss = 1.1477287771413102e-05 | val acc = 0.0029205295722931623
Time execution (tranning): 156.427123 seconds 
Time execution (load saved model): 0.003245 seconds 
Time execution (use saved model): 0.000312 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 279
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1542497977643507e-05

num_try : 77 | val_loss = 1.1542497977643507e-05 | val acc = 0.0030841915868222713
Time execution (tranning): 94.590964 seconds 
Time execution (load saved model): 0.002282 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 226
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.1610135552473365e-05

num_try : 1 | val_loss = 1.1610135552473365e-05 | val acc = 0.0030343839898705482
Time execution (tranning): 107.577043 seconds 
Time execution (load saved model): 0.002250 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1685249228321482e-05

num_try : 73 | val_loss = 1.1685249228321482e-05 | val acc = 0.0030311252921819687
Time execution (tranning): 98.947067 seconds 
Time execution (load saved model): 0.002253 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1696612236846704e-05

num_try : 330 | val_loss = 1.1696612236846704e-05 | val acc = 0.0026824939996004105
Time execution (tranning): 80.813182 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 184
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.1724362284439849e-05

num_try : 198 | val_loss = 1.1724362284439849e-05 | val acc = 0.0030270821880549192
Time execution (tranning): 104.795881 seconds 
Time execution (load saved model): 0.002340 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.1752559357773862e-05

num_try : 260 | val_loss = 1.1752559357773862e-05 | val acc = 0.0030229028780013323
Time execution (tranning): 149.798899 seconds 
Time execution (load saved model): 0.002313 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 342
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1755159030144568e-05

num_try : 439 | val_loss = 1.1755159030144568e-05 | val acc = 0.002831114223226905
Time execution (tranning): 140.381973 seconds 
Time execution (load saved model): 0.002575 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 294
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1756426638385164e-05

num_try : 368 | val_loss = 1.1756426638385164e-05 | val acc = 0.0028726481832563877
Time execution (tranning): 151.758790 seconds 
Time execution (load saved model): 0.002365 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 335
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.1778792318182241e-05

num_try : 394 | val_loss = 1.1778792318182241e-05 | val acc = 0.002740699565038085
Time execution (tranning): 112.768453 seconds 
Time execution (load saved model): 0.002609 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1827661319330219e-05

num_try : 26 | val_loss = 1.1827661319330219e-05 | val acc = 0.0031320315320044756
Time execution (tranning): 106.043508 seconds 
Time execution (load saved model): 0.002287 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.185350911327987e-05

num_try : 480 | val_loss = 1.185350911327987e-05 | val acc = 0.0027794847264885902
Time execution (tranning): 130.485418 seconds 
Time execution (load saved model): 0.003285 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.1867746134157641e-05

num_try : 4 | val_loss = 1.1867746134157641e-05 | val acc = 0.003182966960594058
Time execution (tranning): 71.856282 seconds 
Time execution (load saved model): 0.002274 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 176
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1877389251822024e-05

num_try : 49 | val_loss = 1.1877389251822024e-05 | val acc = 0.003032210748642683
Time execution (tranning): 115.080995 seconds 
Time execution (load saved model): 0.002264 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 283
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.1891281637872453e-05

num_try : 13 | val_loss = 1.1891281637872453e-05 | val acc = 0.0031379228457808495
Time execution (tranning): 133.204741 seconds 
Time execution (load saved model): 0.002342 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 327
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.19586330401944e-05

num_try : 310 | val_loss = 1.19586330401944e-05 | val acc = 0.002961660735309124
Time execution (tranning): 102.274437 seconds 
Time execution (load saved model): 0.002433 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.1995938866675715e-05

num_try : 473 | val_loss = 1.1995938866675715e-05 | val acc = 0.002459799638018012
Time execution (tranning): 85.138706 seconds 
Time execution (load saved model): 0.002542 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 181
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2036000280204462e-05

num_try : 197 | val_loss = 1.2036000280204462e-05 | val acc = 0.0027455813251435757
Time execution (tranning): 74.160913 seconds 
Time execution (load saved model): 0.002388 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 173
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2081865597792785e-05

num_try : 311 | val_loss = 1.2081865597792785e-05 | val acc = 0.002844876376911998
Time execution (tranning): 102.794989 seconds 
Time execution (load saved model): 0.002456 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2144355878263013e-05

num_try : 237 | val_loss = 1.2144355878263013e-05 | val acc = 0.003115664701908827
Time execution (tranning): 108.589851 seconds 
Time execution (load saved model): 0.002378 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 247
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2183012568129925e-05

num_try : 286 | val_loss = 1.2183012568129925e-05 | val acc = 0.0029313326813280582
Time execution (tranning): 86.849714 seconds 
Time execution (load saved model): 0.002286 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.220229207774537e-05

num_try : 359 | val_loss = 1.220229207774537e-05 | val acc = 0.002840905450284481
Time execution (tranning): 94.178844 seconds 
Time execution (load saved model): 0.002446 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2226475801071502e-05

num_try : 547 | val_loss = 1.2226475801071502e-05 | val acc = 0.0027820421382784843
Time execution (tranning): 143.177119 seconds 
Time execution (load saved model): 0.003266 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.2246805026734364e-05

num_try : 210 | val_loss = 1.2246805026734364e-05 | val acc = 0.0029525146819651127
Time execution (tranning): 99.343197 seconds 
Time execution (load saved model): 0.002327 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.229275850164413e-05

num_try : 17 | val_loss = 1.229275850164413e-05 | val acc = 0.0032135574147105217
Time execution (tranning): 100.537618 seconds 
Time execution (load saved model): 0.002258 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2308351733736344e-05

num_try : 200 | val_loss = 1.2308351733736344e-05 | val acc = 0.003071750979870558
Time execution (tranning): 104.784813 seconds 
Time execution (load saved model): 0.002327 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 238
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.2382883669488365e-05

num_try : 224 | val_loss = 1.2382883669488365e-05 | val acc = 0.0030908468179404736
Time execution (tranning): 96.026882 seconds 
Time execution (load saved model): 0.002288 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.239840395101055e-05

num_try : 113 | val_loss = 1.239840395101055e-05 | val acc = 0.0029478587675839663
Time execution (tranning): 98.906258 seconds 
Time execution (load saved model): 0.002244 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2422890367815853e-05

num_try : 48 | val_loss = 1.2422890367815853e-05 | val acc = 0.003156641498208046
Time execution (tranning): 78.866461 seconds 
Time execution (load saved model): 0.002334 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2458348919608397e-05

num_try : 354 | val_loss = 1.2458348919608397e-05 | val acc = 0.002858855528756976
Time execution (tranning): 107.728151 seconds 
Time execution (load saved model): 0.002386 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 244
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2550842429845943e-05

num_try : 487 | val_loss = 1.2550842429845943e-05 | val acc = 0.0029930684249848127
Time execution (tranning): 115.061178 seconds 
Time execution (load saved model): 0.003185 seconds 
Time execution (use saved model): 0.000298 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.2577812012750656e-05

num_try : 53 | val_loss = 1.2577812012750656e-05 | val acc = 0.0029562923591583967
Time execution (tranning): 111.118988 seconds 
Time execution (load saved model): 0.002225 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2636254068638663e-05

num_try : 534 | val_loss = 1.2636254068638663e-05 | val acc = 0.0029555903747677803
Time execution (tranning): 128.550920 seconds 
Time execution (load saved model): 0.003197 seconds 
Time execution (use saved model): 0.000304 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2653204321395605e-05

num_try : 485 | val_loss = 1.2653204321395605e-05 | val acc = 0.0028668432496488094
Time execution (tranning): 145.124558 seconds 
Time execution (load saved model): 0.003273 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 274
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2668445633607916e-05

num_try : 84 | val_loss = 1.2668445633607916e-05 | val acc = 0.0032869887072592974
Time execution (tranning): 137.294138 seconds 
Time execution (load saved model): 0.002292 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 337
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2701226096396567e-05

num_try : 14 | val_loss = 1.2701226096396567e-05 | val acc = 0.0030473186634480953
Time execution (tranning): 129.767997 seconds 
Time execution (load saved model): 0.002240 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 313
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.2702312060355326e-05

num_try : 75 | val_loss = 1.2702312060355326e-05 | val acc = 0.003144519403576851
Time execution (tranning): 71.146333 seconds 
Time execution (load saved model): 0.002273 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 170
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2772994600709354e-05

num_try : 297 | val_loss = 1.2772994600709354e-05 | val acc = 0.002800719114020467
Time execution (tranning): 96.646663 seconds 
Time execution (load saved model): 0.002394 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.2786044708263944e-05

num_try : 251 | val_loss = 1.2786044708263944e-05 | val acc = 0.003109344281256199
Time execution (tranning): 141.345077 seconds 
Time execution (load saved model): 0.002282 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2819111625503864e-05

num_try : 270 | val_loss = 1.2819111625503864e-05 | val acc = 0.0030437838286161423
Time execution (tranning): 100.287734 seconds 
Time execution (load saved model): 0.002387 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2836444911954458e-05

num_try : 287 | val_loss = 1.2836444911954458e-05 | val acc = 0.0030997723806649446
Time execution (tranning): 166.696243 seconds 
Time execution (load saved model): 0.002426 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 379
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.2902336229672074e-05

num_try : 222 | val_loss = 1.2902336229672074e-05 | val acc = 0.003105417126789689
Time execution (tranning): 98.869174 seconds 
Time execution (load saved model): 0.002346 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.2930275643157074e-05

num_try : 262 | val_loss = 1.2930275643157074e-05 | val acc = 0.0029733029659837484
Time execution (tranning): 115.476236 seconds 
Time execution (load saved model): 0.002308 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.2937024439452217e-05

num_try : 248 | val_loss = 1.2937024439452217e-05 | val acc = 0.0031275067012757063
Time execution (tranning): 100.620037 seconds 
Time execution (load saved model): 0.002397 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 227
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3008103956053673e-05

num_try : 511 | val_loss = 1.3008103956053673e-05 | val acc = 0.0027556067798286676
Time execution (tranning): 108.584839 seconds 
Time execution (load saved model): 0.003288 seconds 
Time execution (use saved model): 0.000308 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 197
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3068817625025985e-05

num_try : 342 | val_loss = 1.3068817625025985e-05 | val acc = 0.0030385933350771666
Time execution (tranning): 103.147730 seconds 
Time execution (load saved model): 0.002350 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 236
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3071575658614165e-05

num_try : 272 | val_loss = 1.3071575658614165e-05 | val acc = 0.0031355067621916533
Time execution (tranning): 105.214782 seconds 
Time execution (load saved model): 0.002330 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3077712792437523e-05

num_try : 211 | val_loss = 1.3077712792437523e-05 | val acc = 0.0030960827134549618
Time execution (tranning): 83.761328 seconds 
Time execution (load saved model): 0.002427 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 196
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3082841132927569e-05

num_try : 489 | val_loss = 1.3082841132927569e-05 | val acc = 0.00278185005299747
Time execution (tranning): 167.057692 seconds 
Time execution (load saved model): 0.003202 seconds 
Time execution (use saved model): 0.000303 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 297
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.3083611047477462e-05

num_try : 250 | val_loss = 1.3083611047477462e-05 | val acc = 0.003138310508802533
Time execution (tranning): 129.354102 seconds 
Time execution (load saved model): 0.002316 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 299
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.3190569916332606e-05

num_try : 320 | val_loss = 1.3190569916332606e-05 | val acc = 0.002932845614850521
Time execution (tranning): 94.308613 seconds 
Time execution (load saved model): 0.002344 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 209
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.319767438872077e-05

num_try : 234 | val_loss = 1.319767438872077e-05 | val acc = 0.0031391242519021034
Time execution (tranning): 111.880013 seconds 
Time execution (load saved model): 0.002434 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 263
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3201753681642003e-05

num_try : 236 | val_loss = 1.3201753681642003e-05 | val acc = 0.0031592906452715397
Time execution (tranning): 78.792359 seconds 
Time execution (load saved model): 0.002435 seconds 
Time execution (use saved model): 0.000268 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 178
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3260663117762305e-05

num_try : 418 | val_loss = 1.3260663117762305e-05 | val acc = 0.0029042852111160755
Time execution (tranning): 103.723129 seconds 
Time execution (load saved model): 0.002610 seconds 
Time execution (use saved model): 0.000275 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.3317012326297118e-05

num_try : 25 | val_loss = 1.3317012326297118e-05 | val acc = 0.0032508810982108116
Time execution (tranning): 100.216475 seconds 
Time execution (load saved model): 0.002289 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3345099177968223e-05

num_try : 38 | val_loss = 1.3345099177968223e-05 | val acc = 0.003222651546820998
Time execution (tranning): 116.410170 seconds 
Time execution (load saved model): 0.002247 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 280
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3370870401558932e-05

num_try : 29 | val_loss = 1.3370870401558932e-05 | val acc = 0.003100075526162982
Time execution (tranning): 87.689515 seconds 
Time execution (load saved model): 0.002284 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.338031264822348e-05

num_try : 199 | val_loss = 1.338031264822348e-05 | val acc = 0.0032054996117949486
Time execution (tranning): 154.397811 seconds 
Time execution (load saved model): 0.002307 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 360
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3406480611592997e-05

num_try : 283 | val_loss = 1.3406480611592997e-05 | val acc = 0.003155170474201441
Time execution (tranning): 94.517621 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.3518171626856202e-05

num_try : 284 | val_loss = 1.3518171626856202e-05 | val acc = 0.003196327481418848
Time execution (tranning): 84.587475 seconds 
Time execution (load saved model): 0.002332 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 192
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.355296914880455e-05

num_try : 41 | val_loss = 1.355296914880455e-05 | val acc = 0.003164156572893262
Time execution (tranning): 110.483414 seconds 
Time execution (load saved model): 0.002315 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.3680093534276239e-05

num_try : 261 | val_loss = 1.3680093534276239e-05 | val acc = 0.0030772853642702103
Time execution (tranning): 91.002331 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 207
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.3683496945304796e-05

num_try : 0 | val_loss = 1.3683496945304796e-05 | val acc = 0.003255599644035101
Time execution (tranning): 93.609771 seconds 
Time execution (load saved model): 0.002247 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3766743413725636e-05

num_try : 36 | val_loss = 1.3766743413725636e-05 | val acc = 0.003184912260621786
Time execution (tranning): 85.840809 seconds 
Time execution (load saved model): 0.002271 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.3795534541714006e-05

num_try : 512 | val_loss = 1.3795534541714006e-05 | val acc = 0.0030964103061705828
Time execution (tranning): 161.412129 seconds 
Time execution (load saved model): 0.003250 seconds 
Time execution (use saved model): 0.000309 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3847799837094498e-05

num_try : 88 | val_loss = 1.3847799837094498e-05 | val acc = 0.003235909156501293
Time execution (tranning): 74.953345 seconds 
Time execution (load saved model): 0.002376 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 175
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.3881023523936164e-05

num_try : 15 | val_loss = 1.3881023523936164e-05 | val acc = 0.0032555751968175173
Time execution (tranning): 127.042748 seconds 
Time execution (load saved model): 0.002246 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 308
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.393157257552957e-05

num_try : 62 | val_loss = 1.393157257552957e-05 | val acc = 0.003165173577144742
Time execution (tranning): 112.457785 seconds 
Time execution (load saved model): 0.002262 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 269
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.3991805735713569e-05

num_try : 86 | val_loss = 1.3991805735713569e-05 | val acc = 0.00326333474367857
Time execution (tranning): 112.578852 seconds 
Time execution (load saved model): 0.002385 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 264
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4055750207262462e-05

num_try : 85 | val_loss = 1.4055750207262462e-05 | val acc = 0.003325867932289839
Time execution (tranning): 109.650372 seconds 
Time execution (load saved model): 0.002390 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4122883158051991e-05

num_try : 122 | val_loss = 1.4122883158051991e-05 | val acc = 0.002911662682890892
Time execution (tranning): 78.473284 seconds 
Time execution (load saved model): 0.002397 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 184
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4137540965748485e-05

num_try : 212 | val_loss = 1.4137540965748485e-05 | val acc = 0.003207193687558174
Time execution (tranning): 198.881480 seconds 
Time execution (load saved model): 0.002412 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 439
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4215056280590943e-05

num_try : 227 | val_loss = 1.4215056280590943e-05 | val acc = 0.0030270880088210106
Time execution (tranning): 73.676927 seconds 
Time execution (load saved model): 0.002301 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 168
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4247207254811655e-05

num_try : 382 | val_loss = 1.4247207254811655e-05 | val acc = 0.002960911951959133
Time execution (tranning): 84.884938 seconds 
Time execution (load saved model): 0.002354 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4283938580774703e-05

num_try : 560 | val_loss = 1.4283938580774703e-05 | val acc = 0.0031278536189347506
Time execution (tranning): 130.768448 seconds 
Time execution (load saved model): 0.003272 seconds 
Time execution (use saved model): 0.000318 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 230
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4341555479404633e-05

num_try : 381 | val_loss = 1.4341555479404633e-05 | val acc = 0.003312282031401992
Time execution (tranning): 57.463973 seconds 
Time execution (load saved model): 0.002382 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 127
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.4353751639646362e-05

num_try : 273 | val_loss = 1.4353751639646362e-05 | val acc = 0.0031851676758378744
Time execution (tranning): 107.935229 seconds 
Time execution (load saved model): 0.002306 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 243
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.440853381609486e-05

num_try : 37 | val_loss = 1.440853381609486e-05 | val acc = 0.003416831837967038
Time execution (tranning): 128.591891 seconds 
Time execution (load saved model): 0.002251 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 319
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.4420018369492026e-05

num_try : 239 | val_loss = 1.4420018369492026e-05 | val acc = 0.0031721240375190973
Time execution (tranning): 113.625684 seconds 
Time execution (load saved model): 0.002391 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4452302821155172e-05

num_try : 274 | val_loss = 1.4452302821155172e-05 | val acc = 0.0032217937987297773
Time execution (tranning): 111.575866 seconds 
Time execution (load saved model): 0.002446 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4455911505137919e-05

num_try : 453 | val_loss = 1.4455911505137919e-05 | val acc = 0.0027529937215149403
Time execution (tranning): 139.682566 seconds 
Time execution (load saved model): 0.002539 seconds 
Time execution (use saved model): 0.000267 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.4525797269016039e-05

num_try : 28 | val_loss = 1.4525797269016039e-05 | val acc = 0.003345971694216132
Time execution (tranning): 93.199182 seconds 
Time execution (load saved model): 0.002380 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4547864120686427e-05

num_try : 74 | val_loss = 1.4547864120686427e-05 | val acc = 0.0032124228309839964
Time execution (tranning): 100.058331 seconds 
Time execution (load saved model): 0.002293 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 240
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4551627782566356e-05

num_try : 539 | val_loss = 1.4551627782566356e-05 | val acc = 0.002859561936929822
Time execution (tranning): 123.349539 seconds 
Time execution (load saved model): 0.003210 seconds 
Time execution (use saved model): 0.000310 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4579212756871129e-05

num_try : 213 | val_loss = 1.4579212756871129e-05 | val acc = 0.0031373423989862204
Time execution (tranning): 81.649559 seconds 
Time execution (load saved model): 0.002385 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 187
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.4652250447397819e-05

num_try : 263 | val_loss = 1.4652250447397819e-05 | val acc = 0.0031567635014653206
Time execution (tranning): 110.789215 seconds 
Time execution (load saved model): 0.002283 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4722566529599135e-05

num_try : 60 | val_loss = 1.4722566529599135e-05 | val acc = 0.0031620643567293882
Time execution (tranning): 115.300315 seconds 
Time execution (load saved model): 0.002262 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 283
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4739332491444657e-05

num_try : 296 | val_loss = 1.4739332491444657e-05 | val acc = 0.0029492550529539585
Time execution (tranning): 96.848009 seconds 
Time execution (load saved model): 0.002343 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 212
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4740346514372505e-05

num_try : 76 | val_loss = 1.4740346514372505e-05 | val acc = 0.0034943395294249058
Time execution (tranning): 71.213203 seconds 
Time execution (load saved model): 0.002252 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 170
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.4776560856262222e-05

num_try : 332 | val_loss = 1.4776560856262222e-05 | val acc = 0.0029526115395128727
Time execution (tranning): 124.926213 seconds 
Time execution (load saved model): 0.002395 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 277
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

1.4815013337283744e-05

num_try : 430 | val_loss = 1.4815013337283744e-05 | val acc = 0.0028198049403727055
Time execution (tranning): 101.188608 seconds 
Time execution (load saved model): 0.002684 seconds 
Time execution (use saved model): 0.000283 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[256, 256],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 208
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.483946120060864e-05

num_try : 275 | val_loss = 1.483946120060864e-05 | val acc = 0.003185778157785535
Time execution (tranning): 56.862336 seconds 
Time execution (load saved model): 0.002444 seconds 
Time execution (use saved model): 0.000269 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 130
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.4850686848149052e-05

num_try : 306 | val_loss = 1.4850686848149052e-05 | val acc = 0.0029197633266448975
Time execution (tranning): 109.508883 seconds 
Time execution (load saved model): 0.002454 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 249
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.4922466398274992e-05

num_try : 40 | val_loss = 1.4922466398274992e-05 | val acc = 0.003202401101589203
Time execution (tranning): 111.548547 seconds 
Time execution (load saved model): 0.002247 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 268
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.5002241188994959e-05

num_try : 258 | val_loss = 1.5002241188994959e-05 | val acc = 0.0032765797805041075
Time execution (tranning): 89.312907 seconds 
Time execution (load saved model): 0.002311 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.5011629648142843e-05

num_try : 214 | val_loss = 1.5011629648142843e-05 | val acc = 0.003227946348488331
Time execution (tranning): 68.061840 seconds 
Time execution (load saved model): 0.002354 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 155
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.5067025105963695e-05

num_try : 39 | val_loss = 1.5067025105963695e-05 | val acc = 0.003139876527711749
Time execution (tranning): 111.039246 seconds 
Time execution (load saved model): 0.002376 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 255
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.5084791111803498e-05

num_try : 65 | val_loss = 1.5084791111803498e-05 | val acc = 0.0036194610875099897
Time execution (tranning): 119.222332 seconds 
Time execution (load saved model): 0.002255 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 285
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.5143393120524707e-05

num_try : 63 | val_loss = 1.5143393120524707e-05 | val acc = 0.003479539416730404
Time execution (tranning): 116.906201 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 281
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.5191897873592097e-05

num_try : 238 | val_loss = 1.5191897873592097e-05 | val acc = 0.003326956881210208
Time execution (tranning): 120.248812 seconds 
Time execution (load saved model): 0.002374 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 273
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.5262162660292232e-05

num_try : 87 | val_loss = 1.5262162660292232e-05 | val acc = 0.0034274407662451267
Time execution (tranning): 98.569095 seconds 
Time execution (load saved model): 0.002263 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 234
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.534382376121357e-05

num_try : 12 | val_loss = 1.534382376121357e-05 | val acc = 0.003203746397048235
Time execution (tranning): 109.766780 seconds 
Time execution (load saved model): 0.002374 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 271
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.5836341854083004e-05

num_try : 533 | val_loss = 1.5836341854083004e-05 | val acc = 0.003161284839734435
Time execution (tranning): 140.725563 seconds 
Time execution (load saved model): 0.003461 seconds 
Time execution (use saved model): 0.000334 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[512, 512],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 261
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.5932712676658413e-05

num_try : 271 | val_loss = 1.5932712676658413e-05 | val acc = 0.003269579727202654
Time execution (tranning): 93.020054 seconds 
Time execution (load saved model): 0.002352 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 219
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.601982106876676e-05

num_try : 203 | val_loss = 1.601982106876676e-05 | val acc = 0.003380982205271721
Time execution (tranning): 83.567187 seconds 
Time execution (load saved model): 0.002313 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.645500021368207e-05

num_try : 225 | val_loss = 1.645500021368207e-05 | val acc = 0.0033568621147423983
Time execution (tranning): 86.761889 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 199
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.6560731401114025e-05

num_try : 282 | val_loss = 1.6560731401114025e-05 | val acc = 0.003269020700827241
Time execution (tranning): 85.713938 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 201
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.657861630519619e-05

num_try : 247 | val_loss = 1.657861630519619e-05 | val acc = 0.0034182763192802668
Time execution (tranning): 106.867107 seconds 
Time execution (load saved model): 0.002363 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 246
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6590777595411054e-05

num_try : 235 | val_loss = 1.6590777595411054e-05 | val acc = 0.003405188675969839
Time execution (tranning): 118.829838 seconds 
Time execution (load saved model): 0.002296 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 276
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.6763871326475054e-05

num_try : 64 | val_loss = 1.6763871326475054e-05 | val acc = 0.00361280282959342
Time execution (tranning): 131.328645 seconds 
Time execution (load saved model): 0.002336 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 314
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.689581063146761e-05

num_try : 358 | val_loss = 1.689581063146761e-05 | val acc = 0.002913945820182562
Time execution (tranning): 109.869507 seconds 
Time execution (load saved model): 0.002335 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[128, 128],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.717710010780138e-05

num_try : 61 | val_loss = 1.717710010780138e-05 | val acc = 0.003643345320597291
Time execution (tranning): 101.149796 seconds 
Time execution (load saved model): 0.002255 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 248
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.7275782920478377e-05

num_try : 201 | val_loss = 1.7275782920478377e-05 | val acc = 0.003434801008552313
Time execution (tranning): 67.090064 seconds 
Time execution (load saved model): 0.002325 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 154
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.7379813089064554e-05

num_try : 215 | val_loss = 1.7379813089064554e-05 | val acc = 0.0032895870972424746
Time execution (tranning): 101.983097 seconds 
Time execution (load saved model): 0.002361 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.7541416782478335e-05

num_try : 89 | val_loss = 1.7541416782478335e-05 | val acc = 0.003460283624008298
Time execution (tranning): 126.510671 seconds 
Time execution (load saved model): 0.002366 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.0, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 302
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

1.7566661763339654e-05

num_try : 226 | val_loss = 1.7566661763339654e-05 | val acc = 0.003454080317169428
Time execution (tranning): 90.011431 seconds 
Time execution (load saved model): 0.002286 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.792643515727832e-05

num_try : 202 | val_loss = 1.792643515727832e-05 | val acc = 0.0032802759669721127
Time execution (tranning): 89.349475 seconds 
Time execution (load saved model): 0.002306 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.8602429518068674e-05

num_try : 285 | val_loss = 1.8602429518068674e-05 | val acc = 0.003505231812596321
Time execution (tranning): 102.409536 seconds 
Time execution (load saved model): 0.002333 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

1.8891568961407755e-05

num_try : 190 | val_loss = 1.8891568961407755e-05 | val acc = 0.00372685631737113
Time execution (tranning): 109.161380 seconds 
Time execution (load saved model): 0.002345 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 253
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

1.9544856368156616e-05

num_try : 138 | val_loss = 1.9544856368156616e-05 | val acc = 0.003814870025962591
Time execution (tranning): 110.776625 seconds 
Time execution (load saved model): 0.002261 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

1.9738259561563608e-05

num_try : 259 | val_loss = 1.9738259561563608e-05 | val acc = 0.0034448301885277033
Time execution (tranning): 153.856942 seconds 
Time execution (load saved model): 0.002294 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 362
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.9802535198323313e-05

num_try : 223 | val_loss = 1.9802535198323313e-05 | val acc = 0.0036352851893752813
Time execution (tranning): 82.321302 seconds 
Time execution (load saved model): 0.002355 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.9969586219303892e-05

num_try : 163 | val_loss = 1.9969586219303892e-05 | val acc = 0.0038367731031030416
Time execution (tranning): 121.152366 seconds 
Time execution (load saved model): 0.002298 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 289
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

1.9982720696134494e-05

num_try : 104 | val_loss = 1.9982720696134494e-05 | val acc = 0.003846476785838604
Time execution (tranning): 106.999799 seconds 
Time execution (load saved model): 0.002263 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.0014125148009043e-05

num_try : 175 | val_loss = 2.0014125148009043e-05 | val acc = 0.0037968347314745188
Time execution (tranning): 106.994597 seconds 
Time execution (load saved model): 0.002278 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 257
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.0085754576939508e-05

num_try : 167 | val_loss = 2.0085754576939508e-05 | val acc = 0.0037148799747228622
Time execution (tranning): 103.427310 seconds 
Time execution (load saved model): 0.002260 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 241
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.0426058290468065e-05

num_try : 166 | val_loss = 2.0426058290468065e-05 | val acc = 0.0038861774373799562
Time execution (tranning): 99.305895 seconds 
Time execution (load saved model): 0.002288 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 232
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.044201848548255e-05

num_try : 176 | val_loss = 2.044201848548255e-05 | val acc = 0.00386592885479331
Time execution (tranning): 91.571826 seconds 
Time execution (load saved model): 0.002279 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.0446266807994108e-05

num_try : 103 | val_loss = 2.0446266807994108e-05 | val acc = 0.003948991186916828
Time execution (tranning): 106.665429 seconds 
Time execution (load saved model): 0.002317 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.062943054625066e-05

num_try : 105 | val_loss = 2.062943054625066e-05 | val acc = 0.0039006276056170464
Time execution (tranning): 86.825456 seconds 
Time execution (load saved model): 0.002262 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 203
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.0780352233487065e-05

num_try : 249 | val_loss = 2.0780352233487065e-05 | val acc = 0.0034480977337807417
Time execution (tranning): 106.893031 seconds 
Time execution (load saved model): 0.002287 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[64, 64],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 245
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.0875846385024488e-05

num_try : 150 | val_loss = 2.0875846385024488e-05 | val acc = 0.004010641481727362
Time execution (tranning): 93.612722 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 223
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.0885598332824883e-05

num_try : 139 | val_loss = 2.0885598332824883e-05 | val acc = 0.00390583835542202
Time execution (tranning): 85.551692 seconds 
Time execution (load saved model): 0.002273 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 205
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.097527367368457e-05

num_try : 141 | val_loss = 2.097527367368457e-05 | val acc = 0.003993303515017033
Time execution (tranning): 78.700845 seconds 
Time execution (load saved model): 0.002318 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 182
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.1031769174442162e-05

num_try : 117 | val_loss = 2.1031769174442162e-05 | val acc = 0.003923275973647833
Time execution (tranning): 124.047497 seconds 
Time execution (load saved model): 0.002661 seconds 
Time execution (use saved model): 0.000279 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 287
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.1260853591229532e-05

num_try : 116 | val_loss = 2.1260853591229532e-05 | val acc = 0.003961618524044752
Time execution (tranning): 128.603087 seconds 
Time execution (load saved model): 0.002267 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 298
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.1381028045652783e-05

num_try : 188 | val_loss = 2.1381028045652783e-05 | val acc = 0.003820852842181921
Time execution (tranning): 103.048942 seconds 
Time execution (load saved model): 0.002281 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 237
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.1556751817115584e-05

num_try : 155 | val_loss = 2.1556751817115584e-05 | val acc = 0.004022343549877405
Time execution (tranning): 141.636338 seconds 
Time execution (load saved model): 0.002333 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 327
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.15628954811109e-05

num_try : 164 | val_loss = 2.15628954811109e-05 | val acc = 0.003908846527338028
Time execution (tranning): 101.335982 seconds 
Time execution (load saved model): 0.002268 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 236
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.168740265915403e-05

num_try : 189 | val_loss = 2.168740265915403e-05 | val acc = 0.003984236624091864
Time execution (tranning): 115.425890 seconds 
Time execution (load saved model): 0.002399 seconds 
Time execution (use saved model): 0.000262 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.173509064959944e-05

num_try : 174 | val_loss = 2.173509064959944e-05 | val acc = 0.004058734513819218
Time execution (tranning): 111.421281 seconds 
Time execution (load saved model): 0.002276 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 266
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.183976753258321e-05

num_try : 186 | val_loss = 2.183976753258321e-05 | val acc = 0.003877389943227172
Time execution (tranning): 79.425354 seconds 
Time execution (load saved model): 0.002339 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.1899869070693968e-05

num_try : 106 | val_loss = 2.1899869070693968e-05 | val acc = 0.003939909394830465
Time execution (tranning): 96.017674 seconds 
Time execution (load saved model): 0.002271 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.1996865143592004e-05

num_try : 130 | val_loss = 2.1996865143592004e-05 | val acc = 0.0041503021493554115
Time execution (tranning): 127.298070 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 293
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.2194382772795506e-05

num_try : 102 | val_loss = 2.2194382772795506e-05 | val acc = 0.003982609137892723
Time execution (tranning): 111.309444 seconds 
Time execution (load saved model): 0.002266 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 267
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.25269383736304e-05

num_try : 142 | val_loss = 2.25269383736304e-05 | val acc = 0.003998240921646357
Time execution (tranning): 78.329182 seconds 
Time execution (load saved model): 0.002270 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 179
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.2581459725188323e-05

num_try : 131 | val_loss = 2.2581459725188323e-05 | val acc = 0.004100147634744644
Time execution (tranning): 79.032141 seconds 
Time execution (load saved model): 0.002378 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.288245756062679e-05

num_try : 107 | val_loss = 2.288245756062679e-05 | val acc = 0.004171489272266626
Time execution (tranning): 75.556557 seconds 
Time execution (load saved model): 0.002370 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 174
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.3008317330095453e-05

num_try : 191 | val_loss = 2.3008317330095453e-05 | val acc = 0.004109198693186045
Time execution (tranning): 90.930467 seconds 
Time execution (load saved model): 0.002270 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.3358322850981493e-05

num_try : 187 | val_loss = 2.3358322850981493e-05 | val acc = 0.0040389359928667545
Time execution (tranning): 89.273902 seconds 
Time execution (load saved model): 0.002274 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 211
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.339515987841878e-05

num_try : 140 | val_loss = 2.339515987841878e-05 | val acc = 0.004003133624792099
Time execution (tranning): 84.032061 seconds 
Time execution (load saved model): 0.002332 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.3485267684009158e-05

num_try : 114 | val_loss = 2.3485267684009158e-05 | val acc = 0.003976388834416866
Time execution (tranning): 117.745512 seconds 
Time execution (load saved model): 0.002264 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 282
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.3565450737805806e-05

num_try : 127 | val_loss = 2.3565450737805806e-05 | val acc = 0.00411362387239933
Time execution (tranning): 65.652582 seconds 
Time execution (load saved model): 0.002274 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 156
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.3567096613987816e-05

num_try : 143 | val_loss = 2.3567096613987816e-05 | val acc = 0.00418647937476635
Time execution (tranning): 101.625224 seconds 
Time execution (load saved model): 0.002363 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 235
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.3611930164406658e-05

num_try : 119 | val_loss = 2.3611930164406658e-05 | val acc = 0.00397343747317791
Time execution (tranning): 108.062419 seconds 
Time execution (load saved model): 0.002291 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 251
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.3660005354031455e-05

num_try : 154 | val_loss = 2.3660005354031455e-05 | val acc = 0.00408779876306653
Time execution (tranning): 89.255339 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000259 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 210
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.401276496129867e-05

num_try : 179 | val_loss = 2.401276496129867e-05 | val acc = 0.003970750141888857
Time execution (tranning): 114.607319 seconds 
Time execution (load saved model): 0.002355 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 262
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

2.4025955517572584e-05

num_try : 165 | val_loss = 2.4025955517572584e-05 | val acc = 0.004299507010728121
Time execution (tranning): 90.493558 seconds 
Time execution (load saved model): 0.002288 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 213
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.4269969107990617e-05

num_try : 128 | val_loss = 2.4269969107990617e-05 | val acc = 0.004074332304298878
Time execution (tranning): 98.483843 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 229
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.4996167585413787e-05

num_try : 162 | val_loss = 2.4996167585413787e-05 | val acc = 0.004142910707741976
Time execution (tranning): 79.880102 seconds 
Time execution (load saved model): 0.002338 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 191
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.5121364451479167e-05

num_try : 126 | val_loss = 2.5121364451479167e-05 | val acc = 0.004011576529592276
Time execution (tranning): 85.028952 seconds 
Time execution (load saved model): 0.002290 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 204
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

2.5636057689553126e-05

num_try : 152 | val_loss = 2.5636057689553126e-05 | val acc = 0.004165946040302515
Time execution (tranning): 121.950908 seconds 
Time execution (load saved model): 0.002287 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

2.5707312688609817e-05

num_try : 115 | val_loss = 2.5707312688609817e-05 | val acc = 0.004033850040286779
Time execution (tranning): 92.893273 seconds 
Time execution (load saved model): 0.002301 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 221
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.5938010749086972e-05

num_try : 118 | val_loss = 2.5938010749086972e-05 | val acc = 0.004132751375436783
Time execution (tranning): 124.484801 seconds 
Time execution (load saved model): 0.002375 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 288
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

2.656630267665605e-05

num_try : 151 | val_loss = 2.656630267665605e-05 | val acc = 0.004110577516257763
Time execution (tranning): 86.617465 seconds 
Time execution (load saved model): 0.002348 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 208
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

2.8530232411867474e-05

num_try : 153 | val_loss = 2.8530232411867474e-05 | val acc = 0.0043388856574893
Time execution (tranning): 110.119334 seconds 
Time execution (load saved model): 0.002359 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 256
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

2.8545408149511786e-05

num_try : 178 | val_loss = 2.8545408149511786e-05 | val acc = 0.004320732317864895
Time execution (tranning): 93.479621 seconds 
Time execution (load saved model): 0.002429 seconds 
Time execution (use saved model): 0.000266 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 214
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.174605823005549e-05

num_try : 129 | val_loss = 3.174605823005549e-05 | val acc = 0.004326367750763893
Time execution (tranning): 70.541963 seconds 
Time execution (load saved model): 0.002340 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 164
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.3735755005182e-05

num_try : 59 | val_loss = 3.3735755005182e-05 | val acc = 0.004928601440042257
Time execution (tranning): 77.409685 seconds 
Time execution (load saved model): 0.002253 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 183
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

3.379099975063582e-05

num_try : 54 | val_loss = 3.379099975063582e-05 | val acc = 0.0050448887050151825
Time execution (tranning): 71.064060 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 173
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.3864414472191126e-05

num_try : 66 | val_loss = 3.3864414472191126e-05 | val acc = 0.004750864114612341
Time execution (tranning): 136.467436 seconds 
Time execution (load saved model): 0.002249 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 328
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.458788067291607e-05

num_try : 56 | val_loss = 3.458788067291607e-05 | val acc = 0.005092504434287548
Time execution (tranning): 58.466581 seconds 
Time execution (load saved model): 0.002262 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 138
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.469311252047191e-05

num_try : 67 | val_loss = 3.469311252047191e-05 | val acc = 0.004985211882740259
Time execution (tranning): 92.515420 seconds 
Time execution (load saved model): 0.002310 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 222
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.477746721728181e-05

num_try : 177 | val_loss = 3.477746721728181e-05 | val acc = 0.003845247672870755
Time execution (tranning): 85.494423 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[32, 32],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.5193097737646894e-05

num_try : 80 | val_loss = 3.5193097737646894e-05 | val acc = 0.004941021092236042
Time execution (tranning): 98.043483 seconds 
Time execution (load saved model): 0.002391 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 228
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.5649383626150666e-05

num_try : 8 | val_loss = 3.5649383626150666e-05 | val acc = 0.004824714735150337
Time execution (tranning): 111.543918 seconds 
Time execution (load saved model): 0.002283 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 265
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.572451312720659e-05

num_try : 79 | val_loss = 3.572451312720659e-05 | val acc = 0.005096654873341322
Time execution (tranning): 96.316115 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 233
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.6031277013535145e-05

num_try : 20 | val_loss = 3.6031277013535145e-05 | val acc = 0.005092759616672993
Time execution (tranning): 71.144696 seconds 
Time execution (load saved model): 0.002323 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 166
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.608877615988604e-05

num_try : 58 | val_loss = 3.608877615988604e-05 | val acc = 0.004919827915728092
Time execution (tranning): 70.257895 seconds 
Time execution (load saved model): 0.002309 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 166
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.611377711422392e-05

num_try : 91 | val_loss = 3.611377711422392e-05 | val acc = 0.0048683322966098785
Time execution (tranning): 81.621851 seconds 
Time execution (load saved model): 0.002395 seconds 
Time execution (use saved model): 0.000264 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 196
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.6667415788542715e-05

num_try : 30 | val_loss = 3.6667415788542715e-05 | val acc = 0.005086081102490425
Time execution (tranning): 129.079289 seconds 
Time execution (load saved model): 0.002244 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 310
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.682919292259612e-05

num_try : 70 | val_loss = 3.682919292259612e-05 | val acc = 0.005051976069808006
Time execution (tranning): 87.591708 seconds 
Time execution (load saved model): 0.002263 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.700644823766197e-05

num_try : 90 | val_loss = 3.700644823766197e-05 | val acc = 0.0049692075699567795
Time execution (tranning): 130.996890 seconds 
Time execution (load saved model): 0.002309 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 316
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.701464345795103e-05

num_try : 46 | val_loss = 3.701464345795103e-05 | val acc = 0.005039671435952187
Time execution (tranning): 102.298991 seconds 
Time execution (load saved model): 0.002296 seconds 
Time execution (use saved model): 0.000253 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 239
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.7050922783237185e-05

num_try : 45 | val_loss = 3.7050922783237185e-05 | val acc = 0.004939272068440914
Time execution (tranning): 80.043494 seconds 
Time execution (load saved model): 0.002441 seconds 
Time execution (use saved model): 0.000265 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.7207794593996366e-05

num_try : 57 | val_loss = 3.7207794593996366e-05 | val acc = 0.005063849035650492
Time execution (tranning): 93.531506 seconds 
Time execution (load saved model): 0.002274 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 220
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.737068884220207e-05

num_try : 22 | val_loss = 3.737068884220207e-05 | val acc = 0.005129246506839991
Time execution (tranning): 130.138024 seconds 
Time execution (load saved model): 0.002299 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 304
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

3.777998295845464e-05

num_try : 9 | val_loss = 3.777998295845464e-05 | val acc = 0.005259023979306221
Time execution (tranning): 80.720571 seconds 
Time execution (load saved model): 0.002347 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 189
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.779063272304484e-05

num_try : 44 | val_loss = 3.779063272304484e-05 | val acc = 0.004956865217536688
Time execution (tranning): 108.503890 seconds 
Time execution (load saved model): 0.002364 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 254
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.797451323407586e-05

num_try : 19 | val_loss = 3.797451323407586e-05 | val acc = 0.005166634917259216
Time execution (tranning): 93.575961 seconds 
Time execution (load saved model): 0.002283 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.797468503762502e-05

num_try : 11 | val_loss = 3.797468503762502e-05 | val acc = 0.005015882663428783
Time execution (tranning): 82.136579 seconds 
Time execution (load saved model): 0.002287 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 194
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

3.803607618465321e-05

num_try : 32 | val_loss = 3.803607618465321e-05 | val acc = 0.00512920506298542
Time execution (tranning): 95.861550 seconds 
Time execution (load saved model): 0.002254 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 225
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.812814247794449e-05

num_try : 42 | val_loss = 3.812814247794449e-05 | val acc = 0.005130646284669638
Time execution (tranning): 95.743922 seconds 
Time execution (load saved model): 0.002370 seconds 
Time execution (use saved model): 0.000260 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.827903548881295e-05

num_try : 55 | val_loss = 3.827903548881295e-05 | val acc = 0.005190541967749596
Time execution (tranning): 93.610754 seconds 
Time execution (load saved model): 0.002253 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 228
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

3.8332490676111773e-05

num_try : 81 | val_loss = 3.8332490676111773e-05 | val acc = 0.005094723775982857
Time execution (tranning): 82.047150 seconds 
Time execution (load saved model): 0.002317 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

3.845104194624582e-05

num_try : 71 | val_loss = 3.845104194624582e-05 | val acc = 0.005245306994765997
Time execution (tranning): 181.251233 seconds 
Time execution (load saved model): 0.002305 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 425
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

3.9016166992951186e-05

num_try : 78 | val_loss = 3.9016166992951186e-05 | val acc = 0.005048326216638088
Time execution (tranning): 74.133102 seconds 
Time execution (load saved model): 0.002267 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 179
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.9059510127117394e-05

num_try : 92 | val_loss = 3.9059510127117394e-05 | val acc = 0.005232871975749731
Time execution (tranning): 98.685454 seconds 
Time execution (load saved model): 0.002270 seconds 
Time execution (use saved model): 0.000251 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 231
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

3.9260780813492605e-05

num_try : 6 | val_loss = 3.9260780813492605e-05 | val acc = 0.005268373526632786
Time execution (tranning): 76.182595 seconds 
Time execution (load saved model): 0.002329 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

3.926507668438717e-05

num_try : 43 | val_loss = 3.926507668438717e-05 | val acc = 0.00504668103531003
Time execution (tranning): 89.896374 seconds 
Time execution (load saved model): 0.002305 seconds 
Time execution (use saved model): 0.000256 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 215
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.01457815678441e-05

num_try : 93 | val_loss = 4.01457815678441e-05 | val acc = 0.005240148399025202
Time execution (tranning): 107.170714 seconds 
Time execution (load saved model): 0.002315 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 250
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.0328270770260133e-05

num_try : 69 | val_loss = 4.0328270770260133e-05 | val acc = 0.005132141523063183
Time execution (tranning): 73.029316 seconds 
Time execution (load saved model): 0.002258 seconds 
Time execution (use saved model): 0.000248 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 172
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.093119825483882e-05

num_try : 31 | val_loss = 4.093119825483882e-05 | val acc = 0.005258665885776281
Time execution (tranning): 85.724515 seconds 
Time execution (load saved model): 0.002312 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

4.15509709273465e-05

num_try : 21 | val_loss = 4.15509709273465e-05 | val acc = 0.005028190091252327
Time execution (tranning): 68.228103 seconds 
Time execution (load saved model): 0.002242 seconds 
Time execution (use saved model): 0.000246 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 160
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

4.167116727330722e-05

num_try : 82 | val_loss = 4.167116727330722e-05 | val acc = 0.00536677660420537
Time execution (tranning): 126.195512 seconds 
Time execution (load saved model): 0.002408 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 295
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.311708100431133e-05

num_try : 47 | val_loss = 4.311708100431133e-05 | val acc = 0.005544036626815796
Time execution (tranning): 79.858036 seconds 
Time execution (load saved model): 0.002320 seconds 
Time execution (use saved model): 0.000255 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 188
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.371918279503007e-05

num_try : 10 | val_loss = 4.371918279503007e-05 | val acc = 0.005192523822188377
Time execution (tranning): 84.833709 seconds 
Time execution (load saved model): 0.002388 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 200
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.428648499015253e-05

num_try : 34 | val_loss = 4.428648499015253e-05 | val acc = 0.005322776269167662
Time execution (tranning): 81.950171 seconds 
Time execution (load saved model): 0.002246 seconds 
Time execution (use saved model): 0.000249 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 193
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.514018666668562e-05

num_try : 94 | val_loss = 4.514018666668562e-05 | val acc = 0.005539467558264732
Time execution (tranning): 84.711131 seconds 
Time execution (load saved model): 0.002377 seconds 
Time execution (use saved model): 0.000263 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 197
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 1.0}
----------

4.580754335620441e-05

num_try : 83 | val_loss = 4.580754335620441e-05 | val acc = 0.005637696478515863
Time execution (tranning): 79.843357 seconds 
Time execution (load saved model): 0.002336 seconds 
Time execution (use saved model): 0.000258 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 187
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.5811985582986384e-05

num_try : 23 | val_loss = 4.5811985582986384e-05 | val acc = 0.005437569692730904
Time execution (tranning): 67.792428 seconds 
Time execution (load saved model): 0.002335 seconds 
Time execution (use saved model): 0.000257 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 160
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.626152896889835e-05

num_try : 35 | val_loss = 4.626152896889835e-05 | val acc = 0.0053369635716080666
Time execution (tranning): 137.476068 seconds 
Time execution (load saved model): 0.002256 seconds 
Time execution (use saved model): 0.000250 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 324
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

4.8615785399306336e-05

num_try : 7 | val_loss = 4.8615785399306336e-05 | val acc = 0.005586187820881605
Time execution (tranning): 126.071453 seconds 
Time execution (load saved model): 0.002308 seconds 
Time execution (use saved model): 0.000252 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000004e-08
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 305
Criterion: LogCoshLoss
with parameters: {'factor': 1.8}
----------

5.0168134166597155e-05

num_try : 33 | val_loss = 5.0168134166597155e-05 | val acc = 0.0054949508048594
Time execution (tranning): 84.439163 seconds 
Time execution (load saved model): 0.002284 seconds 
Time execution (use saved model): 0.000247 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.001,
- learning_rate=0.01,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 198
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 2.0}
----------

5.174909842025954e-05

num_try : 68 | val_loss = 5.174909842025954e-05 | val acc = 0.005333715118467808
Time execution (tranning): 87.097816 seconds 
Time execution (load saved model): 0.002314 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 206
Criterion: ModifiedHuberLoss
with parameters: {'delta': 0.2, 'factor': 1.0}
----------

5.2982139259256655e-05

num_try : 18 | val_loss = 5.2982139259256655e-05 | val acc = 0.005555164068937302
Time execution (tranning): 76.303073 seconds 
Time execution (load saved model): 0.002374 seconds 
Time execution (use saved model): 0.000261 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.01,
- L2_penalty=0.01,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-06
    maximize: False
    weight_decay: 0
),
- criterion=LogCoshLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 185
Criterion: LogCoshLoss
with parameters: {'factor': 1.0}
----------

5.418653498054482e-05

num_try : 95 | val_loss = 5.418653498054482e-05 | val acc = 0.005523813422769308
Time execution (tranning): 123.646204 seconds 
Time execution (load saved model): 0.002297 seconds 
Time execution (use saved model): 0.000254 seconds 
Training with hyperparameters : ModelConfig : 
- model_name=Try Hyperparams,
- mode=Mode.DLMT_DQ,
- batch_size=32,
- n_nodes=[16, 16],
- activations=[GELU(approximate='none'), GELU(approximate='none')],
- L1_penalty=0.001,
- L2_penalty=0.001,
- learning_rate=0.001,
- num_epochs=1000,
- optimizer=Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.0000000000000002e-07
    maximize: False
    weight_decay: 0
),
- criterion=ModifiedHuberLoss(),
- p_dropout=0.2, 
- use_batch_norm=True,
- loss=0.0,
- mean_distance=0.0 

Num of epoch used : 286
Criterion: ModifiedHuberLoss
with parameters: {'delta': 1.0, 'factor': 2.0}
----------

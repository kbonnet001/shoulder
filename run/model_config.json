{"input_size": 26, "output_size": 8, "activation": ["GELU"], "n_layers": 1, "n_nodes": [10], "L1_penalty": 0.001, "L2_penalty": 0.001, "use_batch_norm": true, "dropout_prob": 0.5}